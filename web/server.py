#!/usr/bin/env python3
# /// script
# requires-python = ">=3.10"
# dependencies = ["flask", "flask-cors", "anthropic", "requests"]
# ///
"""
Deep Vision Web Server - AI é©±åŠ¨ç‰ˆæœ¬

å®Œæ•´å®ç° deep-vision æŠ€èƒ½çš„æ‰€æœ‰åŠŸèƒ½ï¼š
- åŠ¨æ€ç”Ÿæˆé—®é¢˜å’Œé€‰é¡¹ï¼ˆåŸºäºä¸Šä¸‹æ–‡å’Œè¡Œä¸šçŸ¥è¯†ï¼‰
- æ™ºèƒ½è¿½é—®ï¼ˆè¯†åˆ«è¡¨é¢éœ€æ±‚ï¼ŒæŒ–æ˜æœ¬è´¨ï¼‰
- å†²çªæ£€æµ‹ï¼ˆæ£€æµ‹å›ç­”ä¸å‚è€ƒæ–‡æ¡£çš„å†²çªï¼‰
- çŸ¥è¯†å¢å¼ºï¼ˆä¸“ä¸šé¢†åŸŸä¿¡æ¯èå…¥é€‰é¡¹ï¼‰
- ç”Ÿæˆä¸“ä¸šè°ƒç ”æŠ¥å‘Š
"""

import json
import os
import secrets
import requests
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

from flask import Flask, jsonify, request, send_from_directory
from flask_cors import CORS

# åŠ è½½é…ç½®æ–‡ä»¶
try:
    from config import (
        ANTHROPIC_API_KEY,
        ANTHROPIC_BASE_URL,
        MODEL_NAME,
        MAX_TOKENS_DEFAULT,
        MAX_TOKENS_QUESTION,
        MAX_TOKENS_REPORT,
        SERVER_HOST,
        SERVER_PORT,
        DEBUG_MODE,
        ENABLE_AI,
        ENABLE_DEBUG_LOG,
        ENABLE_WEB_SEARCH,
        ZHIPU_API_KEY,
        ZHIPU_SEARCH_ENGINE,
        SEARCH_MAX_RESULTS,
        SEARCH_TIMEOUT
    )
    print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
except ImportError:
    print("âš ï¸  æœªæ‰¾åˆ° config.pyï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    print("   è¯·å¤åˆ¶ config.example.py ä¸º config.py å¹¶å¡«å…¥å®é™…é…ç½®")
    # é»˜è®¤é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
    ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_AUTH_TOKEN", "")
    ANTHROPIC_BASE_URL = os.environ.get("ANTHROPIC_BASE_URL", "https://api.anthropic.com")
    MODEL_NAME = "claude-sonnet-4-20250514"
    MAX_TOKENS_DEFAULT = 2000
    MAX_TOKENS_QUESTION = 500
    MAX_TOKENS_REPORT = 4000
    SERVER_HOST = "0.0.0.0"
    SERVER_PORT = 5001
    DEBUG_MODE = True
    ENABLE_AI = True
    ENABLE_DEBUG_LOG = True
    ENABLE_WEB_SEARCH = False
    ZHIPU_API_KEY = ""
    ZHIPU_SEARCH_ENGINE = "search_pro"
    SEARCH_MAX_RESULTS = 3
    SEARCH_TIMEOUT = 10

try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False
    print("è­¦å‘Š: anthropic åº“æœªå®‰è£…ï¼Œå°†æ— æ³•ä½¿ç”¨ AI åŠŸèƒ½")

app = Flask(__name__, static_folder='.')
CORS(app)

# è·¯å¾„é…ç½®
SKILL_DIR = Path(__file__).parent.parent.resolve()
DATA_DIR = SKILL_DIR / "data"
SESSIONS_DIR = DATA_DIR / "sessions"
REPORTS_DIR = DATA_DIR / "reports"
CONVERTED_DIR = DATA_DIR / "converted"
TEMP_DIR = DATA_DIR / "temp"
DELETED_REPORTS_FILE = REPORTS_DIR / ".deleted_reports.json"

for d in [SESSIONS_DIR, REPORTS_DIR, CONVERTED_DIR, TEMP_DIR]:
    d.mkdir(parents=True, exist_ok=True)

# Web Search çŠ¶æ€è¿½è¸ªï¼ˆç”¨äºå‰ç«¯å‘¼å¸ç¯æ•ˆæœï¼‰
web_search_active = False

# Claude å®¢æˆ·ç«¯åˆå§‹åŒ–
claude_client = None

if ENABLE_AI and HAS_ANTHROPIC and ANTHROPIC_API_KEY:
    try:
        claude_client = anthropic.Anthropic(
            api_key=ANTHROPIC_API_KEY,
            base_url=ANTHROPIC_BASE_URL
        )
        print(f"âœ… Claude å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
        print(f"   æ¨¡å‹: {MODEL_NAME}")
        print(f"   Base URL: {ANTHROPIC_BASE_URL}")
    except Exception as e:
        print(f"âŒ Claude å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
else:
    if not ENABLE_AI:
        print("â„¹ï¸  AI åŠŸèƒ½å·²ç¦ç”¨ï¼ˆENABLE_AI=Falseï¼‰")
    elif not HAS_ANTHROPIC:
        print("âŒ anthropic åº“æœªå®‰è£…")
    elif not ANTHROPIC_API_KEY:
        print("âŒ æœªé…ç½® ANTHROPIC_API_KEY")


def get_utc_now() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def generate_session_id() -> str:
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    random_suffix = secrets.token_hex(4)
    return f"dv-{timestamp}-{random_suffix}"


def get_deleted_reports() -> set:
    """è·å–å·²åˆ é™¤æŠ¥å‘Šçš„åˆ—è¡¨"""
    if not DELETED_REPORTS_FILE.exists():
        return set()
    try:
        data = json.loads(DELETED_REPORTS_FILE.read_text(encoding="utf-8"))
        return set(data.get("deleted", []))
    except Exception:
        return set()


def mark_report_as_deleted(filename: str):
    """æ ‡è®°æŠ¥å‘Šä¸ºå·²åˆ é™¤ï¼ˆä¸çœŸæ­£åˆ é™¤æ–‡ä»¶ï¼‰"""
    deleted = get_deleted_reports()
    deleted.add(filename)
    DELETED_REPORTS_FILE.write_text(
        json.dumps({"deleted": list(deleted)}, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )


# ============ è”ç½‘æœç´¢åŠŸèƒ½ ============

class MCPClient:
    """æ™ºè°±AI MCPå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url
        self.session_id = None
        self.message_id = 0

    def _get_next_id(self):
        """è·å–ä¸‹ä¸€ä¸ªæ¶ˆæ¯ID"""
        self.message_id += 1
        return self.message_id

    def _make_request(self, method: str, params: dict = None):
        """å‘é€MCP JSON-RPCè¯·æ±‚"""
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }

        # å¦‚æœæœ‰session_idï¼Œæ·»åŠ åˆ°header
        if self.session_id:
            headers["Mcp-Session-Id"] = self.session_id

        # åœ¨URLä¸­æ·»åŠ Authorizationå‚æ•°
        url = f"{self.base_url}?Authorization={self.api_key}"

        request_data = {
            "jsonrpc": "2.0",
            "id": self._get_next_id(),
            "method": method,
            "params": params or {}
        }

        if ENABLE_DEBUG_LOG:
            print(f"ğŸ“¤ MCPè¯·æ±‚: {method}")
            print(f"   å‚æ•°: {params}")

        response = requests.post(url, json=request_data, headers=headers, timeout=SEARCH_TIMEOUT)
        response.raise_for_status()

        # æ£€æŸ¥å“åº”å¤´ä¸­çš„Session ID
        if "Mcp-Session-Id" in response.headers:
            self.session_id = response.headers["Mcp-Session-Id"]
            if ENABLE_DEBUG_LOG:
                print(f"   ğŸ“ è·å¾—Session ID: {self.session_id}")

        # è§£æSSEæ ¼å¼çš„å“åº”
        response_text = response.text.strip()

        # SSEæ ¼å¼: id:1\nevent:message\ndata:{json}\n\n
        result_data = None
        for line in response_text.split('\n'):
            line = line.strip()
            if line.startswith('data:'):
                json_str = line[5:].strip()  # å»æ‰ "data:" å‰ç¼€
                try:
                    result_data = json.loads(json_str)
                    break
                except:
                    continue

        if not result_data:
            raise Exception(f"æ— æ³•è§£æSSEå“åº”: {response_text[:200]}")

        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "error" in result_data:
            raise Exception(f"MCPé”™è¯¯: {result_data['error']}")

        return result_data.get("result", {})

    def initialize(self):
        """åˆå§‹åŒ–MCPè¿æ¥"""
        try:
            result = self._make_request("initialize", {
                "protocolVersion": "2024-11-05",
                "capabilities": {},
                "clientInfo": {
                    "name": "deep-vision",
                    "version": "1.0.0"
                }
            })
            if ENABLE_DEBUG_LOG:
                print(f"âœ… MCPåˆå§‹åŒ–æˆåŠŸ")
            return result
        except Exception as e:
            if ENABLE_DEBUG_LOG:
                print(f"âŒ MCPåˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def call_tool(self, tool_name: str, arguments: dict):
        """è°ƒç”¨MCPå·¥å…·"""
        try:
            # ç¡®ä¿å·²åˆå§‹åŒ–
            if not self.session_id:
                self.initialize()

            result = self._make_request("tools/call", {
                "name": tool_name,
                "arguments": arguments
            })

            return result
        except Exception as e:
            if ENABLE_DEBUG_LOG:
                print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            raise


def web_search(query: str) -> list:
    """ä½¿ç”¨æ™ºè°±AI MCP web_search_prime è¿›è¡Œè”ç½‘æœç´¢"""
    global web_search_active

    if not ENABLE_WEB_SEARCH or not ZHIPU_API_KEY or ZHIPU_API_KEY == "your-zhipu-api-key-here":
        if ENABLE_DEBUG_LOG:
            print(f"âš ï¸  æœç´¢åŠŸèƒ½æœªå¯ç”¨æˆ– API Key æœªé…ç½®ï¼Œè·³è¿‡æœç´¢: {query}")
        return []

    try:
        # è®¾ç½®æœç´¢çŠ¶æ€ä¸ºæ´»åŠ¨
        web_search_active = True

        mcp_url = "https://open.bigmodel.cn/api/mcp/web_search_prime/mcp"

        if ENABLE_DEBUG_LOG:
            print(f"ğŸ” å¼€å§‹MCPæœç´¢: {query}")

        # åˆ›å»ºMCPå®¢æˆ·ç«¯
        client = MCPClient(ZHIPU_API_KEY, mcp_url)

        # è°ƒç”¨webSearchPrimeå·¥å…·ï¼ˆæ³¨æ„ï¼šå·¥å…·åæ˜¯é©¼å³°å‘½åï¼‰
        result = client.call_tool("webSearchPrime", {
            "search_query": query,
            "search_recency_filter": "noLimit",
            "content_size": "medium"
        })

        # è§£æç»“æœ
        results = []

        # MCPè¿”å›çš„contentæ˜¯ä¸€ä¸ªåˆ—è¡¨
        content_list = result.get("content", [])

        for item in content_list:
            if item.get("type") == "text":
                # æ–‡æœ¬å†…å®¹
                text = item.get("text", "")

                # å°è¯•è§£æJSONæ ¼å¼çš„æœç´¢ç»“æœ
                try:
                    import json as json_module

                    # ç¬¬ä¸€æ¬¡è§£æï¼šå»æ‰å¤–å±‚å¼•å·å’Œè½¬ä¹‰
                    if text.startswith('"') and text.endswith('"'):
                        text = json_module.loads(text)

                    # ç¬¬äºŒæ¬¡è§£æï¼šè·å–å®é™…çš„æœç´¢ç»“æœæ•°ç»„
                    search_data = json_module.loads(text)

                    # å¦‚æœæ˜¯åˆ—è¡¨å½¢å¼çš„æœç´¢ç»“æœ
                    if isinstance(search_data, list):
                        for entry in search_data[:SEARCH_MAX_RESULTS]:
                            title = entry.get("title", "")
                            content = entry.get("content", "")
                            url = entry.get("link", entry.get("url", ""))

                            if title or content:  # ç¡®ä¿æœ‰å®é™…å†…å®¹
                                results.append({
                                    "type": "result",
                                    "title": title[:100] if title else "æœç´¢ç»“æœ",
                                    "content": content[:300],
                                    "url": url
                                })
                    # å¦‚æœæ˜¯å•ä¸ªç»“æœ
                    elif isinstance(search_data, dict):
                        title = search_data.get("title", "")
                        content = search_data.get("content", text[:300])
                        url = search_data.get("link", search_data.get("url", ""))

                        results.append({
                            "type": "result",
                            "title": title[:100] if title else "æœç´¢ç»“æœ",
                            "content": content[:300],
                            "url": url
                        })
                except Exception as parse_error:
                    if ENABLE_DEBUG_LOG:
                        print(f"âš ï¸  è§£ææœç´¢ç»“æœå¤±è´¥: {parse_error}")
                        print(f"   åŸå§‹æ–‡æœ¬å‰200å­—ç¬¦: {text[:200]}")
                    # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½œä¸ºæ–‡æœ¬ç»“æœ
                    results.append({
                        "type": "result",
                        "title": "æœç´¢ç»“æœ",
                        "content": text[:300],
                        "url": ""
                    })

        if ENABLE_DEBUG_LOG:
            print(f"âœ… MCPæœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœ")

        # æœç´¢å®Œæˆï¼Œé‡ç½®çŠ¶æ€
        web_search_active = False
        return results

    except requests.exceptions.Timeout:
        print(f"â±ï¸  æœç´¢è¶…æ—¶: {query}")
        web_search_active = False
        return []
    except Exception as e:
        print(f"âŒ MCPæœç´¢å¤±è´¥: {e}")
        if ENABLE_DEBUG_LOG:
            import traceback
            traceback.print_exc()
        web_search_active = False
        return []


def should_search(topic: str, dimension: str, context: dict) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œè”ç½‘æœç´¢"""
    if not ENABLE_WEB_SEARCH:
        return False

    # æŠ€æœ¯å…³é”®è¯
    tech_keywords = [
        "æŠ€æœ¯", "ç³»ç»Ÿ", "å¹³å°", "æ¡†æ¶", "å·¥å…·", "è½¯ä»¶", "åº”ç”¨",
        "AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "å¤§æ¨¡å‹",
        "äº‘", "SaaS", "PaaS", "å¾®æœåŠ¡", "å®¹å™¨", "Docker", "K8s",
        "æ•°æ®åº“", "ä¸­é—´ä»¶", "API", "é›†æˆ", "éƒ¨ç½²"
    ]

    # è¡Œä¸šå…³é”®è¯
    industry_keywords = [
        "è¡Œä¸š", "æ ‡å‡†", "è§„èŒƒ", "åˆè§„", "è®¤è¯", "ç­‰ä¿",
        "å¸‚åœº", "è¶‹åŠ¿", "æœ€æ–°", "ç°çŠ¶", "å‘å±•"
    ]

    # æ—¶é—´æ•æ„Ÿå…³é”®è¯
    time_keywords = [
        "æœ€æ–°", "å½“å‰", "ç°åœ¨", "2024", "2025", "2026",
        "è¶‹åŠ¿", "æœªæ¥", "å‘å±•"
    ]

    topic_lower = topic.lower()
    all_keywords = tech_keywords + industry_keywords + time_keywords

    # å¦‚æœä¸»é¢˜åŒ…å«å…³é”®è¯ï¼Œå¯èƒ½éœ€è¦æœç´¢
    for keyword in all_keywords:
        if keyword in topic:
            return True

    # æŠ€æœ¯çº¦æŸç»´åº¦æ›´å¯èƒ½éœ€è¦æœç´¢
    if dimension == "tech_constraints":
        return True

    return False


def generate_search_query(topic: str, dimension: str, context: dict) -> str:
    """ç”Ÿæˆæœç´¢æŸ¥è¯¢"""
    dim_info = DIMENSION_INFO.get(dimension, {})
    dim_name = dim_info.get("name", dimension)

    # æ„å»ºæœç´¢æŸ¥è¯¢
    if dimension == "tech_constraints":
        return f"{topic} æŠ€æœ¯é€‰å‹ æœ€ä½³å®è·µ 2026"
    elif dimension == "customer_needs":
        return f"{topic} ç”¨æˆ·éœ€æ±‚ è¡Œä¸šç—›ç‚¹ 2026"
    elif dimension == "business_process":
        return f"{topic} ä¸šåŠ¡æµç¨‹ æœ€ä½³å®è·µ"
    elif dimension == "project_constraints":
        return f"{topic} é¡¹ç›®å®æ–½ æˆæœ¬é¢„ç®— å‘¨æœŸ"
    else:
        return f"{topic} {dim_name}"


# ============ Deep Vision AI æ ¸å¿ƒé€»è¾‘ ============

DIMENSION_INFO = {
    "customer_needs": {
        "name": "å®¢æˆ·éœ€æ±‚",
        "description": "æ ¸å¿ƒç—›ç‚¹ã€æœŸæœ›ä»·å€¼ã€ä½¿ç”¨åœºæ™¯ã€ç”¨æˆ·è§’è‰²",
        "key_aspects": ["æ ¸å¿ƒç—›ç‚¹", "æœŸæœ›ä»·å€¼", "ä½¿ç”¨åœºæ™¯", "ç”¨æˆ·è§’è‰²"]
    },
    "business_process": {
        "name": "ä¸šåŠ¡æµç¨‹",
        "description": "å…³é”®æµç¨‹èŠ‚ç‚¹ã€è§’è‰²åˆ†å·¥ã€è§¦å‘äº‹ä»¶ã€å¼‚å¸¸å¤„ç†",
        "key_aspects": ["å…³é”®æµç¨‹", "è§’è‰²åˆ†å·¥", "è§¦å‘äº‹ä»¶", "å¼‚å¸¸å¤„ç†"]
    },
    "tech_constraints": {
        "name": "æŠ€æœ¯çº¦æŸ",
        "description": "ç°æœ‰æŠ€æœ¯æ ˆã€é›†æˆæ¥å£è¦æ±‚ã€æ€§èƒ½æŒ‡æ ‡ã€å®‰å…¨åˆè§„",
        "key_aspects": ["éƒ¨ç½²æ–¹å¼", "ç³»ç»Ÿé›†æˆ", "æ€§èƒ½è¦æ±‚", "å®‰å…¨åˆè§„"]
    },
    "project_constraints": {
        "name": "é¡¹ç›®çº¦æŸ",
        "description": "é¢„ç®—èŒƒå›´ã€æ—¶é—´èŠ‚ç‚¹ã€èµ„æºé™åˆ¶ã€å…¶ä»–çº¦æŸ",
        "key_aspects": ["é¢„ç®—èŒƒå›´", "æ—¶é—´èŠ‚ç‚¹", "èµ„æºé™åˆ¶", "ä¼˜å…ˆçº§"]
    }
}


def build_interview_prompt(session: dict, dimension: str) -> str:
    """æ„å»ºè®¿è°ˆ prompt"""
    topic = session.get("topic", "æœªçŸ¥é¡¹ç›®")
    reference_docs = session.get("reference_docs", [])
    interview_log = session.get("interview_log", [])
    dim_info = DIMENSION_INFO.get(dimension, {})

    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = [f"å½“å‰è°ƒç ”ä¸»é¢˜ï¼š{topic}"]

    # æ·»åŠ å‚è€ƒæ–‡æ¡£å†…å®¹
    if reference_docs:
        context_parts.append("\n## å‚è€ƒæ–‡æ¡£å†…å®¹ï¼š")
        for doc in reference_docs:
            if doc.get("content"):
                context_parts.append(f"### {doc.get('name', 'æ–‡æ¡£')}")
                context_parts.append(doc["content"][:2000])  # é™åˆ¶é•¿åº¦

    # è”ç½‘æœç´¢å¢å¼ºï¼ˆå¦‚æœéœ€è¦ï¼‰
    if should_search(topic, dimension, session):
        search_query = generate_search_query(topic, dimension, session)
        search_results = web_search(search_query)

        if search_results:
            context_parts.append("\n## è¡Œä¸šçŸ¥è¯†å‚è€ƒï¼ˆè”ç½‘æœç´¢ï¼‰ï¼š")
            for idx, result in enumerate(search_results[:2], 1):  # åªå–å‰2ä¸ªç»“æœï¼Œé¿å…è¿‡é•¿
                if result["type"] == "intent":
                    context_parts.append(f"**{result['content'][:200]}**")  # æœç´¢æ„å›¾
                else:
                    context_parts.append(f"{idx}. **{result.get('title', 'å‚è€ƒä¿¡æ¯')[:50]}**")
                    context_parts.append(f"   {result['content'][:200]}")  # é™åˆ¶é•¿åº¦

    # æ·»åŠ å·²æœ‰é—®ç­”è®°å½•
    if interview_log:
        context_parts.append("\n## å·²æ”¶é›†çš„ä¿¡æ¯ï¼š")
        for log in interview_log:
            context_parts.append(f"- Q: {log['question']}")
            context_parts.append(f"  A: {log['answer']}")
            if log.get("dimension"):
                context_parts.append(f"  (ç»´åº¦: {DIMENSION_INFO.get(log['dimension'], {}).get('name', log['dimension'])})")

    # å½“å‰ç»´åº¦å·²æ”¶é›†çš„ä¿¡æ¯
    dim_logs = [log for log in interview_log if log.get("dimension") == dimension]

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éœ€æ±‚è°ƒç ”è®¿è°ˆå¸ˆï¼Œæ­£åœ¨è¿›è¡Œ"{topic}"çš„éœ€æ±‚è°ƒç ”ã€‚

{chr(10).join(context_parts)}

## å½“å‰ä»»åŠ¡

ä½ ç°åœ¨éœ€è¦é’ˆå¯¹ã€Œ{dim_info.get('name', dimension)}ã€ç»´åº¦æ”¶é›†ä¿¡æ¯ã€‚
è¿™ä¸ªç»´åº¦å…³æ³¨ï¼š{dim_info.get('description', '')}

è¯¥ç»´åº¦å·²æ”¶é›†äº† {len(dim_logs)} ä¸ªé—®é¢˜çš„å›ç­”ï¼Œå…³é”®æ–¹é¢åŒ…æ‹¬ï¼š{', '.join(dim_info.get('key_aspects', []))}

## è¦æ±‚

1. ç”Ÿæˆ 1 ä¸ªé’ˆå¯¹æ€§çš„é—®é¢˜ï¼Œç”¨äºæ”¶é›†è¯¥ç»´åº¦çš„å…³é”®ä¿¡æ¯
2. ä¸ºè¿™ä¸ªé—®é¢˜æä¾› 3-4 ä¸ªå…·ä½“çš„é€‰é¡¹
3. é€‰é¡¹è¦åŸºäºï¼š
   - è°ƒç ”ä¸»é¢˜çš„è¡Œä¸šç‰¹ç‚¹
   - å‚è€ƒæ–‡æ¡£ä¸­çš„ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
   - è”ç½‘æœç´¢çš„è¡Œä¸šçŸ¥è¯†ï¼ˆå¦‚æœ‰ï¼‰
   - å·²æ”¶é›†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
4. å¦‚æœç”¨æˆ·çš„ä¸Šä¸€ä¸ªå›ç­”æ¯”è¾ƒç¬¼ç»Ÿæˆ–è¡¨é¢ï¼Œå¯ä»¥ç”Ÿæˆä¸€ä¸ªè¿½é—®æ¥æŒ–æ˜æœ¬è´¨éœ€æ±‚
5. å¦‚æœç”¨æˆ·çš„å›ç­”ä¸å‚è€ƒæ–‡æ¡£å†…å®¹æœ‰å†²çªï¼Œè¦åœ¨é—®é¢˜ä¸­æŒ‡å‡ºå¹¶è¯·æ±‚æ¾„æ¸…
6. **é‡è¦**ï¼šæ ¹æ®é—®é¢˜æ€§è´¨åˆ¤æ–­æ˜¯å•é€‰è¿˜æ˜¯å¤šé€‰ï¼š
   - å•é€‰åœºæ™¯ï¼šäº’æ–¥é€‰é¡¹ï¼ˆæ˜¯/å¦ï¼‰ã€ä¼˜å…ˆçº§é€‰æ‹©ï¼ˆæœ€é‡è¦çš„ï¼‰ã€å”¯ä¸€é€‰æ‹©ï¼ˆé¦–é€‰æ–¹æ¡ˆï¼‰
   - å¤šé€‰åœºæ™¯ï¼šå¯å¹¶å­˜çš„åŠŸèƒ½éœ€æ±‚ã€å¤šä¸ªç—›ç‚¹ã€å¤šç§ç”¨æˆ·è§’è‰²ã€å¤šä¸ªç³»ç»Ÿé›†æˆ

## è¾“å‡ºæ ¼å¼

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
```json
{{
    "question": "ä½ çš„é—®é¢˜",
    "options": ["é€‰é¡¹1", "é€‰é¡¹2", "é€‰é¡¹3", "é€‰é¡¹4"],
    "multi_select": false,
    "is_follow_up": false,
    "follow_up_reason": null,
    "conflict_detected": false,
    "conflict_description": null
}}
```

å­—æ®µè¯´æ˜ï¼š
- multi_select: å¸ƒå°”å€¼ï¼Œtrue è¡¨ç¤ºå¯å¤šé€‰ï¼Œfalse è¡¨ç¤ºå•é€‰

**é‡è¦è­¦å‘Š**ï¼š
- ä½ çš„å›å¤å¿…é¡»æ˜¯ä¸”åªèƒ½æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ JSON å¯¹è±¡
- ç¦æ­¢åœ¨ JSON å‰åæ·»åŠ ä»»ä½•æ–‡å­—ã€è§£é‡Šæˆ–è¯´æ˜
- ç¦æ­¢ä½¿ç”¨ markdown ä»£ç å—ï¼ˆä¸è¦ä½¿ç”¨ ```jsonï¼‰
- ç¬¬ä¸€ä¸ªå­—ç¬¦å¿…é¡»æ˜¯ {{ï¼Œæœ€åä¸€ä¸ªå­—ç¬¦å¿…é¡»æ˜¯ }}
- ä¸¥æ ¼éµå®ˆ JSON è¯­æ³•ï¼Œæ‰€æœ‰å­—ç¬¦ä¸²ä½¿ç”¨åŒå¼•å·"""

    return prompt


def build_report_prompt(session: dict) -> str:
    """æ„å»ºæŠ¥å‘Šç”Ÿæˆ prompt"""
    topic = session.get("topic", "æœªçŸ¥é¡¹ç›®")
    interview_log = session.get("interview_log", [])
    dimensions = session.get("dimensions", {})
    reference_docs = session.get("reference_docs", [])

    # æŒ‰ç»´åº¦æ•´ç†é—®ç­”
    qa_by_dim = {}
    for dim_key in DIMENSION_INFO:
        qa_by_dim[dim_key] = [log for log in interview_log if log.get("dimension") == dim_key]

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éœ€æ±‚åˆ†æå¸ˆï¼Œéœ€è¦åŸºäºä»¥ä¸‹è®¿è°ˆè®°å½•ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„éœ€æ±‚è°ƒç ”æŠ¥å‘Šã€‚

## è°ƒç ”ä¸»é¢˜
{topic}

## å‚è€ƒæ–‡æ¡£
"""

    if reference_docs:
        for doc in reference_docs:
            prompt += f"- {doc.get('name', 'æ–‡æ¡£')}\n"
    else:
        prompt += "æ— å‚è€ƒæ–‡æ¡£\n"

    prompt += "\n## è®¿è°ˆè®°å½•\n"

    for dim_key, dim_info in DIMENSION_INFO.items():
        prompt += f"\n### {dim_info['name']}\n"
        qa_list = qa_by_dim.get(dim_key, [])
        if qa_list:
            for qa in qa_list:
                prompt += f"**Q**: {qa['question']}\n"
                prompt += f"**A**: {qa['answer']}\n\n"
        else:
            prompt += "*è¯¥ç»´åº¦æš‚æ— æ”¶é›†æ•°æ®*\n"

    prompt += """
## æŠ¥å‘Šè¦æ±‚

è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„éœ€æ±‚è°ƒç ”æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š

1. **è°ƒç ”æ¦‚è¿°** - åŸºæœ¬ä¿¡æ¯ã€è°ƒç ”èƒŒæ™¯
2. **éœ€æ±‚æ‘˜è¦** - æ ¸å¿ƒéœ€æ±‚åˆ—è¡¨ã€ä¼˜å…ˆçº§çŸ©é˜µ
3. **è¯¦ç»†éœ€æ±‚åˆ†æ**
   - å®¢æˆ·/ç”¨æˆ·éœ€æ±‚ï¼ˆç—›ç‚¹ã€æœŸæœ›ã€åœºæ™¯ã€è§’è‰²ï¼‰
   - ä¸šåŠ¡æµç¨‹ï¼ˆå…³é”®æµç¨‹ã€å†³ç­–èŠ‚ç‚¹ï¼‰
   - æŠ€æœ¯çº¦æŸï¼ˆéƒ¨ç½²ã€é›†æˆã€å®‰å…¨ï¼‰
   - é¡¹ç›®çº¦æŸï¼ˆé¢„ç®—ã€æ—¶é—´ã€èµ„æºï¼‰
4. **å¯è§†åŒ–åˆ†æ** - ä½¿ç”¨ Mermaid å›¾è¡¨å±•ç¤ºå…³é”®ä¿¡æ¯
5. **æ–¹æ¡ˆå»ºè®®** - åŸºäºéœ€æ±‚çš„å¯è¡Œå»ºè®®
6. **é£é™©è¯„ä¼°** - æ½œåœ¨é£é™©å’Œåº”å¯¹ç­–ç•¥
7. **ä¸‹ä¸€æ­¥è¡ŒåŠ¨** - å…·ä½“çš„è¡ŒåŠ¨é¡¹

**æ³¨æ„**ï¼šä¸éœ€è¦åŒ…å«"é™„å½•"ç« èŠ‚ï¼Œå®Œæ•´çš„è®¿è°ˆè®°å½•ä¼šåœ¨æŠ¥å‘Šç”Ÿæˆåè‡ªåŠ¨è¿½åŠ ã€‚

## Mermaid å›¾è¡¨è§„èŒƒ

è¯·åœ¨æŠ¥å‘Šä¸­åŒ…å«ä»¥ä¸‹ç±»å‹çš„ Mermaid å›¾è¡¨ï¼š

### 1. ä¼˜å…ˆçº§çŸ©é˜µï¼ˆå¿…é¡»ï¼‰
ä½¿ç”¨è±¡é™å›¾å±•ç¤ºéœ€æ±‚ä¼˜å…ˆçº§ï¼Œ**ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼**ï¼š

```mermaid
quadrantChart
    title Priority Matrix
    x-axis Low Urgency --> High Urgency
    y-axis Low Importance --> High Importance
    quadrant-1 Do First
    quadrant-2 Schedule
    quadrant-3 Delegate
    quadrant-4 Eliminate

    Requirement1: [0.8, 0.9]
    Requirement2: [0.3, 0.7]
    Requirement3: [0.6, 0.5]
```

**ä¸¥æ ¼è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š**
- titleã€x-axisã€y-axisã€quadrant æ ‡ç­¾**å¿…é¡»ç”¨è‹±æ–‡**
- æ•°æ®ç‚¹åç§°**å¿…é¡»ç”¨è‹±æ–‡æˆ–æ‹¼éŸ³**ï¼Œä¸èƒ½ç”¨ä¸­æ–‡
- æ•°æ®ç‚¹æ ¼å¼ï¼š`Name: [x, y]`ï¼Œxå’ŒyèŒƒå›´0-1
- ä¸è¦åœ¨æ ‡ç­¾ä¸­ä½¿ç”¨æ‹¬å·ã€å†’å·ç­‰ç‰¹æ®Šç¬¦å·

### 2. ä¸šåŠ¡æµç¨‹å›¾ï¼ˆæ¨èï¼‰
ä½¿ç”¨ flowchart å±•ç¤ºå…³é”®ä¸šåŠ¡æµç¨‹ï¼š

```mermaid
flowchart TD
    A[Start] --> B{Decision}
    B -->|Yes| C[Process1]
    B -->|No| D[Process2]
    C --> E[End]
    D --> E
```

**è§„åˆ™ï¼šèŠ‚ç‚¹æ ‡ç­¾å»ºè®®ç”¨è‹±æ–‡ï¼Œä¸­æ–‡å¯èƒ½å¯¼è‡´æ¸²æŸ“é—®é¢˜**

### 3. éœ€æ±‚åˆ†ç±»é¥¼å›¾ï¼ˆå¯é€‰ï¼‰
```mermaid
pie title Requirements Distribution
    "Functional" : 45
    "Performance" : 25
    "Security" : 20
    "Usability" : 10
```

## é‡è¦æé†’
- æ‰€æœ‰å†…å®¹å¿…é¡»ä¸¥æ ¼åŸºäºè®¿è°ˆè®°å½•ï¼Œä¸å¾—ç¼–é€ 
- ä½¿ç”¨ Markdown æ ¼å¼ï¼ŒMermaid ä»£ç å—ä½¿ç”¨ ```mermaid æ ‡è®°
- **Mermaid å›¾è¡¨çš„æ ‡ç­¾å’Œæ•°æ®ç‚¹åç§°å¿…é¡»ç”¨è‹±æ–‡**ï¼Œå¯åœ¨å›¾è¡¨ä¸‹æ–¹ç”¨ä¸­æ–‡è¯´æ˜
- ä¼˜å…ˆçº§çŸ©é˜µä¸­çš„åæ ‡å€¼è¯·æ ¹æ®å®é™…éœ€æ±‚è¯„ä¼°
- æŠ¥å‘Šè¦ä¸“ä¸šã€ç»“æ„æ¸…æ™°ã€å¯æ“ä½œ
- æŠ¥å‘Šæœ«å°¾ä½¿ç”¨ç½²åï¼š*æ­¤æŠ¥å‘Šç”± Deep Vision æ·±ç³-æ™ºèƒ½éœ€æ±‚è°ƒç ”åŠ©æ‰‹ç”Ÿæˆ*

è¯·ç”Ÿæˆå®Œæ•´çš„æŠ¥å‘Šï¼š"""

    return prompt


async def call_claude_async(prompt: str, max_tokens: int = None) -> Optional[str]:
    """å¼‚æ­¥è°ƒç”¨ Claude API"""
    if not claude_client:
        return None

    if max_tokens is None:
        max_tokens = MAX_TOKENS_DEFAULT

    try:
        message = claude_client.messages.create(
            model=MODEL_NAME,
            max_tokens=max_tokens,
            messages=[{"role": "user", "content": prompt}]
        )
        return message.content[0].text
    except Exception as e:
        print(f"Claude API è°ƒç”¨å¤±è´¥: {e}")
        return None


def call_claude(prompt: str, max_tokens: int = None) -> Optional[str]:
    """åŒæ­¥è°ƒç”¨ Claude API"""
    if not claude_client:
        return None

    if max_tokens is None:
        max_tokens = MAX_TOKENS_DEFAULT

    try:
        message = claude_client.messages.create(
            model=MODEL_NAME,
            max_tokens=max_tokens,
            messages=[{"role": "user", "content": prompt}]
        )
        return message.content[0].text
    except Exception as e:
        print(f"Claude API è°ƒç”¨å¤±è´¥: {e}")
        return None


# ============ é™æ€æ–‡ä»¶ ============

@app.route('/')
def index():
    return send_from_directory('.', 'index.html')


@app.route('/<path:filename>')
def static_files(filename):
    return send_from_directory('.', filename)


# ============ ä¼šè¯ API ============

@app.route('/api/sessions', methods=['GET'])
def list_sessions():
    """è·å–æ‰€æœ‰ä¼šè¯"""
    sessions = []
    for f in SESSIONS_DIR.glob("*.json"):
        try:
            data = json.loads(f.read_text(encoding="utf-8"))
            sessions.append({
                "session_id": data.get("session_id"),
                "topic": data.get("topic"),
                "status": data.get("status"),
                "created_at": data.get("created_at"),
                "updated_at": data.get("updated_at"),
                "dimensions": data.get("dimensions", {}),
                "interview_count": len(data.get("interview_log", []))
            })
        except Exception as e:
            print(f"è¯»å–ä¼šè¯å¤±è´¥ {f}: {e}")

    sessions.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
    return jsonify(sessions)


@app.route('/api/sessions', methods=['POST'])
def create_session():
    """åˆ›å»ºæ–°ä¼šè¯"""
    data = request.get_json()
    topic = data.get("topic", "æœªå‘½åè°ƒç ”")

    session_id = generate_session_id()
    now = get_utc_now()

    session = {
        "session_id": session_id,
        "topic": topic,
        "created_at": now,
        "updated_at": now,
        "status": "in_progress",
        "scenario": None,
        "dimensions": {
            "customer_needs": {"coverage": 0, "items": []},
            "business_process": {"coverage": 0, "items": []},
            "tech_constraints": {"coverage": 0, "items": []},
            "project_constraints": {"coverage": 0, "items": []}
        },
        "reference_docs": [],
        "interview_log": [],
        "requirements": [],
        "summary": None
    }

    session_file = SESSIONS_DIR / f"{session_id}.json"
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify(session)


@app.route('/api/sessions/<session_id>', methods=['GET'])
def get_session(session_id):
    """è·å–ä¼šè¯è¯¦æƒ…"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))
    return jsonify(session)


@app.route('/api/sessions/<session_id>', methods=['PUT'])
def update_session(session_id):
    """æ›´æ–°ä¼šè¯"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    updates = request.get_json()
    session = json.loads(session_file.read_text(encoding="utf-8"))

    for key, value in updates.items():
        if key != "session_id":
            session[key] = value

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify(session)


@app.route('/api/sessions/<session_id>', methods=['DELETE'])
def delete_session(session_id):
    """åˆ é™¤ä¼šè¯"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if session_file.exists():
        session_file.unlink()
    return jsonify({"success": True})


# ============ AI é©±åŠ¨çš„è®¿è°ˆ API ============

@app.route('/api/sessions/<session_id>/next-question', methods=['POST'])
def get_next_question(session_id):
    """è·å–ä¸‹ä¸€ä¸ªé—®é¢˜ï¼ˆAI ç”Ÿæˆï¼‰"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))
    data = request.get_json() or {}
    dimension = data.get("dimension", "customer_needs")

    # æ£€æŸ¥æ˜¯å¦æœ‰ Claude API
    if not claude_client:
        return jsonify({
            "error": "AI æœåŠ¡æœªå¯ç”¨",
            "detail": "è¯·è”ç³»ç®¡ç†å‘˜é…ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡"
        }), 503

    # æ£€æŸ¥ç»´åº¦æ˜¯å¦å·²å®Œæˆ
    dim_logs = [log for log in session.get("interview_log", []) if log.get("dimension") == dimension]
    if len(dim_logs) >= 3:  # æ¯ä¸ªç»´åº¦æœ€å¤š 3 ä¸ªé—®é¢˜
        return jsonify({
            "dimension": dimension,
            "completed": True
        })

    # è°ƒç”¨ Claude ç”Ÿæˆé—®é¢˜
    try:
        prompt = build_interview_prompt(session, dimension)
        response = call_claude(prompt, max_tokens=MAX_TOKENS_QUESTION)

        if not response:
            return jsonify({
                "error": "AI å“åº”å¤±è´¥",
                "detail": "æœªèƒ½ä» AI æœåŠ¡è·å–å“åº”ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
            }), 503

        # è§£æ JSON å“åº”
        result = None
        parse_error = None

        if ENABLE_DEBUG_LOG:
            print(f"ğŸ“ AI åŸå§‹å“åº” (å‰500å­—): {response[:500]}")

        # æ–¹æ³•1: ç›´æ¥å°è¯•è§£æï¼ˆå¦‚æœAIä¸¥æ ¼éµå®ˆæŒ‡ä»¤ï¼‰
        try:
            cleaned = response.strip()
            if cleaned.startswith('{') and cleaned.endswith('}'):
                result = json.loads(cleaned)
                if ENABLE_DEBUG_LOG:
                    print(f"âœ… æ–¹æ³•1æˆåŠŸ: ç›´æ¥è§£æ")
        except json.JSONDecodeError as e:
            parse_error = e
            if ENABLE_DEBUG_LOG:
                print(f"âš ï¸ æ–¹æ³•1å¤±è´¥: {e}")

        # æ–¹æ³•2: å°è¯•æå– ```json ä»£ç å—
        if result is None and "```json" in response:
            try:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                if json_end > json_start:
                    json_str = response[json_start:json_end].strip()
                    result = json.loads(json_str)
                    if ENABLE_DEBUG_LOG:
                        print(f"âœ… æ–¹æ³•2æˆåŠŸ: ä»ä»£ç å—æå–")
            except json.JSONDecodeError as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•2å¤±è´¥ (JSONé”™è¯¯): {e}")
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•2å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æ–¹æ³•3: æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡ï¼ˆèŠ±æ‹¬å·é…å¯¹ï¼‰
        if result is None:
            try:
                json_start = response.find('{')
                if json_start >= 0:
                    brace_count = 0
                    json_end = -1
                    in_string = False
                    escape_next = False

                    for i in range(json_start, len(response)):
                        char = response[i]

                        if escape_next:
                            escape_next = False
                            continue

                        if char == '\\':
                            escape_next = True
                            continue

                        if char == '"' and not escape_next:
                            in_string = not in_string
                            continue

                        if not in_string:
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    json_end = i + 1
                                    break

                    if json_end > json_start:
                        try:
                            json_str = response[json_start:json_end]
                            result = json.loads(json_str)
                            if ENABLE_DEBUG_LOG:
                                print(f"âœ… æ–¹æ³•3æˆåŠŸ: èŠ±æ‹¬å·é…å¯¹æå–")
                        except json.JSONDecodeError as e:
                            parse_error = e
                            if ENABLE_DEBUG_LOG:
                                print(f"âš ï¸ æ–¹æ³•3å¤±è´¥ (JSONé”™è¯¯): {e}")
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•3å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æ–¹æ³•4: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON å¯¹è±¡
        if result is None:
            try:
                import re
                json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
                matches = re.findall(json_pattern, response, re.DOTALL)
                for match in matches:
                    try:
                        candidate = json.loads(match)
                        # éªŒè¯å¿…é¡»æœ‰ question å­—æ®µ
                        if isinstance(candidate, dict) and "question" in candidate:
                            result = candidate
                            if ENABLE_DEBUG_LOG:
                                print(f"âœ… æ–¹æ³•4æˆåŠŸ: æ­£åˆ™è¡¨è¾¾å¼æå–")
                            break
                    except json.JSONDecodeError:
                        continue
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•4å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æ–¹æ³•5: å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSONï¼ˆè¡¥å…¨ç¼ºå¤±å­—æ®µï¼‰
        if result is None and '{' in response and '"question"' in response:
            try:
                if ENABLE_DEBUG_LOG:
                    print(f"ğŸ”§ å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON...")

                # æ‰¾åˆ°JSONå¯¹è±¡çš„å¼€å§‹ä½ç½®
                json_start = response.find('{')
                json_content = response[json_start:]

                # å°è¯•è¡¥å…¨ç¼ºå¤±çš„ç»“å°¾éƒ¨åˆ†
                if '"options"' in json_content and '"question"' in json_content:
                    # å¦‚æœæœ‰optionsæ•°ç»„ä½†æ²¡æœ‰æ­£ç¡®ç»“æŸï¼Œå°è¯•è¡¥å…¨
                    if json_content.count('[') > json_content.count(']'):
                        json_content += ']'
                    if json_content.count('{') > json_content.count('}'):
                        # æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
                        if '"multi_select"' not in json_content:
                            json_content += ', "multi_select": false'
                        if '"is_follow_up"' not in json_content:
                            json_content += ', "is_follow_up": false'
                        json_content += '}'

                    # å°è¯•è§£æä¿®å¤åçš„JSON
                    try:
                        result = json.loads(json_content)
                        if isinstance(result, dict) and "question" in result:
                            if ENABLE_DEBUG_LOG:
                                print(f"âœ… æ–¹æ³•5æˆåŠŸ: JSONä¿®å¤å®Œæˆ")
                    except json.JSONDecodeError as e:
                        if ENABLE_DEBUG_LOG:
                            print(f"âš ï¸ æ–¹æ³•5å¤±è´¥: ä¿®å¤åä»æ— æ³•è§£æ - {e}")
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•5å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æˆåŠŸè§£æ
        if result is not None and isinstance(result, dict):
            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
            if "question" in result and "options" in result:
                result["dimension"] = dimension
                result["ai_generated"] = True
                # è¡¥å…¨å¯èƒ½ç¼ºå¤±çš„å­—æ®µ
                if "multi_select" not in result:
                    result["multi_select"] = False
                if "is_follow_up" not in result:
                    result["is_follow_up"] = False
                return jsonify(result)

        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†
        if ENABLE_DEBUG_LOG:
            print(f"âŒ æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥")
            print(f"ğŸ“„ å®Œæ•´å“åº”å†…å®¹:\n{response}")

        return jsonify({
            "error": "AI å“åº”æ ¼å¼é”™è¯¯",
            "detail": f"AI è¿”å›çš„å†…å®¹ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON æ ¼å¼æ•°æ®ã€‚æœ€åé”™è¯¯: {str(parse_error) if parse_error else 'æœªçŸ¥'}"
        }), 503

    except Exception as e:
        print(f"ç”Ÿæˆé—®é¢˜æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        error_msg = str(e)

        # æ ¹æ®å¼‚å¸¸ç±»å‹æä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
        if "connection" in error_msg.lower() or "network" in error_msg.lower():
            return jsonify({
                "error": "ç½‘ç»œè¿æ¥å¤±è´¥",
                "detail": "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
            }), 503
        elif "timeout" in error_msg.lower():
            return jsonify({
                "error": "è¯·æ±‚è¶…æ—¶",
                "detail": "AI æœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
            }), 503
        elif "authentication" in error_msg.lower() or "api key" in error_msg.lower():
            return jsonify({
                "error": "API è®¤è¯å¤±è´¥",
                "detail": "API Key æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·è”ç³»ç®¡ç†å‘˜"
            }), 503
        elif "rate limit" in error_msg.lower():
            return jsonify({
                "error": "è¯·æ±‚é¢‘ç‡è¶…é™",
                "detail": "AI æœåŠ¡è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
            }), 503
        else:
            return jsonify({
                "error": "ç”Ÿæˆé—®é¢˜å¤±è´¥",
                "detail": f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {error_msg}"
            }), 503


def get_fallback_question(session: dict, dimension: str) -> dict:
    """è·å–å¤‡ç”¨é—®é¢˜ï¼ˆæ—  AI æ—¶ä½¿ç”¨ï¼‰"""
    fallback_questions = {
        "customer_needs": [
            {"question": "æ‚¨å¸Œæœ›é€šè¿‡è¿™ä¸ªé¡¹ç›®è§£å†³å“ªäº›æ ¸å¿ƒé—®é¢˜ï¼Ÿ", "options": ["æå‡å·¥ä½œæ•ˆç‡", "é™ä½è¿è¥æˆæœ¬", "æ”¹å–„ç”¨æˆ·ä½“éªŒ", "å¢å¼ºæ•°æ®åˆ†æèƒ½åŠ›"], "multi_select": True},
            {"question": "ä¸»è¦çš„ç”¨æˆ·ç¾¤ä½“æœ‰å“ªäº›ï¼Ÿ", "options": ["å†…éƒ¨å‘˜å·¥", "å¤–éƒ¨å®¢æˆ·", "åˆä½œä¼™ä¼´", "ç®¡ç†å±‚"], "multi_select": True},
            {"question": "ç”¨æˆ·æœ€æœŸæœ›è·å¾—çš„æ ¸å¿ƒä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ", "options": ["èŠ‚çœæ—¶é—´", "å‡å°‘é”™è¯¯", "è·å–æ´å¯Ÿ", "æå‡åä½œ"], "multi_select": False},
        ],
        "business_process": [
            {"question": "å½“å‰ä¸šåŠ¡æµç¨‹ä¸­éœ€è¦ä¼˜åŒ–çš„ç¯èŠ‚æœ‰å“ªäº›ï¼Ÿ", "options": ["æ•°æ®å½•å…¥", "å®¡æ‰¹æµç¨‹", "æŠ¥è¡¨ç”Ÿæˆ", "è·¨éƒ¨é—¨åä½œ"], "multi_select": True},
            {"question": "å…³é”®ä¸šåŠ¡æµç¨‹æ¶‰åŠå“ªäº›éƒ¨é—¨ï¼Ÿ", "options": ["é”€å”®éƒ¨é—¨", "æŠ€æœ¯éƒ¨é—¨", "è´¢åŠ¡éƒ¨é—¨", "è¿è¥éƒ¨é—¨"], "multi_select": True},
            {"question": "æµç¨‹ä¸­æœ€å…³é”®çš„å†³ç­–èŠ‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ", "options": ["å®¡æ‰¹èŠ‚ç‚¹", "åˆ†é…èŠ‚ç‚¹", "éªŒæ”¶èŠ‚ç‚¹", "ç»“ç®—èŠ‚ç‚¹"], "multi_select": False},
        ],
        "tech_constraints": [
            {"question": "æœŸæœ›çš„ç³»ç»Ÿéƒ¨ç½²æ–¹å¼æ˜¯ï¼Ÿ", "options": ["å…¬æœ‰äº‘éƒ¨ç½²", "ç§æœ‰äº‘éƒ¨ç½²", "æ··åˆäº‘éƒ¨ç½²", "æœ¬åœ°éƒ¨ç½²"], "multi_select": False},
            {"question": "éœ€è¦ä¸å“ªäº›ç°æœ‰ç³»ç»Ÿé›†æˆï¼Ÿ", "options": ["ERPç³»ç»Ÿ", "CRMç³»ç»Ÿ", "OAåŠå…¬ç³»ç»Ÿ", "è´¢åŠ¡ç³»ç»Ÿ"], "multi_select": True},
            {"question": "å¯¹ç³»ç»Ÿå®‰å…¨æ€§çš„è¦æ±‚æ˜¯ï¼Ÿ", "options": ["ç­‰ä¿äºŒçº§", "ç­‰ä¿ä¸‰çº§", "åŸºç¡€å®‰å…¨å³å¯", "éœ€è¦è¯¦ç»†è¯„ä¼°"], "multi_select": False},
        ],
        "project_constraints": [
            {"question": "é¡¹ç›®çš„é¢„æœŸé¢„ç®—èŒƒå›´æ˜¯ï¼Ÿ", "options": ["10ä¸‡ä»¥å†…", "10-50ä¸‡", "50-100ä¸‡", "100ä¸‡ä»¥ä¸Š"], "multi_select": False},
            {"question": "æœŸæœ›çš„ä¸Šçº¿æ—¶é—´æ˜¯ï¼Ÿ", "options": ["1ä¸ªæœˆå†…", "1-3ä¸ªæœˆ", "3-6ä¸ªæœˆ", "6ä¸ªæœˆä»¥ä¸Š"], "multi_select": False},
            {"question": "é¡¹ç›®å›¢é˜Ÿçš„èµ„æºæƒ…å†µå¦‚ä½•ï¼Ÿ", "options": ["æœ‰ä¸“èŒå›¢é˜Ÿ", "å…¼èŒå‚ä¸", "å®Œå…¨å¤–åŒ…", "éœ€è¦è¯„ä¼°"], "multi_select": False},
        ]
    }

    # è·å–è¯¥ç»´åº¦å·²å›ç­”çš„é—®é¢˜æ•°
    answered = len([log for log in session.get("interview_log", []) if log.get("dimension") == dimension])
    questions = fallback_questions.get(dimension, [])

    if answered < len(questions):
        q = questions[answered]
        return {
            "question": q["question"],
            "options": q["options"],
            "multi_select": q.get("multi_select", False),
            "dimension": dimension,
            "ai_generated": False,
            "is_follow_up": False
        }

    # ç»´åº¦å·²å®Œæˆ
    return {
        "question": None,
        "dimension": dimension,
        "completed": True
    }


@app.route('/api/sessions/<session_id>/submit-answer', methods=['POST'])
def submit_answer(session_id):
    """æäº¤å›ç­”"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))
    data = request.get_json()

    question = data.get("question")
    answer = data.get("answer")
    dimension = data.get("dimension")
    options = data.get("options", [])

    # æ·»åŠ åˆ°è®¿è°ˆè®°å½•
    log_entry = {
        "timestamp": get_utc_now(),
        "question": question,
        "answer": answer,
        "dimension": dimension,
        "options": options
    }
    session["interview_log"].append(log_entry)

    # æ›´æ–°ç»´åº¦æ•°æ®
    if dimension and dimension in session["dimensions"]:
        session["dimensions"][dimension]["items"].append({
            "name": answer,
            "description": question,
            "priority": "ä¸­"
        })

        # è®¡ç®—è¦†ç›–åº¦ï¼ˆæ¯ä¸ªç»´åº¦ 3 ä¸ªé—®é¢˜ä¸º 100%ï¼‰
        item_count = len(session["dimensions"][dimension]["items"])
        session["dimensions"][dimension]["coverage"] = min(100, int(item_count / 3 * 100))

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify(session)


@app.route('/api/sessions/<session_id>/undo-answer', methods=['POST'])
def undo_answer(session_id):
    """æ’¤é”€æœ€åä¸€ä¸ªå›ç­”"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # æ£€æŸ¥æ˜¯å¦æœ‰å›ç­”å¯ä»¥æ’¤é”€
    if not session.get("interview_log") or len(session["interview_log"]) == 0:
        return jsonify({"error": "æ²¡æœ‰å¯æ’¤é”€çš„å›ç­”"}), 400

    # åˆ é™¤æœ€åä¸€ä¸ªå›ç­”
    last_log = session["interview_log"].pop()
    dimension = last_log.get("dimension")

    # æ›´æ–°ç»´åº¦æ•°æ®
    if dimension and dimension in session["dimensions"]:
        # åˆ é™¤æœ€åä¸€ä¸ª item
        if session["dimensions"][dimension]["items"]:
            session["dimensions"][dimension]["items"].pop()

        # é‡æ–°è®¡ç®—è¦†ç›–åº¦
        item_count = len(session["dimensions"][dimension]["items"])
        session["dimensions"][dimension]["coverage"] = min(100, int(item_count / 3 * 100))

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify(session)


# ============ æ–‡æ¡£ä¸Šä¼  API ============

@app.route('/api/sessions/<session_id>/documents', methods=['POST'])
def upload_document(session_id):
    """ä¸Šä¼ å‚è€ƒæ–‡æ¡£"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    if 'file' not in request.files:
        return jsonify({"error": "æœªæ‰¾åˆ°æ–‡ä»¶"}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400

    filename = file.filename
    filepath = TEMP_DIR / filename
    file.save(filepath)

    # è¯»å–æ–‡ä»¶å†…å®¹
    ext = Path(filename).suffix.lower()
    content = ""

    if ext in ['.md', '.txt']:
        content = filepath.read_text(encoding="utf-8")
    elif ext == '.pdf':
        content = f"[PDF æ–‡ä»¶: {filename}]"  # ç®€åŒ–å¤„ç†
    elif ext in ['.docx', '.xlsx', '.pptx']:
        # è°ƒç”¨è½¬æ¢è„šæœ¬
        import subprocess
        convert_script = SKILL_DIR / "scripts" / "convert_doc.py"
        if convert_script.exists():
            try:
                result = subprocess.run(
                    ["uv", "run", str(convert_script), "convert", str(filepath)],
                    capture_output=True, text=True, cwd=str(SKILL_DIR)
                )
                if result.returncode == 0:
                    converted_file = CONVERTED_DIR / f"{Path(filename).stem}.md"
                    if converted_file.exists():
                        content = converted_file.read_text(encoding="utf-8")
            except Exception as e:
                print(f"è½¬æ¢æ–‡æ¡£å¤±è´¥: {e}")

    # æ›´æ–°ä¼šè¯
    session = json.loads(session_file.read_text(encoding="utf-8"))
    session["reference_docs"].append({
        "name": filename,
        "type": ext,
        "content": content[:10000],  # é™åˆ¶é•¿åº¦
        "uploaded_at": get_utc_now()
    })
    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify({
        "success": True,
        "filename": filename,
        "content_length": len(content)
    })


@app.route('/api/sessions/<session_id>/documents/<path:doc_name>', methods=['DELETE'])
def delete_document(session_id, doc_name):
    """åˆ é™¤å‚è€ƒæ–‡æ¡£"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # æŸ¥æ‰¾å¹¶åˆ é™¤æ–‡æ¡£
    original_count = len(session["reference_docs"])
    session["reference_docs"] = [
        doc for doc in session["reference_docs"]
        if doc["name"] != doc_name
    ]

    if len(session["reference_docs"]) == original_count:
        return jsonify({"error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    # æ³¨æ„ï¼šä¸åˆ é™¤åå°æ–‡ä»¶å­˜æ¡£ï¼Œä»…ä»ä¼šè¯ä¸­ç§»é™¤å¼•ç”¨
    # è¿™æ ·æ–‡ä»¶ä»ä¿ç•™åœ¨ temp/ å’Œ converted/ ç›®å½•ä¸­ä¾›åç»­ä½¿ç”¨

    return jsonify({
        "success": True,
        "deleted": doc_name
    })


# ============ æŠ¥å‘Šç”Ÿæˆ API ============

@app.route('/api/sessions/<session_id>/generate-report', methods=['POST'])
def generate_report(session_id):
    """ç”Ÿæˆè°ƒç ”æŠ¥å‘Šï¼ˆAI ç”Ÿæˆï¼‰"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # æ£€æŸ¥æ˜¯å¦æœ‰ Claude API
    if claude_client:
        prompt = build_report_prompt(session)
        report_content = call_claude(prompt, max_tokens=MAX_TOKENS_REPORT)

        if report_content:
            # è¿½åŠ å®Œæ•´çš„è®¿è°ˆè®°å½•é™„å½•ï¼ˆç¡®ä¿é™„å½•å®Œæ•´ï¼‰
            appendix = generate_interview_appendix(session)
            report_content = report_content + appendix

            # ä¿å­˜æŠ¥å‘Š
            topic_slug = session.get("topic", "report").replace(" ", "-")[:30]
            date_str = datetime.now().strftime("%Y%m%d")
            filename = f"deep-vision-{date_str}-{topic_slug}.md"
            report_file = REPORTS_DIR / filename
            report_file.write_text(report_content, encoding="utf-8")

            # æ›´æ–°ä¼šè¯çŠ¶æ€
            session["status"] = "completed"
            session["updated_at"] = get_utc_now()
            session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

            return jsonify({
                "success": True,
                "report_path": str(report_file),
                "report_name": filename,
                "ai_generated": True
            })

    # å›é€€åˆ°ç®€å•æŠ¥å‘Šç”Ÿæˆ
    report_content = generate_simple_report(session)
    topic_slug = session.get("topic", "report").replace(" ", "-")[:30]
    date_str = datetime.now().strftime("%Y%m%d")
    filename = f"deep-vision-{date_str}-{topic_slug}.md"
    report_file = REPORTS_DIR / filename
    report_file.write_text(report_content, encoding="utf-8")

    session["status"] = "completed"
    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify({
        "success": True,
        "report_path": str(report_file),
        "report_name": filename,
        "ai_generated": False
    })


def generate_interview_appendix(session: dict) -> str:
    """ç”Ÿæˆå®Œæ•´çš„è®¿è°ˆè®°å½•é™„å½•"""
    interview_log = session.get("interview_log", [])
    if not interview_log:
        return ""

    appendix = "\n\n---\n\n## é™„å½•ï¼šå®Œæ•´è®¿è°ˆè®°å½•\n\n"
    appendix += f"> æœ¬æ¬¡è°ƒç ”å…±æ”¶é›†äº† {len(interview_log)} ä¸ªé—®é¢˜çš„å›ç­”\n\n"

    for i, log in enumerate(interview_log, 1):
        dim_name = DIMENSION_INFO.get(log.get('dimension', ''), {}).get('name', 'æœªåˆ†ç±»')
        appendix += f"### Q{i}: {log['question']}\n\n"
        appendix += f"**å›ç­”**: {log['answer']}\n\n"
        appendix += f"**ç»´åº¦**: {dim_name}\n\n"
        if log.get('timestamp'):
            appendix += f"*è®°å½•æ—¶é—´: {log['timestamp']}*\n\n"
        appendix += "---\n\n"

    return appendix


def generate_simple_report(session: dict) -> str:
    """ç”Ÿæˆç®€å•æŠ¥å‘Šï¼ˆæ—  AI æ—¶ä½¿ç”¨ï¼‰"""
    topic = session.get("topic", "æœªå‘½åé¡¹ç›®")
    interview_log = session.get("interview_log", [])
    now = datetime.now()

    content = f"""# {topic} éœ€æ±‚è°ƒç ”æŠ¥å‘Š

**è°ƒç ”æ—¥æœŸ**: {now.strftime('%Y-%m-%d')}
**æŠ¥å‘Šç¼–å·**: deep-vision-{now.strftime('%Y%m%d')}

---

## 1. è°ƒç ”æ¦‚è¿°

æœ¬æ¬¡è°ƒç ”ä¸»é¢˜ä¸ºã€Œ{topic}ã€ï¼Œå…±æ”¶é›†äº† {len(interview_log)} ä¸ªé—®é¢˜çš„å›ç­”ã€‚

## 2. éœ€æ±‚æ‘˜è¦

"""

    for dim_key, dim_info in DIMENSION_INFO.items():
        content += f"### {dim_info['name']}\n\n"
        logs = [log for log in interview_log if log.get("dimension") == dim_key]
        if logs:
            for log in logs:
                content += f"- **{log['answer']}** - {log['question']}\n"
        else:
            content += "*æš‚æ— æ•°æ®*\n"
        content += "\n"

    # ä½¿ç”¨ç»Ÿä¸€çš„é™„å½•ç”Ÿæˆå‡½æ•°ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
    content += generate_interview_appendix(session)

    content += """
*æ­¤æŠ¥å‘Šç”± Deep Vision æ·±ç³-æ™ºèƒ½éœ€æ±‚è°ƒç ”åŠ©æ‰‹ç”Ÿæˆ*
"""

    return content


# ============ æŠ¥å‘Š API ============

@app.route('/api/reports', methods=['GET'])
def list_reports():
    """è·å–æ‰€æœ‰æŠ¥å‘Šï¼ˆæ’é™¤å·²åˆ é™¤çš„ï¼‰"""
    deleted = get_deleted_reports()
    reports = []
    for f in REPORTS_DIR.glob("*.md"):
        # è·³è¿‡å·²æ ‡è®°ä¸ºåˆ é™¤çš„æŠ¥å‘Š
        if f.name in deleted:
            continue
        stat = f.stat()
        reports.append({
            "name": f.name,
            "path": str(f),
            "size": stat.st_size,
            "created_at": datetime.fromtimestamp(stat.st_mtime).isoformat()
        })

    reports.sort(key=lambda x: x["created_at"], reverse=True)
    return jsonify(reports)


@app.route('/api/reports/<path:filename>', methods=['GET'])
def get_report(filename):
    """è·å–æŠ¥å‘Šå†…å®¹"""
    report_file = REPORTS_DIR / filename
    if not report_file.exists():
        return jsonify({"error": "æŠ¥å‘Šä¸å­˜åœ¨"}), 404

    content = report_file.read_text(encoding="utf-8")
    return jsonify({"name": filename, "content": content})


@app.route('/api/reports/<path:filename>', methods=['DELETE'])
def delete_report(filename):
    """åˆ é™¤æŠ¥å‘Šï¼ˆä»…æ ‡è®°ä¸ºå·²åˆ é™¤ï¼Œä¿ç•™æ–‡ä»¶å­˜æ¡£ï¼‰"""
    report_file = REPORTS_DIR / filename
    if not report_file.exists():
        return jsonify({"error": "æŠ¥å‘Šä¸å­˜åœ¨"}), 404

    try:
        # åªæ ‡è®°ä¸ºå·²åˆ é™¤ï¼Œä¸çœŸæ­£åˆ é™¤æ–‡ä»¶
        mark_report_as_deleted(filename)
        return jsonify({
            "message": "æŠ¥å‘Šå·²ä»åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆæ–‡ä»¶å·²å­˜æ¡£ï¼‰",
            "name": filename
        })
    except Exception as e:
        return jsonify({"error": f"æ ‡è®°åˆ é™¤å¤±è´¥: {str(e)}"}), 500


# ============ çŠ¶æ€ API ============

@app.route('/api/status', methods=['GET'])
def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    return jsonify({
        "status": "running",
        "ai_available": claude_client is not None,
        "model": MODEL_NAME if claude_client else None,
        "sessions_dir": str(SESSIONS_DIR),
        "reports_dir": str(REPORTS_DIR)
    })


@app.route('/api/status/web-search', methods=['GET'])
def get_web_search_status():
    """è·å– Web Search API è°ƒç”¨çŠ¶æ€ï¼ˆç”¨äºå‰ç«¯å‘¼å¸ç¯æ•ˆæœï¼‰"""
    return jsonify({
        "active": web_search_active
    })


if __name__ == '__main__':
    print("=" * 60)
    print("Deep Vision Web Server - AI é©±åŠ¨ç‰ˆæœ¬")
    print("=" * 60)
    print(f"Sessions: {SESSIONS_DIR}")
    print(f"Reports: {REPORTS_DIR}")
    print(f"AI çŠ¶æ€: {'å·²å¯ç”¨' if claude_client else 'æœªå¯ç”¨'}")
    if claude_client:
        print(f"æ¨¡å‹: {MODEL_NAME}")

    # æœç´¢åŠŸèƒ½çŠ¶æ€
    search_enabled = ENABLE_WEB_SEARCH and ZHIPU_API_KEY and ZHIPU_API_KEY != "your-zhipu-api-key-here"
    print(f"è”ç½‘æœç´¢: {'âœ… å·²å¯ç”¨ (æ™ºè°±AI MCP)' if search_enabled else 'âš ï¸  æœªå¯ç”¨'}")
    if not search_enabled and ENABLE_WEB_SEARCH:
        print("   æç¤º: é…ç½® ZHIPU_API_KEY ä»¥å¯ç”¨è”ç½‘æœç´¢åŠŸèƒ½")

    print()
    print(f"è®¿é—®: http://localhost:{SERVER_PORT}")
    print("=" * 60)
    app.run(host=SERVER_HOST, port=SERVER_PORT, debug=DEBUG_MODE)
