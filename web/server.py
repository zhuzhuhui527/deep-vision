#!/usr/bin/env python3
# /// script
# requires-python = ">=3.10"
# dependencies = ["flask", "flask-cors", "anthropic", "requests"]
# ///
"""
Deep Vision Web Server - AI é©±åŠ¨ç‰ˆæœ¬

å®Œæ•´å®ç° deep-vision æŠ€èƒ½çš„æ‰€æœ‰åŠŸèƒ½ï¼š
- åŠ¨æ€ç”Ÿæˆé—®é¢˜å’Œé€‰é¡¹ï¼ˆåŸºäºä¸Šä¸‹æ–‡å’Œè¡Œä¸šçŸ¥è¯†ï¼‰
- æ™ºèƒ½è¿½é—®ï¼ˆè¯†åˆ«è¡¨é¢éœ€æ±‚ï¼ŒæŒ–æ˜æœ¬è´¨ï¼‰
- å†²çªæ£€æµ‹ï¼ˆæ£€æµ‹å›ç­”ä¸å‚è€ƒæ–‡æ¡£çš„å†²çªï¼‰
- çŸ¥è¯†å¢å¼ºï¼ˆä¸“ä¸šé¢†åŸŸä¿¡æ¯èå…¥é€‰é¡¹ï¼‰
- ç”Ÿæˆä¸“ä¸šè°ƒç ”æŠ¥å‘Š
"""

import json
import os
import secrets
import requests
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

from flask import Flask, jsonify, request, send_from_directory
from flask_cors import CORS

# åŠ è½½é…ç½®æ–‡ä»¶
try:
    from config import (
        ANTHROPIC_API_KEY,
        ANTHROPIC_BASE_URL,
        MODEL_NAME,
        MAX_TOKENS_DEFAULT,
        MAX_TOKENS_QUESTION,
        MAX_TOKENS_REPORT,
        SERVER_HOST,
        SERVER_PORT,
        DEBUG_MODE,
        ENABLE_AI,
        ENABLE_DEBUG_LOG,
        ENABLE_WEB_SEARCH,
        ZHIPU_API_KEY,
        ZHIPU_SEARCH_ENGINE,
        SEARCH_MAX_RESULTS,
        SEARCH_TIMEOUT
    )
    print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
except ImportError:
    print("âš ï¸  æœªæ‰¾åˆ° config.pyï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    print("   è¯·å¤åˆ¶ config.example.py ä¸º config.py å¹¶å¡«å…¥å®é™…é…ç½®")
    # é»˜è®¤é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
    ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY", "")
    ANTHROPIC_BASE_URL = os.environ.get("ANTHROPIC_BASE_URL", "")
    ZHIPU_API_KEY = os.environ.get("ZHIPU_API_KEY", "")
    MODEL_NAME = os.environ.get("MODEL_NAME", "")
    MAX_TOKENS_DEFAULT = 2000
    MAX_TOKENS_QUESTION = 800
    MAX_TOKENS_REPORT = 4000
    SERVER_HOST = "0.0.0.0"
    SERVER_PORT = 5001
    DEBUG_MODE = True
    ENABLE_AI = True
    ENABLE_DEBUG_LOG = True
    ENABLE_WEB_SEARCH = False
    ZHIPU_API_KEY = ""
    ZHIPU_SEARCH_ENGINE = "search_pro"
    SEARCH_MAX_RESULTS = 3
    SEARCH_TIMEOUT = 10

try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False
    print("è­¦å‘Š: anthropic åº“æœªå®‰è£…ï¼Œå°†æ— æ³•ä½¿ç”¨ AI åŠŸèƒ½")

app = Flask(__name__, static_folder='.')
CORS(app)

# è·¯å¾„é…ç½®
SKILL_DIR = Path(__file__).parent.parent.resolve()
DATA_DIR = SKILL_DIR / "data"
SESSIONS_DIR = DATA_DIR / "sessions"
REPORTS_DIR = DATA_DIR / "reports"
CONVERTED_DIR = DATA_DIR / "converted"
TEMP_DIR = DATA_DIR / "temp"
METRICS_DIR = DATA_DIR / "metrics"
SUMMARIES_DIR = DATA_DIR / "summaries"  # æ–‡æ¡£æ‘˜è¦ç¼“å­˜ç›®å½•
DELETED_REPORTS_FILE = REPORTS_DIR / ".deleted_reports.json"

for d in [SESSIONS_DIR, REPORTS_DIR, CONVERTED_DIR, TEMP_DIR, METRICS_DIR, SUMMARIES_DIR]:
    d.mkdir(parents=True, exist_ok=True)

# Web Search çŠ¶æ€è¿½è¸ªï¼ˆç”¨äºå‰ç«¯å‘¼å¸ç¯æ•ˆæœï¼‰
web_search_active = False


# ============ æ€§èƒ½ç›‘æ§ç³»ç»Ÿ ============

class MetricsCollector:
    """API æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, metrics_file: Path):
        self.metrics_file = metrics_file
        self._ensure_metrics_file()

    def _ensure_metrics_file(self):
        """ç¡®ä¿æŒ‡æ ‡æ–‡ä»¶å­˜åœ¨"""
        if not self.metrics_file.exists():
            self.metrics_file.write_text(json.dumps({
                "calls": [],
                "summary": {
                    "total_calls": 0,
                    "total_timeouts": 0,
                    "total_truncations": 0,
                    "avg_response_time": 0,
                    "avg_prompt_length": 0
                }
            }, ensure_ascii=False, indent=2), encoding="utf-8")

    def record_api_call(self, call_type: str, prompt_length: int, response_time: float,
                       success: bool, timeout: bool = False, error_msg: str = None,
                       truncated_docs: list = None, max_tokens: int = None):
        """è®°å½• API è°ƒç”¨æŒ‡æ ‡"""
        try:
            # è¯»å–ç°æœ‰æ•°æ®
            data = json.loads(self.metrics_file.read_text(encoding="utf-8"))

            # æ·»åŠ æ–°è®°å½•
            call_record = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "type": call_type,  # "question" or "report"
                "prompt_length": prompt_length,
                "response_time_ms": round(response_time * 1000, 2),
                "max_tokens": max_tokens,
                "success": success,
                "timeout": timeout,
                "error": error_msg,
                "truncated_docs": truncated_docs or []
            }

            data["calls"].append(call_record)

            # æ›´æ–°æ±‡æ€»ç»Ÿè®¡
            summary = data["summary"]
            summary["total_calls"] = summary.get("total_calls", 0) + 1
            if timeout:
                summary["total_timeouts"] = summary.get("total_timeouts", 0) + 1
            if truncated_docs:
                summary["total_truncations"] = summary.get("total_truncations", 0) + len(truncated_docs)

            # è®¡ç®—å¹³å‡å€¼
            all_calls = data["calls"]
            if all_calls:
                summary["avg_response_time"] = round(
                    sum(c["response_time_ms"] for c in all_calls) / len(all_calls), 2
                )
                summary["avg_prompt_length"] = round(
                    sum(c["prompt_length"] for c in all_calls) / len(all_calls), 2
                )

            # ä¿å­˜ï¼ˆåªä¿ç•™æœ€è¿‘ 1000 æ¡è®°å½•ï¼‰
            if len(data["calls"]) > 1000:
                data["calls"] = data["calls"][-1000:]

            self.metrics_file.write_text(
                json.dumps(data, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )

        except Exception as e:
            print(f"âš ï¸  è®°å½•æŒ‡æ ‡å¤±è´¥: {e}")

    def get_statistics(self, last_n: int = None) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            data = json.loads(self.metrics_file.read_text(encoding="utf-8"))
            calls = data["calls"]

            if last_n:
                calls = calls[-last_n:]

            if not calls:
                return {
                    "total_calls": 0,
                    "message": "æš‚æ— æ•°æ®"
                }

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_calls = len(calls)
            successful_calls = sum(1 for c in calls if c["success"])
            timeout_calls = sum(1 for c in calls if c.get("timeout", False))
            truncation_events = sum(len(c.get("truncated_docs", [])) for c in calls)

            response_times = [c["response_time_ms"] for c in calls if c["success"]]
            prompt_lengths = [c["prompt_length"] for c in calls]

            stats = {
                "period": f"æœ€è¿‘ {last_n} æ¬¡è°ƒç”¨" if last_n else "å…¨éƒ¨è°ƒç”¨",
                "total_calls": total_calls,
                "successful_calls": successful_calls,
                "failed_calls": total_calls - successful_calls,
                "timeout_calls": timeout_calls,
                "timeout_rate": round(timeout_calls / total_calls * 100, 2) if total_calls > 0 else 0,
                "truncation_events": truncation_events,
                "truncation_rate": round(truncation_events / total_calls * 100, 2) if total_calls > 0 else 0,
                "avg_response_time_ms": round(sum(response_times) / len(response_times), 2) if response_times else 0,
                "max_response_time_ms": round(max(response_times), 2) if response_times else 0,
                "min_response_time_ms": round(min(response_times), 2) if response_times else 0,
                "avg_prompt_length": round(sum(prompt_lengths) / len(prompt_lengths), 2) if prompt_lengths else 0,
                "max_prompt_length": max(prompt_lengths) if prompt_lengths else 0,
            }

            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            stats["recommendations"] = self._generate_recommendations(stats)

            return stats

        except Exception as e:
            return {"error": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}"}

    def _generate_recommendations(self, stats: dict) -> list:
        """åŸºäºç»Ÿè®¡æ•°æ®ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # è¶…æ—¶ç‡è¿‡é«˜
        if stats["timeout_rate"] > 10:
            recommendations.append({
                "level": "critical",
                "message": f"è¶…æ—¶ç‡è¿‡é«˜ ({stats['timeout_rate']}%)ï¼Œå»ºè®®å‡å°‘æ–‡æ¡£é•¿åº¦é™åˆ¶æˆ–å®æ–½æ™ºèƒ½æ‘˜è¦"
            })
        elif stats["timeout_rate"] > 5:
            recommendations.append({
                "level": "warning",
                "message": f"è¶…æ—¶ç‡åé«˜ ({stats['timeout_rate']}%)ï¼Œéœ€è¦å…³æ³¨"
            })

        # æˆªæ–­ç‡è¿‡é«˜
        if stats["truncation_rate"] > 50:
            recommendations.append({
                "level": "warning",
                "message": f"æ–‡æ¡£æˆªæ–­é¢‘ç¹ ({stats['truncation_rate']}%)ï¼Œå»ºè®®å®æ–½æ™ºèƒ½æ‘˜è¦åŠŸèƒ½"
            })

        # Prompt è¿‡é•¿
        if stats["avg_prompt_length"] > 8000:
            recommendations.append({
                "level": "warning",
                "message": f"å¹³å‡ Prompt é•¿åº¦è¾ƒå¤§ ({stats['avg_prompt_length']} å­—ç¬¦)ï¼Œå¯èƒ½å½±å“å“åº”é€Ÿåº¦"
            })

        # å“åº”æ—¶é—´è¿‡é•¿
        if stats["avg_response_time_ms"] > 60000:
            recommendations.append({
                "level": "warning",
                "message": f"å¹³å‡å“åº”æ—¶é—´è¾ƒé•¿ ({stats['avg_response_time_ms']/1000:.1f} ç§’)ï¼Œå»ºè®®ä¼˜åŒ– Prompt é•¿åº¦"
            })

        # ä¸€åˆ‡æ­£å¸¸
        if not recommendations:
            if stats["timeout_rate"] < 5 and stats["truncation_rate"] < 30:
                recommendations.append({
                    "level": "info",
                    "message": "ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå¯è€ƒè™‘é€‚åº¦å¢åŠ æ–‡æ¡£é•¿åº¦é™åˆ¶ä»¥æå‡è´¨é‡"
                })

        return recommendations


# åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨
metrics_collector = MetricsCollector(METRICS_DIR / "api_metrics.json")

# Claude å®¢æˆ·ç«¯åˆå§‹åŒ–
claude_client = None

# æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆ
def is_valid_api_key(api_key: str) -> bool:
    """æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯é»˜è®¤å ä½ç¬¦ï¼‰"""
    if not api_key:
        return False
    placeholder_patterns = [
        "your-", "your_", "example", "test", "placeholder",
        "api-key", "apikey", "YOUR-", "YOUR_"
    ]
    api_key_lower = api_key.lower()
    for pattern in placeholder_patterns:
        if pattern in api_key_lower:
            return False
    return True

# æ£€æŸ¥é…ç½®
api_key_valid = is_valid_api_key(ANTHROPIC_API_KEY)
base_url_valid = ANTHROPIC_BASE_URL and ANTHROPIC_BASE_URL != "https://api.anthropic.com" or api_key_valid

if not api_key_valid:
    print("âš ï¸  ANTHROPIC_API_KEY æœªé…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼")
    print("   è¯·åœ¨ config.py ä¸­å¡«å…¥æœ‰æ•ˆçš„ API Key")
    ENABLE_AI = False

if not base_url_valid and not ANTHROPIC_BASE_URL:
    print("âš ï¸  ANTHROPIC_BASE_URL æœªé…ç½®")
    print("   è¯·åœ¨ config.py ä¸­å¡«å…¥æœ‰æ•ˆçš„ Base URL")

if ENABLE_AI and HAS_ANTHROPIC and api_key_valid:
    try:
        claude_client = anthropic.Anthropic(
            api_key=ANTHROPIC_API_KEY,
            base_url=ANTHROPIC_BASE_URL
        )
        print(f"âœ… Claude å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
        print(f"   æ¨¡å‹: {MODEL_NAME}")
        print(f"   Base URL: {ANTHROPIC_BASE_URL}")

        # æµ‹è¯• API è¿æ¥
        try:
            test_response = claude_client.messages.create(
                model=MODEL_NAME,
                max_tokens=5,
                messages=[{"role": "user", "content": "Hi"}]
            )
            print(f"âœ… API è¿æ¥æµ‹è¯•æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸  API è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            print("   è¯·æ£€æŸ¥ API Key å’Œ Base URL æ˜¯å¦æ­£ç¡®")
            claude_client = None
    except Exception as e:
        print(f"âŒ Claude å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        claude_client = None
    except Exception as e:
        print(f"âŒ Claude å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
else:
    if not ENABLE_AI:
        print("â„¹ï¸  AI åŠŸèƒ½å·²ç¦ç”¨ï¼ˆENABLE_AI=Falseï¼‰")
    elif not HAS_ANTHROPIC:
        print("âŒ anthropic åº“æœªå®‰è£…")
    elif not ANTHROPIC_API_KEY:
        print("âŒ æœªé…ç½® ANTHROPIC_API_KEY")


def get_utc_now() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def generate_session_id() -> str:
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    random_suffix = secrets.token_hex(4)
    return f"dv-{timestamp}-{random_suffix}"


def get_deleted_reports() -> set:
    """è·å–å·²åˆ é™¤æŠ¥å‘Šçš„åˆ—è¡¨"""
    if not DELETED_REPORTS_FILE.exists():
        return set()
    try:
        data = json.loads(DELETED_REPORTS_FILE.read_text(encoding="utf-8"))
        return set(data.get("deleted", []))
    except Exception:
        return set()


def mark_report_as_deleted(filename: str):
    """æ ‡è®°æŠ¥å‘Šä¸ºå·²åˆ é™¤ï¼ˆä¸çœŸæ­£åˆ é™¤æ–‡ä»¶ï¼‰"""
    deleted = get_deleted_reports()
    deleted.add(filename)
    DELETED_REPORTS_FILE.write_text(
        json.dumps({"deleted": list(deleted)}, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )


# ============ è”ç½‘æœç´¢åŠŸèƒ½ ============

class MCPClient:
    """æ™ºè°±AI MCPå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url
        self.session_id = None
        self.message_id = 0

    def _get_next_id(self):
        """è·å–ä¸‹ä¸€ä¸ªæ¶ˆæ¯ID"""
        self.message_id += 1
        return self.message_id

    def _make_request(self, method: str, params: dict = None):
        """å‘é€MCP JSON-RPCè¯·æ±‚"""
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }

        # å¦‚æœæœ‰session_idï¼Œæ·»åŠ åˆ°header
        if self.session_id:
            headers["Mcp-Session-Id"] = self.session_id

        # åœ¨URLä¸­æ·»åŠ Authorizationå‚æ•°
        url = f"{self.base_url}?Authorization={self.api_key}"

        request_data = {
            "jsonrpc": "2.0",
            "id": self._get_next_id(),
            "method": method,
            "params": params or {}
        }

        if ENABLE_DEBUG_LOG:
            print(f"ğŸ“¤ MCPè¯·æ±‚: {method}")
            print(f"   å‚æ•°: {params}")

        response = requests.post(url, json=request_data, headers=headers, timeout=SEARCH_TIMEOUT)
        response.raise_for_status()

        # æ£€æŸ¥å“åº”å¤´ä¸­çš„Session ID
        if "Mcp-Session-Id" in response.headers:
            self.session_id = response.headers["Mcp-Session-Id"]
            if ENABLE_DEBUG_LOG:
                print(f"   ğŸ“ è·å¾—Session ID: {self.session_id}")

        # è§£æSSEæ ¼å¼çš„å“åº”
        response_text = response.text.strip()

        # SSEæ ¼å¼: id:1\nevent:message\ndata:{json}\n\n
        result_data = None
        for line in response_text.split('\n'):
            line = line.strip()
            if line.startswith('data:'):
                json_str = line[5:].strip()  # å»æ‰ "data:" å‰ç¼€
                try:
                    result_data = json.loads(json_str)
                    break
                except:
                    continue

        if not result_data:
            raise Exception(f"æ— æ³•è§£æSSEå“åº”: {response_text[:200]}")

        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "error" in result_data:
            raise Exception(f"MCPé”™è¯¯: {result_data['error']}")

        return result_data.get("result", {})

    def initialize(self):
        """åˆå§‹åŒ–MCPè¿æ¥"""
        try:
            result = self._make_request("initialize", {
                "protocolVersion": "2024-11-05",
                "capabilities": {},
                "clientInfo": {
                    "name": "deep-vision",
                    "version": "1.0.0"
                }
            })
            if ENABLE_DEBUG_LOG:
                print(f"âœ… MCPåˆå§‹åŒ–æˆåŠŸ")
            return result
        except Exception as e:
            if ENABLE_DEBUG_LOG:
                print(f"âŒ MCPåˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def call_tool(self, tool_name: str, arguments: dict):
        """è°ƒç”¨MCPå·¥å…·"""
        try:
            # ç¡®ä¿å·²åˆå§‹åŒ–
            if not self.session_id:
                self.initialize()

            result = self._make_request("tools/call", {
                "name": tool_name,
                "arguments": arguments
            })

            return result
        except Exception as e:
            if ENABLE_DEBUG_LOG:
                print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            raise


def web_search(query: str) -> list:
    """ä½¿ç”¨æ™ºè°±AI MCP web_search_prime è¿›è¡Œè”ç½‘æœç´¢"""
    global web_search_active

    if not ENABLE_WEB_SEARCH or not ZHIPU_API_KEY or ZHIPU_API_KEY == "your-zhipu-api-key-here":
        if ENABLE_DEBUG_LOG:
            print(f"âš ï¸  æœç´¢åŠŸèƒ½æœªå¯ç”¨æˆ– API Key æœªé…ç½®ï¼Œè·³è¿‡æœç´¢: {query}")
        return []

    try:
        # è®¾ç½®æœç´¢çŠ¶æ€ä¸ºæ´»åŠ¨
        web_search_active = True

        mcp_url = "https://open.bigmodel.cn/api/mcp/web_search_prime/mcp"

        if ENABLE_DEBUG_LOG:
            print(f"ğŸ” å¼€å§‹MCPæœç´¢: {query}")

        # åˆ›å»ºMCPå®¢æˆ·ç«¯
        client = MCPClient(ZHIPU_API_KEY, mcp_url)

        # è°ƒç”¨webSearchPrimeå·¥å…·ï¼ˆæ³¨æ„ï¼šå·¥å…·åæ˜¯é©¼å³°å‘½åï¼‰
        result = client.call_tool("webSearchPrime", {
            "search_query": query,
            "search_recency_filter": "noLimit",
            "content_size": "medium"
        })

        # è§£æç»“æœ
        results = []

        # MCPè¿”å›çš„contentæ˜¯ä¸€ä¸ªåˆ—è¡¨
        content_list = result.get("content", [])

        for item in content_list:
            if item.get("type") == "text":
                # æ–‡æœ¬å†…å®¹
                text = item.get("text", "")

                # å°è¯•è§£æJSONæ ¼å¼çš„æœç´¢ç»“æœ
                try:
                    import json as json_module

                    # ç¬¬ä¸€æ¬¡è§£æï¼šå»æ‰å¤–å±‚å¼•å·å’Œè½¬ä¹‰
                    if text.startswith('"') and text.endswith('"'):
                        text = json_module.loads(text)

                    # ç¬¬äºŒæ¬¡è§£æï¼šè·å–å®é™…çš„æœç´¢ç»“æœæ•°ç»„
                    search_data = json_module.loads(text)

                    # å¦‚æœæ˜¯åˆ—è¡¨å½¢å¼çš„æœç´¢ç»“æœ
                    if isinstance(search_data, list):
                        for entry in search_data[:SEARCH_MAX_RESULTS]:
                            title = entry.get("title", "")
                            content = entry.get("content", "")
                            url = entry.get("link", entry.get("url", ""))

                            if title or content:  # ç¡®ä¿æœ‰å®é™…å†…å®¹
                                results.append({
                                    "type": "result",
                                    "title": title[:100] if title else "æœç´¢ç»“æœ",
                                    "content": content[:300],
                                    "url": url
                                })
                    # å¦‚æœæ˜¯å•ä¸ªç»“æœ
                    elif isinstance(search_data, dict):
                        title = search_data.get("title", "")
                        content = search_data.get("content", text[:300])
                        url = search_data.get("link", search_data.get("url", ""))

                        results.append({
                            "type": "result",
                            "title": title[:100] if title else "æœç´¢ç»“æœ",
                            "content": content[:300],
                            "url": url
                        })
                except Exception as parse_error:
                    if ENABLE_DEBUG_LOG:
                        print(f"âš ï¸  è§£ææœç´¢ç»“æœå¤±è´¥: {parse_error}")
                        print(f"   åŸå§‹æ–‡æœ¬å‰200å­—ç¬¦: {text[:200]}")
                    # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½œä¸ºæ–‡æœ¬ç»“æœ
                    results.append({
                        "type": "result",
                        "title": "æœç´¢ç»“æœ",
                        "content": text[:300],
                        "url": ""
                    })

        if ENABLE_DEBUG_LOG:
            print(f"âœ… MCPæœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœ")

        # æœç´¢å®Œæˆï¼Œé‡ç½®çŠ¶æ€
        web_search_active = False
        return results

    except requests.exceptions.Timeout:
        print(f"â±ï¸  æœç´¢è¶…æ—¶: {query}")
        web_search_active = False
        return []
    except Exception as e:
        print(f"âŒ MCPæœç´¢å¤±è´¥: {e}")
        if ENABLE_DEBUG_LOG:
            import traceback
            traceback.print_exc()
        web_search_active = False
        return []


def should_search(topic: str, dimension: str, context: dict) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œè”ç½‘æœç´¢"""
    if not ENABLE_WEB_SEARCH:
        return False

    # æŠ€æœ¯å…³é”®è¯
    tech_keywords = [
        "æŠ€æœ¯", "ç³»ç»Ÿ", "å¹³å°", "æ¡†æ¶", "å·¥å…·", "è½¯ä»¶", "åº”ç”¨",
        "AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "å¤§æ¨¡å‹",
        "äº‘", "SaaS", "PaaS", "å¾®æœåŠ¡", "å®¹å™¨", "Docker", "K8s",
        "æ•°æ®åº“", "ä¸­é—´ä»¶", "API", "é›†æˆ", "éƒ¨ç½²"
    ]

    # è¡Œä¸šå…³é”®è¯
    industry_keywords = [
        "è¡Œä¸š", "æ ‡å‡†", "è§„èŒƒ", "åˆè§„", "è®¤è¯", "ç­‰ä¿",
        "å¸‚åœº", "è¶‹åŠ¿", "æœ€æ–°", "ç°çŠ¶", "å‘å±•"
    ]

    # æ—¶é—´æ•æ„Ÿå…³é”®è¯
    time_keywords = [
        "æœ€æ–°", "å½“å‰", "ç°åœ¨", "2024", "2025", "2026",
        "è¶‹åŠ¿", "æœªæ¥", "å‘å±•"
    ]

    topic_lower = topic.lower()
    all_keywords = tech_keywords + industry_keywords + time_keywords

    # å¦‚æœä¸»é¢˜åŒ…å«å…³é”®è¯ï¼Œå¯èƒ½éœ€è¦æœç´¢
    for keyword in all_keywords:
        if keyword in topic:
            return True

    # æŠ€æœ¯çº¦æŸç»´åº¦æ›´å¯èƒ½éœ€è¦æœç´¢
    if dimension == "tech_constraints":
        return True

    return False


def generate_search_query(topic: str, dimension: str, context: dict) -> str:
    """ç”Ÿæˆæœç´¢æŸ¥è¯¢"""
    dim_info = DIMENSION_INFO.get(dimension, {})
    dim_name = dim_info.get("name", dimension)

    # æ„å»ºæœç´¢æŸ¥è¯¢
    if dimension == "tech_constraints":
        return f"{topic} æŠ€æœ¯é€‰å‹ æœ€ä½³å®è·µ 2026"
    elif dimension == "customer_needs":
        return f"{topic} ç”¨æˆ·éœ€æ±‚ è¡Œä¸šç—›ç‚¹ 2026"
    elif dimension == "business_process":
        return f"{topic} ä¸šåŠ¡æµç¨‹ æœ€ä½³å®è·µ"
    elif dimension == "project_constraints":
        return f"{topic} é¡¹ç›®å®æ–½ æˆæœ¬é¢„ç®— å‘¨æœŸ"
    else:
        return f"{topic} {dim_name}"


# ============ Deep Vision AI æ ¸å¿ƒé€»è¾‘ ============

DIMENSION_INFO = {
    "customer_needs": {
        "name": "å®¢æˆ·éœ€æ±‚",
        "description": "æ ¸å¿ƒç—›ç‚¹ã€æœŸæœ›ä»·å€¼ã€ä½¿ç”¨åœºæ™¯ã€ç”¨æˆ·è§’è‰²",
        "key_aspects": ["æ ¸å¿ƒç—›ç‚¹", "æœŸæœ›ä»·å€¼", "ä½¿ç”¨åœºæ™¯", "ç”¨æˆ·è§’è‰²"]
    },
    "business_process": {
        "name": "ä¸šåŠ¡æµç¨‹",
        "description": "å…³é”®æµç¨‹èŠ‚ç‚¹ã€è§’è‰²åˆ†å·¥ã€è§¦å‘äº‹ä»¶ã€å¼‚å¸¸å¤„ç†",
        "key_aspects": ["å…³é”®æµç¨‹", "è§’è‰²åˆ†å·¥", "è§¦å‘äº‹ä»¶", "å¼‚å¸¸å¤„ç†"]
    },
    "tech_constraints": {
        "name": "æŠ€æœ¯çº¦æŸ",
        "description": "ç°æœ‰æŠ€æœ¯æ ˆã€é›†æˆæ¥å£è¦æ±‚ã€æ€§èƒ½æŒ‡æ ‡ã€å®‰å…¨åˆè§„",
        "key_aspects": ["éƒ¨ç½²æ–¹å¼", "ç³»ç»Ÿé›†æˆ", "æ€§èƒ½è¦æ±‚", "å®‰å…¨åˆè§„"]
    },
    "project_constraints": {
        "name": "é¡¹ç›®çº¦æŸ",
        "description": "é¢„ç®—èŒƒå›´ã€æ—¶é—´èŠ‚ç‚¹ã€èµ„æºé™åˆ¶ã€å…¶ä»–çº¦æŸ",
        "key_aspects": ["é¢„ç®—èŒƒå›´", "æ—¶é—´èŠ‚ç‚¹", "èµ„æºé™åˆ¶", "ä¼˜å…ˆçº§"]
    }
}


# ============ æ»‘åŠ¨çª—å£ä¸Šä¸‹æ–‡ç®¡ç† ============

# é…ç½®å‚æ•°
CONTEXT_WINDOW_SIZE = 5  # ä¿ç•™æœ€è¿‘Næ¡å®Œæ•´é—®ç­”
SUMMARY_THRESHOLD = 8    # è¶…è¿‡æ­¤æ•°é‡æ—¶è§¦å‘æ‘˜è¦ç”Ÿæˆ
MAX_DOC_LENGTH = 2000    # å•ä¸ªæ–‡æ¡£æœ€å¤§é•¿åº¦ï¼ˆçº¦650æ±‰å­—ï¼Œå¢åŠ 33%ï¼‰
MAX_TOTAL_DOCS = 5000    # æ‰€æœ‰æ–‡æ¡£æ€»é•¿åº¦é™åˆ¶ï¼ˆçº¦1600æ±‰å­—ï¼Œå¢åŠ 67%ï¼‰
API_TIMEOUT = 90.0       # API è°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œä»60ç§’å¢åŠ åˆ°90ç§’

# ============ æ™ºèƒ½æ–‡æ¡£æ‘˜è¦é…ç½®ï¼ˆç¬¬ä¸‰é˜¶æ®µä¼˜åŒ–ï¼‰ ============
ENABLE_SMART_SUMMARY = True       # å¯ç”¨æ™ºèƒ½æ–‡æ¡£æ‘˜è¦ï¼ˆæ›¿ä»£ç®€å•æˆªæ–­ï¼‰
SMART_SUMMARY_THRESHOLD = 1500    # è§¦å‘æ™ºèƒ½æ‘˜è¦çš„æ–‡æ¡£é•¿åº¦é˜ˆå€¼ï¼ˆå­—ç¬¦ï¼‰
SMART_SUMMARY_TARGET = 800        # æ‘˜è¦ç›®æ ‡é•¿åº¦ï¼ˆå­—ç¬¦ï¼‰
SUMMARY_CACHE_ENABLED = True      # å¯ç”¨æ‘˜è¦ç¼“å­˜ï¼ˆé¿å…é‡å¤ç”Ÿæˆï¼‰
MAX_TOKENS_SUMMARY = 500          # æ‘˜è¦ç”Ÿæˆçš„æœ€å¤§tokenæ•°


# ============ æ™ºèƒ½æ–‡æ¡£æ‘˜è¦å®ç° ============

def get_document_hash(content: str) -> str:
    """è®¡ç®—æ–‡æ¡£å†…å®¹çš„hashå€¼ï¼Œç”¨äºæ‘˜è¦ç¼“å­˜"""
    import hashlib
    return hashlib.md5(content.encode('utf-8')).hexdigest()[:16]


def get_cached_summary(doc_hash: str) -> Optional[str]:
    """è·å–ç¼“å­˜çš„æ–‡æ¡£æ‘˜è¦"""
    if not SUMMARY_CACHE_ENABLED:
        return None

    cache_file = SUMMARIES_DIR / f"{doc_hash}.txt"
    if cache_file.exists():
        try:
            summary = cache_file.read_text(encoding='utf-8')
            if ENABLE_DEBUG_LOG:
                print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„æ–‡æ¡£æ‘˜è¦: {doc_hash}")
            return summary
        except Exception as e:
            if ENABLE_DEBUG_LOG:
                print(f"âš ï¸  è¯»å–æ‘˜è¦ç¼“å­˜å¤±è´¥: {e}")
    return None


def save_summary_cache(doc_hash: str, summary: str) -> None:
    """ä¿å­˜æ–‡æ¡£æ‘˜è¦åˆ°ç¼“å­˜"""
    if not SUMMARY_CACHE_ENABLED:
        return

    cache_file = SUMMARIES_DIR / f"{doc_hash}.txt"
    try:
        cache_file.write_text(summary, encoding='utf-8')
        if ENABLE_DEBUG_LOG:
            print(f"ğŸ’¾ æ‘˜è¦å·²ç¼“å­˜: {doc_hash}")
    except Exception as e:
        if ENABLE_DEBUG_LOG:
            print(f"âš ï¸  ä¿å­˜æ‘˜è¦ç¼“å­˜å¤±è´¥: {e}")


def summarize_document(content: str, doc_name: str = "æ–‡æ¡£", topic: str = "") -> tuple[str, bool]:
    """
    æ™ºèƒ½æ–‡æ¡£æ‘˜è¦ç”Ÿæˆï¼ˆç¬¬ä¸‰é˜¶æ®µä¼˜åŒ–æ ¸å¿ƒåŠŸèƒ½ï¼‰

    å½“æ–‡æ¡£è¿‡é•¿æ—¶ï¼Œä½¿ç”¨AIç”Ÿæˆä¿ç•™å…³é”®ä¿¡æ¯çš„æ‘˜è¦ï¼Œè€Œéç®€å•æˆªæ–­ã€‚

    Args:
        content: æ–‡æ¡£åŸå§‹å†…å®¹
        doc_name: æ–‡æ¡£åç§°ï¼ˆç”¨äºæç¤ºï¼‰
        topic: è°ƒç ”ä¸»é¢˜ï¼ˆç”¨äºç”Ÿæˆæ›´ç›¸å…³çš„æ‘˜è¦ï¼‰

    Returns:
        tuple[str, bool]: (å¤„ç†åçš„å†…å®¹, æ˜¯å¦ç”Ÿæˆäº†æ‘˜è¦)
    """
    original_length = len(content)

    # å¦‚æœæ–‡æ¡£é•¿åº¦æœªè¶…è¿‡é˜ˆå€¼ï¼Œç›´æ¥è¿”å›åŸæ–‡
    if original_length <= SMART_SUMMARY_THRESHOLD:
        return content, False

    # å¦‚æœæœªå¯ç”¨æ™ºèƒ½æ‘˜è¦æˆ–æ²¡æœ‰AIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨ç®€å•æˆªæ–­
    if not ENABLE_SMART_SUMMARY or not claude_client:
        truncated = content[:MAX_DOC_LENGTH]
        if ENABLE_DEBUG_LOG:
            print(f"ğŸ“„ æ–‡æ¡£ {doc_name} ä½¿ç”¨ç®€å•æˆªæ–­: {original_length} -> {MAX_DOC_LENGTH} å­—ç¬¦")
        return truncated, False

    # æ£€æŸ¥ç¼“å­˜
    doc_hash = get_document_hash(content)
    cached = get_cached_summary(doc_hash)
    if cached:
        return cached, True

    # ç”Ÿæˆæ™ºèƒ½æ‘˜è¦
    if ENABLE_DEBUG_LOG:
        print(f"ğŸ¤– ä¸ºæ–‡æ¡£ {doc_name} ç”Ÿæˆæ™ºèƒ½æ‘˜è¦: {original_length} -> ~{SMART_SUMMARY_TARGET} å­—ç¬¦")

    # æ„å»ºæ‘˜è¦ç”Ÿæˆprompt
    summary_prompt = f"""è¯·ä¸ºä»¥ä¸‹æ–‡æ¡£ç”Ÿæˆä¸€ä¸ªç²¾ç‚¼çš„æ‘˜è¦ã€‚

## è¦æ±‚
1. æ‘˜è¦é•¿åº¦æ§åˆ¶åœ¨ {SMART_SUMMARY_TARGET} å­—ç¬¦ä»¥å†…
2. ä¿ç•™æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯ã€æ ¸å¿ƒè§‚ç‚¹å’Œé‡è¦æ•°æ®
3. å¦‚æœæ–‡æ¡£ä¸"{topic}"ä¸»é¢˜ç›¸å…³ï¼Œä¼˜å…ˆä¿ç•™ä¸ä¸»é¢˜ç›¸å…³çš„å†…å®¹
4. ä½¿ç”¨ç®€æ´æ¸…æ™°çš„è¯­è¨€ï¼Œé¿å…å†—ä½™
5. ä¿æŒä¿¡æ¯çš„å‡†ç¡®æ€§ï¼Œä¸è¦æ·»åŠ æ–‡æ¡£ä¸­æ²¡æœ‰çš„å†…å®¹

## æ–‡æ¡£åç§°
{doc_name}

## æ–‡æ¡£å†…å®¹
{content[:8000]}

## è¾“å‡ºæ ¼å¼
ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦æ·»åŠ "æ‘˜è¦ï¼š"ç­‰å‰ç¼€ã€‚"""

    try:
        import time
        start_time = time.time()

        response = claude_client.messages.create(
            model=MODEL_NAME,
            max_tokens=MAX_TOKENS_SUMMARY,
            timeout=60.0,  # æ‘˜è¦ç”Ÿæˆç”¨è¾ƒçŸ­è¶…æ—¶
            messages=[{"role": "user", "content": summary_prompt}]
        )

        response_time = time.time() - start_time
        summary = response.content[0].text.strip()

        # è®°å½•metrics
        metrics_collector.record_api_call(
            call_type="doc_summary",
            prompt_length=len(summary_prompt),
            response_time=response_time,
            success=True,
            timeout=False,
            max_tokens=MAX_TOKENS_SUMMARY
        )

        # ä¿å­˜åˆ°ç¼“å­˜
        save_summary_cache(doc_hash, summary)

        if ENABLE_DEBUG_LOG:
            print(f"âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ: {original_length} -> {len(summary)} å­—ç¬¦ ({response_time:.1f}s)")

        return summary, True

    except Exception as e:
        if ENABLE_DEBUG_LOG:
            print(f"âš ï¸  æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æˆªæ–­: {e}")

        # è®°å½•å¤±è´¥çš„metrics
        metrics_collector.record_api_call(
            call_type="doc_summary",
            prompt_length=len(summary_prompt) if 'summary_prompt' in locals() else 0,
            response_time=0,
            success=False,
            timeout="timeout" in str(e).lower(),
            error_msg=str(e),
            max_tokens=MAX_TOKENS_SUMMARY
        )

        # å›é€€åˆ°ç®€å•æˆªæ–­
        return content[:MAX_DOC_LENGTH], False


def process_document_for_context(doc: dict, remaining_length: int, topic: str = "") -> tuple[str, str, int, bool]:
    """
    å¤„ç†æ–‡æ¡£ä»¥ç”¨äºä¸Šä¸‹æ–‡ï¼ˆç»Ÿä¸€çš„æ–‡æ¡£å¤„ç†å…¥å£ï¼‰

    Args:
        doc: æ–‡æ¡£å­—å…¸ï¼ŒåŒ…å« name å’Œ content
        remaining_length: å‰©ä½™å¯ç”¨é•¿åº¦
        topic: è°ƒç ”ä¸»é¢˜

    Returns:
        tuple[str, str, int, bool]: (æ–‡æ¡£å, å¤„ç†åçš„å†…å®¹, ä½¿ç”¨çš„é•¿åº¦, æ˜¯å¦è¢«æ‘˜è¦/æˆªæ–­)
    """
    doc_name = doc.get('name', 'æ–‡æ¡£')
    content = doc.get('content', '')

    if not content:
        return doc_name, '', 0, False

    original_length = len(content)
    max_allowed = min(MAX_DOC_LENGTH, remaining_length)

    # å¦‚æœæ–‡æ¡£å¾ˆçŸ­ï¼ˆä¸è¶…è¿‡æ‘˜è¦é˜ˆå€¼ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
    if original_length <= SMART_SUMMARY_THRESHOLD:
        # ä½†å¦‚æœè¶…è¿‡max_allowedï¼Œä»éœ€æˆªæ–­
        if original_length > max_allowed:
            return doc_name, content[:max_allowed], max_allowed, True
        return doc_name, content, original_length, False

    # æ–‡æ¡£è¶…è¿‡æ‘˜è¦é˜ˆå€¼ï¼Œå°è¯•æ™ºèƒ½æ‘˜è¦
    if ENABLE_SMART_SUMMARY:
        processed_content, is_summarized = summarize_document(content, doc_name, topic)

        # å¦‚æœæ‘˜è¦åä»ç„¶è¿‡é•¿ï¼Œå†æˆªæ–­
        if len(processed_content) > max_allowed:
            processed_content = processed_content[:max_allowed]

        return doc_name, processed_content, len(processed_content), True

    # æœªå¯ç”¨æ™ºèƒ½æ‘˜è¦ï¼Œç®€å•æˆªæ–­
    truncated = content[:max_allowed]
    return doc_name, truncated, len(truncated), True


def generate_history_summary(session: dict, exclude_recent: int = 5) -> Optional[str]:
    """
    ç”Ÿæˆå†å²è®¿è°ˆè®°å½•çš„æ‘˜è¦

    Args:
        session: ä¼šè¯æ•°æ®
        exclude_recent: æ’é™¤æœ€è¿‘Næ¡è®°å½•ï¼ˆè¿™äº›ä¼šä¿ç•™å®Œæ•´å†…å®¹ï¼‰

    Returns:
        æ‘˜è¦æ–‡æœ¬ï¼Œå¦‚æœæ— éœ€æ‘˜è¦åˆ™è¿”å› None
    """
    interview_log = session.get("interview_log", [])

    # å¦‚æœè®°å½•å¤ªå°‘ï¼Œä¸éœ€è¦æ‘˜è¦
    if len(interview_log) <= exclude_recent:
        return None

    # è·å–éœ€è¦æ‘˜è¦çš„å†å²è®°å½•
    history_logs = interview_log[:-exclude_recent] if exclude_recent > 0 else interview_log

    if not history_logs:
        return None

    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„æ‘˜è¦
    cached_summary = session.get("context_summary", {})
    cached_count = cached_summary.get("log_count", 0)

    # å¦‚æœç¼“å­˜çš„æ‘˜è¦è¦†ç›–äº†ç›¸åŒæ•°é‡çš„è®°å½•ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜
    if cached_count == len(history_logs) and cached_summary.get("text"):
        if ENABLE_DEBUG_LOG:
            print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„å†å²æ‘˜è¦ï¼ˆè¦†ç›– {cached_count} æ¡è®°å½•ï¼‰")
        return cached_summary["text"]

    # éœ€è¦ç”Ÿæˆæ–°æ‘˜è¦
    if not claude_client:
        # æ—  AI æ—¶ä½¿ç”¨ç®€å•æ‘˜è¦
        return _generate_simple_summary(history_logs)

    # æ„å»ºæ‘˜è¦ç”Ÿæˆ prompt
    summary_prompt = _build_summary_prompt(session.get("topic", ""), history_logs)

    try:
        if ENABLE_DEBUG_LOG:
            print(f"ğŸ—œï¸ æ­£åœ¨ç”Ÿæˆå†å²æ‘˜è¦ï¼ˆ{len(history_logs)} æ¡è®°å½•ï¼‰...")

        summary_text = call_claude(summary_prompt, max_tokens=300, call_type="summary")

        if summary_text:
            if ENABLE_DEBUG_LOG:
                print(f"âœ… å†å²æ‘˜è¦ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary_text)} å­—ç¬¦")
            return summary_text
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå†å²æ‘˜è¦å¤±è´¥: {e}")

    # å¤±è´¥æ—¶å›é€€åˆ°ç®€å•æ‘˜è¦
    return _generate_simple_summary(history_logs)


def _build_summary_prompt(topic: str, logs: list) -> str:
    """æ„å»ºæ‘˜è¦ç”Ÿæˆçš„ prompt"""
    # æŒ‰ç»´åº¦æ•´ç†
    by_dim = {}
    for log in logs:
        dim = log.get("dimension", "other")
        if dim not in by_dim:
            by_dim[dim] = []
        by_dim[dim].append(log)

    logs_text = ""
    for dim, dim_logs in by_dim.items():
        dim_name = DIMENSION_INFO.get(dim, {}).get("name", dim)
        logs_text += f"\nã€{dim_name}ã€‘\n"
        for log in dim_logs:
            logs_text += f"Q: {log['question'][:80]}\nA: {log['answer'][:100]}\n"

    return f"""è¯·å°†ä»¥ä¸‹è®¿è°ˆè®°å½•å‹ç¼©ä¸ºç®€æ´çš„æ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ç‚¹ã€‚

è°ƒç ”ä¸»é¢˜ï¼š{topic}

è®¿è°ˆè®°å½•ï¼š
{logs_text}

è¦æ±‚ï¼š
1. æŒ‰ç»´åº¦æ•´ç†å…³é”®ä¿¡æ¯
2. æ¯ä¸ªç»´åº¦ç”¨1-2å¥è¯æ¦‚æ‹¬æ ¸å¿ƒè¦ç‚¹
3. ä¿ç•™å…·ä½“çš„æ•°æ®ã€æŒ‡æ ‡ã€é€‰æ‹©
4. æ€»é•¿åº¦æ§åˆ¶åœ¨200å­—ä»¥å†…
5. ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦æ·»åŠ å…¶ä»–è¯´æ˜

æ‘˜è¦ï¼š"""


def _generate_simple_summary(logs: list) -> str:
    """ç”Ÿæˆç®€å•æ‘˜è¦ï¼ˆæ—  AI æ—¶ä½¿ç”¨ï¼‰"""
    by_dim = {}
    for log in logs:
        dim = log.get("dimension", "other")
        dim_name = DIMENSION_INFO.get(dim, {}).get("name", dim)
        if dim_name not in by_dim:
            by_dim[dim_name] = []
        # åªä¿ç•™ç­”æ¡ˆçš„å…³é”®éƒ¨åˆ†
        answer = log.get("answer", "")[:50]
        by_dim[dim_name].append(answer)

    parts = []
    for dim_name, answers in by_dim.items():
        parts.append(f"ã€{dim_name}ã€‘: {'; '.join(answers[:3])}")

    return " | ".join(parts)


def update_context_summary(session: dict, session_file) -> None:
    """
    æ›´æ–°ä¼šè¯çš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆåœ¨æäº¤å›ç­”åè°ƒç”¨ï¼‰

    åªæœ‰å½“å†å²è®°å½•è¶…è¿‡é˜ˆå€¼æ—¶æ‰ç”Ÿæˆæ‘˜è¦
    """
    interview_log = session.get("interview_log", [])

    # æœªè¶…è¿‡é˜ˆå€¼ï¼Œä¸éœ€è¦æ‘˜è¦
    if len(interview_log) < SUMMARY_THRESHOLD:
        return

    # è®¡ç®—éœ€è¦æ‘˜è¦çš„è®°å½•æ•°
    history_count = len(interview_log) - CONTEXT_WINDOW_SIZE
    if history_count <= 0:
        return

    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ‘˜è¦
    cached_summary = session.get("context_summary", {})
    if cached_summary.get("log_count", 0) >= history_count:
        return  # ç¼“å­˜ä»ç„¶æœ‰æ•ˆ

    # ç”Ÿæˆæ–°æ‘˜è¦
    history_logs = interview_log[:history_count]

    if claude_client:
        summary_prompt = _build_summary_prompt(session.get("topic", ""), history_logs)
        try:
            summary_text = call_claude(summary_prompt, max_tokens=300, call_type="summary")
            if summary_text:
                session["context_summary"] = {
                    "text": summary_text,
                    "log_count": history_count,
                    "updated_at": get_utc_now()
                }
                # ä¿å­˜æ›´æ–°
                session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")
                if ENABLE_DEBUG_LOG:
                    print(f"ğŸ“ å·²æ›´æ–°ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆè¦†ç›– {history_count} æ¡å†å²è®°å½•ï¼‰")
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°ä¸Šä¸‹æ–‡æ‘˜è¦å¤±è´¥: {e}")
    else:
        # æ—  AI æ—¶ä½¿ç”¨ç®€å•æ‘˜è¦
        session["context_summary"] = {
            "text": _generate_simple_summary(history_logs),
            "log_count": history_count,
            "updated_at": get_utc_now()
        }
        session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")


# ============ æ™ºèƒ½è¿½é—®è¯„ä¼° ============

# ç»´åº¦è¿½é—®æ•æ„Ÿåº¦ï¼ˆè¶Šé«˜è¶Šå®¹æ˜“è§¦å‘è¿½é—®ï¼‰
DIMENSION_FOLLOW_UP_SENSITIVITY = {
    "customer_needs": 0.8,       # å®¢æˆ·éœ€æ±‚æœ€éœ€è¦æ·±æŒ–
    "business_process": 0.6,     # ä¸šåŠ¡æµç¨‹éœ€è¦ä¸€å®šæ·±åº¦
    "tech_constraints": 0.5,     # æŠ€æœ¯çº¦æŸç›¸å¯¹æ˜ç¡®
    "project_constraints": 0.4,  # é¡¹ç›®çº¦æŸé€šå¸¸è¾ƒç›´æ¥
}


def evaluate_answer_depth(question: str, answer: str, dimension: str,
                          options: list = None, is_follow_up: bool = False) -> dict:
    """
    è¯„ä¼°å›ç­”æ·±åº¦ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è¿½é—®

    ä¸‰å±‚åˆ¤æ–­ï¼š
    1. æ˜ç¡®éœ€è¦è¿½é—®ï¼ˆå›ç­”å¤ªå¼±ï¼‰
    2. æ˜ç¡®ä¸éœ€è¦è¿½é—®ï¼ˆå›ç­”å·²å……åˆ†ï¼‰
    3. å»ºè®®AIè¯„ä¼°ï¼ˆäº¤ç»™AIåœ¨ç”Ÿæˆä¸‹ä¸€é¢˜æ—¶åˆ¤æ–­ï¼‰

    Returns:
        {
            "needs_follow_up": bool,       # è§„åˆ™å±‚åˆ¤æ–­ç»“æœ
            "suggest_ai_eval": bool,       # æ˜¯å¦å»ºè®®AIå†æ¬¡è¯„ä¼°
            "reason": str or None,         # è¿½é—®åŸå› 
            "signals": list                # æ£€æµ‹åˆ°çš„ä¿¡å·
        }
    """
    # è¿½é—®çš„å›ç­”ä¸å†è¿½é—®ï¼ˆé¿å…æ— é™è¿½é—®ï¼‰
    if is_follow_up:
        return {"needs_follow_up": False, "suggest_ai_eval": False,
                "reason": None, "signals": []}

    signals = []
    answer_stripped = answer.strip()
    answer_len = len(answer_stripped)
    sensitivity = DIMENSION_FOLLOW_UP_SENSITIVITY.get(dimension, 0.5)

    # ---- ç¬¬ä¸€å±‚ï¼šæ˜ç¡®éœ€è¦è¿½é—®çš„æƒ…å†µ ----

    # 1. å›ç­”è¿‡çŸ­ï¼ˆæ ¹æ®ç»´åº¦æ•æ„Ÿåº¦è°ƒæ•´é˜ˆå€¼ï¼‰
    short_threshold = int(20 + sensitivity * 20)  # å®¢æˆ·éœ€æ±‚36å­—ç¬¦ï¼Œé¡¹ç›®çº¦æŸ28å­—ç¬¦
    if answer_len < short_threshold:
        signals.append("too_short")

    # 2. æ¨¡ç³Šè¡¨è¾¾æ£€æµ‹ï¼ˆæ‰©å±•è¯åº“ï¼‰
    vague_indicators = [
        # ä¸ç¡®å®šç±»
        "çœ‹æƒ…å†µ", "ä¸ä¸€å®š", "å¯èƒ½", "æˆ–è®¸", "å¤§æ¦‚", "å·®ä¸å¤š", "åˆ°æ—¶å€™",
        "å†è¯´", "è¿˜æ²¡æƒ³å¥½", "ä¸ç¡®å®š", "çœ‹å…·ä½“", "æ ¹æ®æƒ…å†µ", "å¾…å®š",
        "ä»¥åå†è¯´", "æš‚æ—¶ä¸æ¸…æ¥š", "ç›®å‰è¿˜ä¸å¥½è¯´",
        # ç¬¼ç»Ÿç±»
        "éƒ½å¯ä»¥", "éƒ½è¡Œ", "éšä¾¿", "æ— æ‰€è°“", "å·®ä¸å¤š", "ä¸€èˆ¬",
        # å›é¿ç±»
        "ä¸å¤ªäº†è§£", "æ²¡æƒ³è¿‡", "ä¸çŸ¥é“", "è¯´ä¸å¥½", "å¾ˆéš¾è¯´",
    ]
    matched_vague = [v for v in vague_indicators if v in answer_stripped]
    if matched_vague:
        signals.append("vague_expression")

    # 3. å®Œå…¨åŒ¹é…æ³›æ³›å›ç­”
    generic_answers = [
        "å¥½çš„", "æ˜¯çš„", "å¯ä»¥", "æ²¡é—®é¢˜", "éœ€è¦", "åº”è¯¥è¦",
        "å¯¹", "å—¯", "è¡Œ", "åŒæ„", "æ²¡æœ‰", "ä¸éœ€è¦",
    ]
    if answer_stripped in generic_answers:
        signals.append("generic_answer")

    # 4. ä»…é€‰æ‹©äº†é¢„è®¾é€‰é¡¹æ²¡æœ‰è¡¥å……ï¼ˆç­”æ¡ˆç­‰äºæŸä¸ªé€‰é¡¹åŸæ–‡ï¼‰
    if options:
        is_exact_option = answer_stripped in options
        # å•é€‰ä¸”ç­”æ¡ˆå°±æ˜¯é€‰é¡¹åŸæ–‡ï¼Œç¼ºä¹è‡ªå·±çš„æ€è€ƒ
        if is_exact_option and answer_len < 40:
            signals.append("option_only")

    # 5. ç¼ºä¹é‡åŒ–ä¿¡æ¯ï¼ˆå¯¹æŸäº›ç»´åº¦é‡è¦ï¼‰
    has_numbers = any(c.isdigit() for c in answer_stripped)
    quantitative_dimensions = ["tech_constraints", "project_constraints"]
    if dimension in quantitative_dimensions and not has_numbers and answer_len < 60:
        signals.append("no_quantification")

    # 6. å¤šé€‰ä½†åªé€‰äº†ä¸€ä¸ªï¼ˆå¯èƒ½éœ€è¦è¡¥å……ï¼‰
    if options and "ï¼›" not in answer_stripped and len(options) >= 3:
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤šé€‰é¢˜ä½†åªé€‰äº†ä¸€ä¸ª
        selected_count = sum(1 for opt in options if opt in answer_stripped)
        if selected_count <= 1 and answer_len < 30:
            signals.append("single_selection")

    # ---- ç¬¬äºŒå±‚ï¼šåˆ¤æ–­æ˜¯å¦æ˜ç¡®ä¸éœ€è¦è¿½é—® ----

    # å›ç­”è¶³å¤Ÿè¯¦ç»†ï¼Œä¸éœ€è¦è¿½é—®
    sufficient_signals = []
    if answer_len > 80:
        sufficient_signals.append("detailed_answer")
    if "ï¼›" in answer_stripped and answer_len > 40:
        sufficient_signals.append("multi_point_answer")
    if has_numbers and answer_len > 30:
        sufficient_signals.append("quantified_answer")

    # ---- ç¬¬ä¸‰å±‚ï¼šç»¼åˆåˆ¤æ–­ ----

    # è®¡ç®—è¿½é—®å¾—åˆ†ï¼ˆä¿¡å·è¶Šå¤šè¶Šéœ€è¦è¿½é—®ï¼‰
    signal_weights = {
        "too_short": 0.4,
        "vague_expression": 0.5,
        "generic_answer": 0.8,
        "option_only": 0.3,
        "no_quantification": 0.2,
        "single_selection": 0.2,
    }
    follow_up_score = sum(signal_weights.get(s, 0.1) for s in signals)
    follow_up_score *= sensitivity  # åº”ç”¨ç»´åº¦æ•æ„Ÿåº¦

    # å‡å»å……åˆ†åº¦ä¿¡å·
    sufficient_weights = {
        "detailed_answer": 0.5,
        "multi_point_answer": 0.3,
        "quantified_answer": 0.2,
    }
    sufficient_score = sum(sufficient_weights.get(s, 0) for s in sufficient_signals)
    follow_up_score -= sufficient_score

    # åˆ¤æ–­ç»“æœ
    if follow_up_score >= 0.4:
        # æ˜ç¡®éœ€è¦è¿½é—®
        reason = _build_follow_up_reason(signals)
        return {"needs_follow_up": True, "suggest_ai_eval": False,
                "reason": reason, "signals": signals}
    elif follow_up_score >= 0.15 and not sufficient_signals:
        # è¾¹ç•Œæƒ…å†µï¼Œå»ºè®®è®©AIè¯„ä¼°
        reason = _build_follow_up_reason(signals)
        return {"needs_follow_up": False, "suggest_ai_eval": True,
                "reason": reason, "signals": signals}
    else:
        # ä¸éœ€è¦è¿½é—®
        return {"needs_follow_up": False, "suggest_ai_eval": False,
                "reason": None, "signals": signals}


def _build_follow_up_reason(signals: list) -> str:
    """æ ¹æ®æ£€æµ‹åˆ°çš„ä¿¡å·æ„å»ºè¿½é—®åŸå› """
    reason_map = {
        "too_short": "å›ç­”è¿‡äºç®€çŸ­ï¼Œéœ€è¦è¡¥å……å…·ä½“ç»†èŠ‚",
        "vague_expression": "å›ç­”åŒ…å«æ¨¡ç³Šè¡¨è¿°ï¼Œéœ€è¦æ˜ç¡®å…·ä½“è¦æ±‚",
        "generic_answer": "å›ç­”è¿‡äºç¬¼ç»Ÿï¼Œéœ€è¦æ·±å…¥äº†è§£å…·ä½“éœ€æ±‚",
        "option_only": "ä»…é€‰æ‹©äº†é¢„è®¾é€‰é¡¹ï¼Œéœ€è¦äº†è§£å…·ä½“åœºæ™¯å’Œè€ƒé‡",
        "no_quantification": "ç¼ºå°‘é‡åŒ–æŒ‡æ ‡ï¼Œéœ€è¦æ˜ç¡®å…·ä½“æ•°æ®è¦æ±‚",
        "single_selection": "åªé€‰æ‹©äº†å•ä¸€é€‰é¡¹ï¼Œéœ€è¦äº†è§£æ˜¯å¦è¿˜æœ‰å…¶ä»–éœ€æ±‚",
    }
    reasons = [reason_map.get(s, "") for s in signals if s in reason_map]
    return reasons[0] if reasons else "éœ€è¦è¿›ä¸€æ­¥äº†è§£è¯¦ç»†éœ€æ±‚"


def build_interview_prompt(session: dict, dimension: str, all_dim_logs: list) -> tuple[str, list]:
    """æ„å»ºè®¿è°ˆ promptï¼ˆä½¿ç”¨æ»‘åŠ¨çª—å£ + æ‘˜è¦å‹ç¼© + æ™ºèƒ½è¿½é—®ï¼‰

    Returns:
        tuple[str, list]: (promptå­—ç¬¦ä¸², è¢«æˆªæ–­çš„æ–‡æ¡£åˆ—è¡¨)
    """
    topic = session.get("topic", "æœªçŸ¥é¡¹ç›®")
    description = session.get("description")
    reference_docs = session.get("reference_docs", [])
    research_docs = session.get("research_docs", [])
    interview_log = session.get("interview_log", [])
    dim_info = DIMENSION_INFO.get(dimension, {})

    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = [f"å½“å‰è°ƒç ”ä¸»é¢˜ï¼š{topic}"]

    # å¦‚æœæœ‰ä¸»é¢˜æè¿°ï¼Œæ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
    if description:
        context_parts.append(f"\nä¸»é¢˜æè¿°ï¼š{description[:500]}")

    # æ·»åŠ å‚è€ƒæ–‡æ¡£å†…å®¹ï¼ˆä½¿ç”¨æ€»é•¿åº¦é™åˆ¶ + æ™ºèƒ½æ‘˜è¦ï¼‰
    total_doc_length = 0
    truncated_docs = []  # è®°å½•è¢«å¤„ç†çš„æ–‡æ¡£ï¼ˆæ‘˜è¦æˆ–æˆªæ–­ï¼‰
    summarized_docs = []  # è®°å½•ä½¿ç”¨æ™ºèƒ½æ‘˜è¦çš„æ–‡æ¡£
    if reference_docs:
        context_parts.append("\n## å‚è€ƒæ–‡æ¡£å†…å®¹ï¼š")
        for doc in reference_docs:
            if doc.get("content") and total_doc_length < MAX_TOTAL_DOCS:
                remaining = MAX_TOTAL_DOCS - total_doc_length
                original_length = len(doc["content"])

                # ä½¿ç”¨æ™ºèƒ½æ‘˜è¦å¤„ç†æ–‡æ¡£
                doc_name, processed_content, used_length, was_processed = process_document_for_context(
                    doc, remaining, topic
                )

                if processed_content:
                    context_parts.append(f"### {doc_name}")
                    context_parts.append(processed_content)
                    total_doc_length += used_length

                    # è®°å½•å¤„ç†æƒ…å†µ
                    if was_processed:
                        if used_length < original_length * 0.6:  # å¦‚æœå†…å®¹å‡å°‘è¶…è¿‡40%ï¼Œå¯èƒ½æ˜¯æ‘˜è¦
                            summarized_docs.append(f"{doc_name}ï¼ˆåŸ{original_length}å­—ç¬¦ï¼Œæ‘˜è¦è‡³{used_length}å­—ç¬¦ï¼‰")
                        else:
                            truncated_docs.append(f"{doc_name}ï¼ˆåŸ{original_length}å­—ç¬¦ï¼Œæˆªå–{used_length}å­—ç¬¦ï¼‰")

    # æ·»åŠ å·²æœ‰è°ƒç ”æˆæœå†…å®¹ï¼ˆå…±äº«æ€»é•¿åº¦é™åˆ¶ + æ™ºèƒ½æ‘˜è¦ï¼‰
    if research_docs and total_doc_length < MAX_TOTAL_DOCS:
        context_parts.append("\n## å·²æœ‰è°ƒç ”æˆæœï¼ˆä¾›å‚è€ƒï¼‰ï¼š")
        for doc in research_docs:
            if doc.get("content") and total_doc_length < MAX_TOTAL_DOCS:
                remaining = MAX_TOTAL_DOCS - total_doc_length
                original_length = len(doc["content"])

                # ä½¿ç”¨æ™ºèƒ½æ‘˜è¦å¤„ç†æ–‡æ¡£
                doc_name, processed_content, used_length, was_processed = process_document_for_context(
                    doc, remaining, topic
                )

                if processed_content:
                    context_parts.append(f"### {doc_name}")
                    context_parts.append(processed_content)
                    total_doc_length += used_length

                    # è®°å½•å¤„ç†æƒ…å†µ
                    if was_processed:
                        if used_length < original_length * 0.6:
                            summarized_docs.append(f"{doc_name}ï¼ˆåŸ{original_length}å­—ç¬¦ï¼Œæ‘˜è¦è‡³{used_length}å­—ç¬¦ï¼‰")
                        else:
                            truncated_docs.append(f"{doc_name}ï¼ˆåŸ{original_length}å­—ç¬¦ï¼Œæˆªå–{used_length}å­—ç¬¦ï¼‰")

    # æ·»åŠ å¤„ç†æç¤ºï¼ˆè®© AI çŸ¥é“æ–‡æ¡£ä¿¡æ¯ç»è¿‡å¤„ç†ï¼‰
    if summarized_docs:
        context_parts.append(f"\nğŸ“ æ³¨æ„ï¼šä»¥ä¸‹æ–‡æ¡£å·²é€šè¿‡AIç”Ÿæˆæ‘˜è¦ä»¥ä¿ç•™å…³é”®ä¿¡æ¯ï¼š{', '.join(summarized_docs)}")
    if truncated_docs:
        context_parts.append(f"\nâš ï¸ æ³¨æ„ï¼šä»¥ä¸‹æ–‡æ¡£å› é•¿åº¦é™åˆ¶å·²è¢«æˆªæ–­ï¼Œè¯·åŸºäºå·²æœ‰ä¿¡æ¯è¿›è¡Œæé—®ï¼š{', '.join(truncated_docs)}")

    # è”ç½‘æœç´¢å¢å¼ºï¼ˆé™åˆ¶ç»“æœæ•°é‡å’Œé•¿åº¦ï¼‰
    if should_search(topic, dimension, session):
        search_query = generate_search_query(topic, dimension, session)
        search_results = web_search(search_query)

        if search_results:
            context_parts.append("\n## è¡Œä¸šçŸ¥è¯†å‚è€ƒï¼ˆè”ç½‘æœç´¢ï¼‰ï¼š")
            for idx, result in enumerate(search_results[:2], 1):
                if result["type"] == "intent":
                    context_parts.append(f"**{result['content'][:150]}**")
                else:
                    context_parts.append(f"{idx}. **{result.get('title', 'å‚è€ƒä¿¡æ¯')[:40]}**")
                    context_parts.append(f"   {result['content'][:150]}")

    # ========== æ»‘åŠ¨çª—å£ + æ‘˜è¦å‹ç¼© ==========
    if interview_log:
        context_parts.append("\n## å·²æ”¶é›†çš„ä¿¡æ¯ï¼š")

        # åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨æ‘˜è¦
        if len(interview_log) > CONTEXT_WINDOW_SIZE:
            # è·å–æˆ–ç”Ÿæˆå†å²æ‘˜è¦
            history_summary = generate_history_summary(session, exclude_recent=CONTEXT_WINDOW_SIZE)
            if history_summary:
                context_parts.append(f"\n### å†å²è°ƒç ”æ‘˜è¦ï¼ˆå…±{len(interview_log) - CONTEXT_WINDOW_SIZE}æ¡ï¼‰ï¼š")
                context_parts.append(history_summary)
                context_parts.append("\n### æœ€è¿‘é—®ç­”è®°å½•ï¼š")

            # åªä¿ç•™æœ€è¿‘çš„å®Œæ•´è®°å½•
            recent_logs = interview_log[-CONTEXT_WINDOW_SIZE:]
        else:
            recent_logs = interview_log

        # æ·»åŠ å®Œæ•´çš„æœ€è¿‘é—®ç­”è®°å½•
        for log in recent_logs:
            follow_up_mark = " [è¿½é—®]" if log.get("is_follow_up") else ""
            context_parts.append(f"- Q: {log['question']}{follow_up_mark}")
            context_parts.append(f"  A: {log['answer']}")
            dim_name = DIMENSION_INFO.get(log.get("dimension", ""), {}).get("name", "")
            if dim_name:
                context_parts.append(f"  (ç»´åº¦: {dim_name})")

    # è®¡ç®—æ­£å¼é—®é¢˜æ•°é‡ï¼ˆæ’é™¤è¿½é—®ï¼‰
    formal_questions_count = len([log for log in all_dim_logs if not log.get("is_follow_up", False)])

    # ========== æ™ºèƒ½è¿½é—®åˆ¤æ–­ï¼ˆä½¿ç”¨å¢å¼ºè§„åˆ™ + AIè¯„ä¼°ï¼‰ ==========
    last_log = None
    should_follow_up = False
    suggest_ai_eval = False
    follow_up_reason = ""
    eval_signals = []

    if all_dim_logs:
        last_log = all_dim_logs[-1]
        last_answer = last_log.get("answer", "")
        last_question = last_log.get("question", "")
        last_options = last_log.get("options", [])
        last_is_follow_up = last_log.get("is_follow_up", False)

        # ä½¿ç”¨å¢å¼ºç‰ˆè¯„ä¼°å‡½æ•°
        eval_result = evaluate_answer_depth(
            question=last_question,
            answer=last_answer,
            dimension=dimension,
            options=last_options,
            is_follow_up=last_is_follow_up
        )

        should_follow_up = eval_result["needs_follow_up"]
        suggest_ai_eval = eval_result["suggest_ai_eval"]
        follow_up_reason = eval_result["reason"] or ""
        eval_signals = eval_result["signals"]

        if ENABLE_DEBUG_LOG and (should_follow_up or suggest_ai_eval):
            print(f"ğŸ” è¿½é—®è¯„ä¼°: signals={eval_signals}, follow_up={should_follow_up}, ai_eval={suggest_ai_eval}")

    # æ„å»º AI è¯„ä¼°æç¤ºï¼ˆå½“è§„åˆ™æœªæ˜ç¡®è§¦å‘ä½†å»ºè®®AIåˆ¤æ–­æ—¶ï¼‰
    ai_eval_guidance = ""
    if suggest_ai_eval and last_log:
        ai_eval_guidance = f"""
## å›ç­”æ·±åº¦è¯„ä¼°

è¯·å…ˆè¯„ä¼°ç”¨æˆ·çš„ä¸Šä¸€ä¸ªå›ç­”æ˜¯å¦éœ€è¦è¿½é—®ï¼š

**ä¸Šä¸€ä¸ªé—®é¢˜**: {last_log.get('question', '')[:100]}
**ç”¨æˆ·å›ç­”**: {last_log.get('answer', '')}
**æ£€æµ‹ä¿¡å·**: {', '.join(eval_signals) if eval_signals else 'æ— æ˜æ˜¾é—®é¢˜'}

åˆ¤æ–­æ ‡å‡†ï¼ˆæ»¡è¶³ä»»ä¸€æ¡å³åº”è¿½é—®ï¼‰ï¼š
1. å›ç­”åªæ˜¯é€‰æ‹©äº†é€‰é¡¹ï¼Œæ²¡æœ‰è¯´æ˜å…·ä½“åœºæ™¯æˆ–åŸå› 
2. ç¼ºå°‘é‡åŒ–æŒ‡æ ‡ï¼ˆå¦‚æ—¶é—´ã€æ•°é‡ã€é¢‘ç‡ç­‰ï¼‰
3. å›ç­”æ¯”è¾ƒç¬¼ç»Ÿï¼Œæ²¡æœ‰é’ˆå¯¹æ€§ç»†èŠ‚
4. å¯èƒ½éšè—äº†æ›´æ·±å±‚çš„éœ€æ±‚æˆ–é¡¾è™‘

å¦‚æœåˆ¤æ–­éœ€è¦è¿½é—®ï¼Œè¯·ï¼š
- è®¾ç½® is_follow_up: true
- é’ˆå¯¹ä¸Šä¸€ä¸ªå›ç­”è¿›è¡Œæ·±å…¥æé—®
- é—®é¢˜è¦æ›´å…·ä½“ï¼Œå¼•å¯¼ç”¨æˆ·ç»™å‡ºæ˜ç¡®ç­”æ¡ˆ

å¦‚æœåˆ¤æ–­ä¸éœ€è¦è¿½é—®ï¼Œè¯·ç”Ÿæˆæ–°é—®é¢˜ç»§ç»­è°ƒç ”ã€‚
"""

    # æ„å»ºè¿½é—®æ¨¡å¼çš„æç¤º
    follow_up_section = ""
    if should_follow_up:
        follow_up_section = f"""## è¿½é—®æ¨¡å¼ï¼ˆå¿…é¡»æ‰§è¡Œï¼‰

ä¸Šä¸€ä¸ªç”¨æˆ·å›ç­”éœ€è¦è¿½é—®ã€‚åŸå› ï¼š{follow_up_reason}

**ä¸Šä¸€ä¸ªé—®é¢˜**: {last_log.get('question', '')[:100] if last_log else ''}
**ç”¨æˆ·å›ç­”**: {last_log.get('answer', '') if last_log else ''}

è¿½é—®è¦æ±‚ï¼š
1. å¿…é¡»è®¾ç½® is_follow_up: true
2. é’ˆå¯¹ä¸Šä¸€ä¸ªå›ç­”è¿›è¡Œæ·±å…¥æé—®ï¼Œä¸è¦è·³åˆ°æ–°è¯é¢˜
3. è¿½é—®é—®é¢˜è¦æ›´å…·ä½“ã€æ›´æœ‰é’ˆå¯¹æ€§
4. å¼•å¯¼ç”¨æˆ·ç»™å‡ºå…·ä½“çš„åœºæ™¯ã€æ•°æ®ã€æˆ–æ˜ç¡®çš„é€‰æ‹©
5. å¯ä»¥ä½¿ç”¨"æ‚¨æåˆ°çš„XXXï¼Œèƒ½å¦å…·ä½“è¯´æ˜..."è¿™æ ·çš„å¥å¼
"""
    else:
        follow_up_section = """## é—®é¢˜ç”Ÿæˆè¦æ±‚

1. ç”Ÿæˆ 1 ä¸ªé’ˆå¯¹æ€§çš„é—®é¢˜ï¼Œç”¨äºæ”¶é›†è¯¥ç»´åº¦çš„å…³é”®ä¿¡æ¯
2. ä¸ºè¿™ä¸ªé—®é¢˜æä¾› 3-4 ä¸ªå…·ä½“çš„é€‰é¡¹
3. é€‰é¡¹è¦åŸºäºï¼š
   - è°ƒç ”ä¸»é¢˜çš„è¡Œä¸šç‰¹ç‚¹
   - å‚è€ƒæ–‡æ¡£ä¸­çš„ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
   - è”ç½‘æœç´¢çš„è¡Œä¸šçŸ¥è¯†ï¼ˆå¦‚æœ‰ï¼‰
   - å·²æ”¶é›†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
4. æ ¹æ®é—®é¢˜æ€§è´¨åˆ¤æ–­æ˜¯å•é€‰è¿˜æ˜¯å¤šé€‰ï¼š
   - å•é€‰åœºæ™¯ï¼šäº’æ–¥é€‰é¡¹ï¼ˆæ˜¯/å¦ï¼‰ã€ä¼˜å…ˆçº§é€‰æ‹©ã€å”¯ä¸€é€‰æ‹©
   - å¤šé€‰åœºæ™¯ï¼šå¯å¹¶å­˜çš„åŠŸèƒ½éœ€æ±‚ã€å¤šä¸ªç—›ç‚¹ã€å¤šç§ç”¨æˆ·è§’è‰²
5. å¦‚æœç”¨æˆ·çš„å›ç­”ä¸å‚è€ƒæ–‡æ¡£å†…å®¹æœ‰å†²çªï¼Œè¦åœ¨é—®é¢˜ä¸­æŒ‡å‡ºå¹¶è¯·æ±‚æ¾„æ¸…
"""

    prompt = f"""**ä¸¥æ ¼è¾“å‡ºè¦æ±‚ï¼šä½ çš„å›å¤å¿…é¡»æ˜¯çº¯ JSON å¯¹è±¡ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€markdown ä»£ç å—æˆ–å…¶ä»–æ–‡æœ¬ã€‚ç¬¬ä¸€ä¸ªå­—ç¬¦å¿…é¡»æ˜¯ {{ï¼Œæœ€åä¸€ä¸ªå­—ç¬¦å¿…é¡»æ˜¯ }}**

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éœ€æ±‚è°ƒç ”è®¿è°ˆå¸ˆï¼Œæ­£åœ¨è¿›è¡Œ"{topic}"çš„éœ€æ±‚è°ƒç ”ã€‚
ä½ çš„æ ¸å¿ƒèŒè´£æ˜¯**æ·±åº¦æŒ–æ˜ç”¨æˆ·çš„çœŸå®éœ€æ±‚**ï¼Œä¸æ»¡è¶³äºè¡¨é¢å›ç­”ã€‚

{chr(10).join(context_parts)}

## å½“å‰ä»»åŠ¡

ä½ ç°åœ¨éœ€è¦é’ˆå¯¹ã€Œ{dim_info.get('name', dimension)}ã€ç»´åº¦æ”¶é›†ä¿¡æ¯ã€‚
è¿™ä¸ªç»´åº¦å…³æ³¨ï¼š{dim_info.get('description', '')}

è¯¥ç»´åº¦å·²æ”¶é›†äº† {formal_questions_count} ä¸ªæ­£å¼é—®é¢˜çš„å›ç­”ï¼Œå…³é”®æ–¹é¢åŒ…æ‹¬ï¼š{', '.join(dim_info.get('key_aspects', []))}
{ai_eval_guidance}
{follow_up_section}

## è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

ä½ çš„å›å¤å¿…é¡»æ˜¯ä¸€ä¸ªçº¯ JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

{{
    "question": "ä½ çš„é—®é¢˜",
    "options": ["é€‰é¡¹1", "é€‰é¡¹2", "é€‰é¡¹3", "é€‰é¡¹4"],
    "multi_select": false,
    "is_follow_up": {'true' if should_follow_up else 'false æˆ– trueï¼ˆæ ¹æ®ä½ çš„åˆ¤æ–­ï¼‰'},
    "follow_up_reason": {json.dumps(follow_up_reason, ensure_ascii=False) if should_follow_up else '"ä½ çš„åˆ¤æ–­ç†ç”±" æˆ– null'},
    "conflict_detected": false,
    "conflict_description": null
}}

å­—æ®µè¯´æ˜ï¼š
- question: å­—ç¬¦ä¸²ï¼Œä½ è¦é—®çš„é—®é¢˜
- options: å­—ç¬¦ä¸²æ•°ç»„ï¼Œ3-4 ä¸ªé€‰é¡¹
- multi_select: å¸ƒå°”å€¼ï¼Œtrue=å¯å¤šé€‰ï¼Œfalse=å•é€‰
- is_follow_up: å¸ƒå°”å€¼ï¼Œtrue=è¿½é—®ï¼ˆé’ˆå¯¹ä¸Šä¸€å›ç­”æ·±å…¥ï¼‰ï¼Œfalse=æ–°é—®é¢˜
- follow_up_reason: å­—ç¬¦ä¸²æˆ– nullï¼Œè¿½é—®æ—¶è¯´æ˜åŸå› 
- conflict_detected: å¸ƒå°”å€¼
- conflict_description: å­—ç¬¦ä¸²æˆ– null

**å…³é”®æé†’ï¼š**
- ä¸è¦ä½¿ç”¨ ```json ä»£ç å—æ ‡è®°
- ä¸è¦åœ¨ JSON å‰åæ·»åŠ ä»»ä½•è¯´æ˜æ–‡å­—
- ç¡®ä¿ JSON è¯­æ³•å®Œå…¨æ­£ç¡®ï¼ˆæ‰€æœ‰å­—ç¬¦ä¸²ç”¨åŒå¼•å·ï¼Œå¸ƒå°”å€¼ç”¨ true/falseï¼Œç©ºå€¼ç”¨ nullï¼‰
- ä½ çš„æ•´ä¸ªå›å¤å°±æ˜¯è¿™ä¸ª JSON å¯¹è±¡ï¼Œæ²¡æœ‰å…¶ä»–å†…å®¹
- **é‡è¦**ï¼šä½œä¸ºä¸“ä¸šè®¿è°ˆå¸ˆï¼Œè¦å–„äºè¿½é—®ï¼ŒæŒ–æ˜è¡¨é¢å›ç­”èƒŒåçš„çœŸå®éœ€æ±‚"""

    return prompt, truncated_docs


def build_report_prompt(session: dict) -> str:
    """æ„å»ºæŠ¥å‘Šç”Ÿæˆ prompt"""
    topic = session.get("topic", "æœªçŸ¥é¡¹ç›®")
    description = session.get("description")  # è·å–ä¸»é¢˜æè¿°
    interview_log = session.get("interview_log", [])
    dimensions = session.get("dimensions", {})
    reference_docs = session.get("reference_docs", [])
    research_docs = session.get("research_docs", [])  # è·å–å·²æœ‰è°ƒç ”æˆæœ

    # æŒ‰ç»´åº¦æ•´ç†é—®ç­”
    qa_by_dim = {}
    for dim_key in DIMENSION_INFO:
        qa_by_dim[dim_key] = [log for log in interview_log if log.get("dimension") == dim_key]

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„éœ€æ±‚åˆ†æå¸ˆï¼Œéœ€è¦åŸºäºä»¥ä¸‹è®¿è°ˆè®°å½•ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„éœ€æ±‚è°ƒç ”æŠ¥å‘Šã€‚

## è°ƒç ”ä¸»é¢˜
{topic}
"""

    # å¦‚æœæœ‰ä¸»é¢˜æè¿°ï¼Œæ·»åŠ åˆ° prompt ä¸­
    if description:
        prompt += f"""
## ä¸»é¢˜æè¿°
{description}
"""

    prompt += """
## å‚è€ƒæ–‡æ¡£
"""

    if reference_docs:
        prompt += "ä»¥ä¸‹æ˜¯ç”¨æˆ·æä¾›çš„å‚è€ƒæ–‡æ¡£ï¼Œè¯·åœ¨ç”ŸæˆæŠ¥å‘Šæ—¶å‚è€ƒè¿™äº›å†…å®¹ï¼š\n\n"
        for doc in reference_docs:
            doc_name = doc.get('name', 'æ–‡æ¡£')
            prompt += f"### {doc_name}\n"
            if doc.get("content"):
                content = doc["content"]
                original_length = len(content)

                # ä½¿ç”¨æ™ºèƒ½æ‘˜è¦å¤„ç†é•¿æ–‡æ¡£
                if original_length > SMART_SUMMARY_THRESHOLD and ENABLE_SMART_SUMMARY:
                    processed_content, is_summarized = summarize_document(content, doc_name, topic)
                    if is_summarized:
                        prompt += f"{processed_content}\n"
                        prompt += f"*[åŸæ–‡æ¡£ {original_length} å­—ç¬¦ï¼Œå·²é€šè¿‡AIç”Ÿæˆæ‘˜è¦ä¿ç•™å…³é”®ä¿¡æ¯]*\n\n"
                    elif len(processed_content) > MAX_DOC_LENGTH:
                        prompt += f"{processed_content[:MAX_DOC_LENGTH]}\n"
                        prompt += f"*[æ–‡æ¡£å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ {MAX_DOC_LENGTH} å­—ç¬¦]*\n\n"
                    else:
                        prompt += f"{processed_content}\n\n"
                elif original_length > MAX_DOC_LENGTH:
                    prompt += f"{content[:MAX_DOC_LENGTH]}\n"
                    prompt += f"*[æ–‡æ¡£å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ {MAX_DOC_LENGTH} å­—ç¬¦]*\n\n"
                else:
                    prompt += f"{content}\n\n"
            else:
                prompt += "*[æ–‡æ¡£å†…å®¹ä¸ºç©º]*\n\n"
    else:
        prompt += "æ— å‚è€ƒæ–‡æ¡£\n"

    # æ·»åŠ å·²æœ‰è°ƒç ”æˆæœ
    if research_docs:
        prompt += "\n## å·²æœ‰è°ƒç ”æˆæœ\n"
        prompt += "ä»¥ä¸‹æ˜¯ç”¨æˆ·æä¾›çš„å·²æœ‰è°ƒç ”æˆæœï¼Œè¯·åœ¨ç”ŸæˆæŠ¥å‘Šæ—¶å‚è€ƒå¹¶æ•´åˆè¿™äº›å†…å®¹ï¼š\n\n"
        for doc in research_docs:
            doc_name = doc.get('name', 'è°ƒç ”æ–‡æ¡£')
            prompt += f"### {doc_name}\n"
            if doc.get("content"):
                content = doc["content"]
                original_length = len(content)

                # ä½¿ç”¨æ™ºèƒ½æ‘˜è¦å¤„ç†é•¿æ–‡æ¡£
                if original_length > SMART_SUMMARY_THRESHOLD and ENABLE_SMART_SUMMARY:
                    processed_content, is_summarized = summarize_document(content, doc_name, topic)
                    if is_summarized:
                        prompt += f"{processed_content}\n"
                        prompt += f"*[åŸè°ƒç ”æˆæœ {original_length} å­—ç¬¦ï¼Œå·²é€šè¿‡AIç”Ÿæˆæ‘˜è¦ä¿ç•™å…³é”®ä¿¡æ¯]*\n\n"
                    elif len(processed_content) > MAX_DOC_LENGTH:
                        prompt += f"{processed_content[:MAX_DOC_LENGTH]}\n"
                        prompt += f"*[è°ƒç ”æˆæœå†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ {MAX_DOC_LENGTH} å­—ç¬¦]*\n\n"
                    else:
                        prompt += f"{processed_content}\n\n"
                elif original_length > MAX_DOC_LENGTH:
                    prompt += f"{content[:MAX_DOC_LENGTH]}\n"
                    prompt += f"*[è°ƒç ”æˆæœå†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ {MAX_DOC_LENGTH} å­—ç¬¦]*\n\n"
                else:
                    prompt += f"{content}\n\n"

    prompt += "\n## è®¿è°ˆè®°å½•\n"

    for dim_key, dim_info in DIMENSION_INFO.items():
        prompt += f"\n### {dim_info['name']}\n"
        qa_list = qa_by_dim.get(dim_key, [])
        if qa_list:
            for qa in qa_list:
                prompt += f"**Q**: {qa['question']}\n"
                prompt += f"**A**: {qa['answer']}\n\n"
        else:
            prompt += "*è¯¥ç»´åº¦æš‚æ— æ”¶é›†æ•°æ®*\n"

    prompt += """
## æŠ¥å‘Šè¦æ±‚

è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„éœ€æ±‚è°ƒç ”æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š

1. **è°ƒç ”æ¦‚è¿°** - åŸºæœ¬ä¿¡æ¯ã€è°ƒç ”èƒŒæ™¯
2. **éœ€æ±‚æ‘˜è¦** - æ ¸å¿ƒéœ€æ±‚åˆ—è¡¨ã€ä¼˜å…ˆçº§çŸ©é˜µ
3. **è¯¦ç»†éœ€æ±‚åˆ†æ**
   - å®¢æˆ·/ç”¨æˆ·éœ€æ±‚ï¼ˆç—›ç‚¹ã€æœŸæœ›ã€åœºæ™¯ã€è§’è‰²ï¼‰
   - ä¸šåŠ¡æµç¨‹ï¼ˆå…³é”®æµç¨‹ã€å†³ç­–èŠ‚ç‚¹ï¼‰
   - æŠ€æœ¯çº¦æŸï¼ˆéƒ¨ç½²ã€é›†æˆã€å®‰å…¨ï¼‰
   - é¡¹ç›®çº¦æŸï¼ˆé¢„ç®—ã€æ—¶é—´ã€èµ„æºï¼‰
4. **å¯è§†åŒ–åˆ†æ** - ä½¿ç”¨ Mermaid å›¾è¡¨å±•ç¤ºå…³é”®ä¿¡æ¯
5. **æ–¹æ¡ˆå»ºè®®** - åŸºäºéœ€æ±‚çš„å¯è¡Œå»ºè®®
6. **é£é™©è¯„ä¼°** - æ½œåœ¨é£é™©å’Œåº”å¯¹ç­–ç•¥
7. **ä¸‹ä¸€æ­¥è¡ŒåŠ¨** - å…·ä½“çš„è¡ŒåŠ¨é¡¹

**æ³¨æ„**ï¼šä¸éœ€è¦åŒ…å«"é™„å½•"ç« èŠ‚ï¼Œå®Œæ•´çš„è®¿è°ˆè®°å½•ä¼šåœ¨æŠ¥å‘Šç”Ÿæˆåè‡ªåŠ¨è¿½åŠ ã€‚

## Mermaid å›¾è¡¨è§„èŒƒ

è¯·åœ¨æŠ¥å‘Šä¸­åŒ…å«ä»¥ä¸‹ç±»å‹çš„ Mermaid å›¾è¡¨ã€‚**é™¤ quadrantChart å¤–ï¼Œæ‰€æœ‰å›¾è¡¨éƒ½åº”ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾**ã€‚

### 1. ä¼˜å…ˆçº§çŸ©é˜µï¼ˆå¿…é¡»ï¼‰
ä½¿ç”¨è±¡é™å›¾å±•ç¤ºéœ€æ±‚ä¼˜å…ˆçº§ï¼Œ**ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼**ï¼š

```mermaid
quadrantChart
    title Priority Matrix
    x-axis Low Urgency --> High Urgency
    y-axis Low Importance --> High Importance
    quadrant-1 Do First
    quadrant-2 Schedule
    quadrant-3 Delegate
    quadrant-4 Eliminate

    Requirement1: [0.8, 0.9]
    Requirement2: [0.3, 0.7]
    Requirement3: [0.6, 0.5]
```

**quadrantChart ä¸¥æ ¼è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š**
- titleã€x-axisã€y-axisã€quadrant æ ‡ç­¾**å¿…é¡»ç”¨è‹±æ–‡**ï¼ˆquadrantChart ä¸æ”¯æŒä¸­æ–‡ï¼‰
- æ•°æ®ç‚¹åç§°**å¿…é¡»ç”¨è‹±æ–‡æˆ–æ‹¼éŸ³**ï¼Œä¸èƒ½ç”¨ä¸­æ–‡
- æ•°æ®ç‚¹æ ¼å¼ï¼š`Name: [x, y]`ï¼Œxå’ŒyèŒƒå›´0-1
- ä¸è¦åœ¨æ ‡ç­¾ä¸­ä½¿ç”¨æ‹¬å·ã€å†’å·ç­‰ç‰¹æ®Šç¬¦å·
- åœ¨å›¾è¡¨ä¸‹æ–¹ç”¨ä¸­æ–‡è¡¨æ ¼è¯´æ˜æ¯ä¸ªæ•°æ®ç‚¹çš„å«ä¹‰

### 2. ä¸šåŠ¡æµç¨‹å›¾ï¼ˆæ¨èï¼‰
ä½¿ç”¨ flowchart å±•ç¤ºå…³é”®ä¸šåŠ¡æµç¨‹ï¼Œ**ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾**ï¼š

```mermaid
flowchart TD
    A[å¼€å§‹] --> B{åˆ¤æ–­æ¡ä»¶}
    B -->|æ˜¯| C[å¤„ç†æµç¨‹1]
    B -->|å¦| D[å¤„ç†æµç¨‹2]
    C --> E[ç»“æŸ]
    D --> E
```

**flowchart è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š**
- èŠ‚ç‚¹IDä½¿ç”¨è‹±æ–‡å­—æ¯ï¼ˆå¦‚ Aã€Bã€Cï¼‰ï¼ŒèŠ‚ç‚¹æ ‡ç­¾ä½¿ç”¨ä¸­æ–‡ï¼ˆå¦‚ `A[ä¸­æ–‡æ ‡ç­¾]`ï¼‰
- è¿æ¥çº¿æ ‡ç­¾ä½¿ç”¨ä¸­æ–‡ï¼ˆå¦‚ `-->|æ˜¯|`ï¼‰
- subgraph æ ‡é¢˜ä½¿ç”¨ä¸­æ–‡ï¼ˆå¦‚ `subgraph å­æµç¨‹åç§°`ï¼‰
- **æ¯ä¸ª subgraph å¿…é¡»æœ‰å¯¹åº”çš„ end å…³é—­**
- èŠ‚ç‚¹æ ‡ç­¾ä¸­**ä¸¥ç¦ä½¿ç”¨ä»¥ä¸‹ç‰¹æ®Šå­—ç¬¦**ï¼š
  - åŠè§’å†’å· `:` - ç”¨çŸ­æ¨ªçº¿ `-` æˆ–ç©ºæ ¼æ›¿ä»£
  - åŠè§’å¼•å· `"` - ç”¨å…¨è§’å¼•å· "" æˆ–ä¹¦åå· ã€Šã€‹ æ›¿ä»£
  - åŠè§’æ‹¬å· `()` - ç”¨å…¨è§’æ‹¬å· ï¼ˆï¼‰ æ›¿ä»£
  - HTML æ ‡ç­¾å¦‚ `<br>` - ç”¨ç©ºæ ¼æˆ–æ¢è¡Œæ›¿ä»£
- è±å½¢åˆ¤æ–­èŠ‚ç‚¹ä½¿ç”¨ `{ä¸­æ–‡}` æ ¼å¼
- **ä¸è¦åœ¨åŒä¸€ä¸ª flowchart ä¸­åµŒå¥—è¿‡å¤šå±‚çº§ï¼ˆæœ€å¤š2å±‚ subgraphï¼‰**
- **è¿æ¥çº¿ä½¿ç”¨ `-->` æˆ– `---|` æ ¼å¼ï¼Œä¸è¦ä½¿ç”¨ `---`**

### 3. éœ€æ±‚åˆ†ç±»é¥¼å›¾ï¼ˆå¯é€‰ï¼‰
ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾ï¼š
```mermaid
pie title éœ€æ±‚åˆ†å¸ƒ
    "åŠŸèƒ½éœ€æ±‚" : 45
    "æ€§èƒ½éœ€æ±‚" : 25
    "å®‰å…¨éœ€æ±‚" : 20
    "æ˜“ç”¨æ€§" : 10
```

### 4. éƒ¨ç½²æ¶æ„å›¾ï¼ˆå¦‚æ¶‰åŠæŠ€æœ¯çº¦æŸï¼‰
å¦‚æœè®¿è°ˆä¸­æ¶‰åŠéƒ¨ç½²æ¨¡å¼ã€ç³»ç»Ÿæ¶æ„ç­‰æŠ€æœ¯è¯é¢˜ï¼Œå¯ä½¿ç”¨ flowchart å±•ç¤ºéƒ¨ç½²æ¶æ„ï¼š

```mermaid
flowchart LR
    A[å®¢æˆ·ç«¯] --> B[è´Ÿè½½å‡è¡¡]
    B --> C[åº”ç”¨æœåŠ¡å™¨]
    C --> D[æ•°æ®åº“]
```

**éƒ¨ç½²æ¶æ„å›¾è§„åˆ™ï¼š**
- ä½¿ç”¨ flowchart LRï¼ˆä»å·¦åˆ°å³ï¼‰æˆ– flowchart TDï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰
- èŠ‚ç‚¹IDä½¿ç”¨è‹±æ–‡å­—æ¯ï¼Œæ ‡ç­¾ä½¿ç”¨ä¸­æ–‡
- ä¿æŒç»“æ„ç®€æ´ï¼Œé¿å…è¿‡åº¦å¤æ‚çš„åµŒå¥—

## é‡è¦æé†’
- æ‰€æœ‰å†…å®¹å¿…é¡»ä¸¥æ ¼åŸºäºè®¿è°ˆè®°å½•ï¼Œä¸å¾—ç¼–é€ 
- ä½¿ç”¨ Markdown æ ¼å¼ï¼ŒMermaid ä»£ç å—ä½¿ç”¨ ```mermaid æ ‡è®°
- **flowchartã€pie ç­‰å›¾è¡¨ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾**ï¼ŒquadrantChart å› æŠ€æœ¯é™åˆ¶å¿…é¡»ç”¨è‹±æ–‡
- ä¼˜å…ˆçº§çŸ©é˜µä¸­çš„åæ ‡å€¼è¯·æ ¹æ®å®é™…éœ€æ±‚è¯„ä¼°
- æŠ¥å‘Šè¦ä¸“ä¸šã€ç»“æ„æ¸…æ™°ã€å¯æ“ä½œ
- **Mermaid è¯­æ³•è¦æ±‚ä¸¥æ ¼ï¼Œè¯·ä»”ç»†æ£€æŸ¥æ¯ä¸ªå›¾è¡¨çš„è¯­æ³•æ­£ç¡®æ€§**
- æŠ¥å‘Šæœ«å°¾ä½¿ç”¨ç½²åï¼š*æ­¤æŠ¥å‘Šç”± Deep Vision æ·±ç³-æ™ºèƒ½éœ€æ±‚è°ƒç ”åŠ©æ‰‹ç”Ÿæˆ*

è¯·ç”Ÿæˆå®Œæ•´çš„æŠ¥å‘Šï¼š"""

    return prompt


async def call_claude_async(prompt: str, max_tokens: int = None) -> Optional[str]:
    """å¼‚æ­¥è°ƒç”¨ Claude APIï¼Œå¸¦è¶…æ—¶æ§åˆ¶"""
    if not claude_client:
        return None

    if max_tokens is None:
        max_tokens = MAX_TOKENS_DEFAULT

    try:
        if ENABLE_DEBUG_LOG:
            print(f"ğŸ¤– å¼‚æ­¥è°ƒç”¨ Claude APIï¼Œmax_tokens={max_tokens}ï¼Œtimeout={API_TIMEOUT}s")

        # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
        message = claude_client.messages.create(
            model=MODEL_NAME,
            max_tokens=max_tokens,
            messages=[{"role": "user", "content": prompt}],
            timeout=API_TIMEOUT
        )

        response_text = message.content[0].text

        if ENABLE_DEBUG_LOG:
            print(f"âœ… API å¼‚æ­¥å“åº”æˆåŠŸï¼Œé•¿åº¦: {len(response_text)} å­—ç¬¦")

        return response_text
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ Claude API å¼‚æ­¥è°ƒç”¨å¤±è´¥: {error_msg}")

        if "timeout" in error_msg.lower():
            print(f"   åŸå› : API è°ƒç”¨è¶…æ—¶ï¼ˆè¶…è¿‡{API_TIMEOUT}ç§’ï¼‰")
        elif "rate" in error_msg.lower():
            print(f"   åŸå› : API è¯·æ±‚é¢‘ç‡é™åˆ¶")
        elif "authentication" in error_msg.lower() or "api key" in error_msg.lower():
            print(f"   åŸå› : API Key è®¤è¯å¤±è´¥")

        return None


def call_claude(prompt: str, max_tokens: int = None, retry_on_timeout: bool = True,
                call_type: str = "unknown", truncated_docs: list = None) -> Optional[str]:
    """åŒæ­¥è°ƒç”¨ Claude APIï¼Œå¸¦è¶…æ—¶æ§åˆ¶å’Œå®¹é”™æœºåˆ¶"""
    import time

    if not claude_client:
        return None

    if max_tokens is None:
        max_tokens = MAX_TOKENS_DEFAULT

    start_time = time.time()
    success = False
    timeout_occurred = False
    error_message = None
    response_text = None

    try:
        if ENABLE_DEBUG_LOG:
            print(f"ğŸ¤– è°ƒç”¨ Claude APIï¼Œmax_tokens={max_tokens}ï¼Œtimeout={API_TIMEOUT}s")

        # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
        message = claude_client.messages.create(
            model=MODEL_NAME,
            max_tokens=max_tokens,
            messages=[{"role": "user", "content": prompt}],
            timeout=API_TIMEOUT
        )

        response_text = message.content[0].text
        success = True

        if ENABLE_DEBUG_LOG:
            print(f"âœ… API å“åº”æˆåŠŸï¼Œé•¿åº¦: {len(response_text)} å­—ç¬¦")

    except Exception as e:
        error_message = str(e)
        print(f"âŒ Claude API è°ƒç”¨å¤±è´¥: {error_message}")

        # è¯¦ç»†çš„é”™è¯¯åˆ†ç±»å’Œå®¹é”™å¤„ç†
        if "timeout" in error_message.lower():
            timeout_occurred = True
            print(f"   åŸå› : API è°ƒç”¨è¶…æ—¶ï¼ˆè¶…è¿‡{API_TIMEOUT}ç§’ï¼‰")

            # è¶…æ—¶å®¹é”™ï¼šå¦‚æœå…è®¸é‡è¯•ï¼Œå°è¯•å‡å°‘ prompt é•¿åº¦
            if retry_on_timeout and len(prompt) > 5000:
                print(f"   ğŸ”„ å°è¯•å®¹é”™é‡è¯•ï¼šæˆªæ–­ prompt åé‡è¯•...")
                # æˆªæ–­ prompt åˆ°åŸæ¥çš„ 70%
                truncated_prompt = prompt[:int(len(prompt) * 0.7)]
                truncated_prompt += "\n\n[æ³¨æ„ï¼šç”±äºå†…å®¹è¿‡é•¿ï¼Œéƒ¨åˆ†ä¸Šä¸‹æ–‡å·²è¢«æˆªæ–­ï¼Œè¯·åŸºäºå·²æœ‰ä¿¡æ¯è¿›è¡Œå›ç­”]"

                # é€’å½’é‡è¯•ï¼ˆç¦æ­¢å†æ¬¡é‡è¯•ï¼‰
                response_text = call_claude(
                    truncated_prompt, max_tokens,
                    retry_on_timeout=False,
                    call_type=call_type + "_retry",
                    truncated_docs=truncated_docs
                )

                if response_text:
                    success = True

        elif "rate" in error_message.lower():
            print(f"   åŸå› : API è¯·æ±‚é¢‘ç‡é™åˆ¶")
        elif "authentication" in error_message.lower() or "api key" in error_message.lower():
            print(f"   åŸå› : API Key è®¤è¯å¤±è´¥")

    finally:
        # è®°å½•æŒ‡æ ‡
        response_time = time.time() - start_time
        metrics_collector.record_api_call(
            call_type=call_type,
            prompt_length=len(prompt),
            response_time=response_time,
            success=success,
            timeout=timeout_occurred,
            error_msg=error_message if not success else None,
            truncated_docs=truncated_docs,
            max_tokens=max_tokens
        )

    return response_text


# ============ é™æ€æ–‡ä»¶ ============

@app.route('/')
def index():
    return send_from_directory('.', 'index.html')


@app.route('/<path:filename>')
def static_files(filename):
    return send_from_directory('.', filename)


# ============ ä¼šè¯ API ============

@app.route('/api/sessions', methods=['GET'])
def list_sessions():
    """è·å–æ‰€æœ‰ä¼šè¯"""
    sessions = []
    for f in SESSIONS_DIR.glob("*.json"):
        try:
            data = json.loads(f.read_text(encoding="utf-8"))
            sessions.append({
                "session_id": data.get("session_id"),
                "topic": data.get("topic"),
                "status": data.get("status"),
                "created_at": data.get("created_at"),
                "updated_at": data.get("updated_at"),
                "dimensions": data.get("dimensions", {}),
                "interview_count": len(data.get("interview_log", []))
            })
        except Exception as e:
            print(f"è¯»å–ä¼šè¯å¤±è´¥ {f}: {e}")

    sessions.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
    return jsonify(sessions)


@app.route('/api/sessions', methods=['POST'])
def create_session():
    """åˆ›å»ºæ–°ä¼šè¯"""
    data = request.get_json()
    topic = data.get("topic", "æœªå‘½åè°ƒç ”")
    description = data.get("description")  # è·å–å¯é€‰çš„ä¸»é¢˜æè¿°

    session_id = generate_session_id()
    now = get_utc_now()

    session = {
        "session_id": session_id,
        "topic": topic,
        "description": description,  # å­˜å‚¨ä¸»é¢˜æè¿°
        "created_at": now,
        "updated_at": now,
        "status": "in_progress",
        "scenario": None,
        "dimensions": {
            "customer_needs": {"coverage": 0, "items": []},
            "business_process": {"coverage": 0, "items": []},
            "tech_constraints": {"coverage": 0, "items": []},
            "project_constraints": {"coverage": 0, "items": []}
        },
        "reference_docs": [],
        "research_docs": [],  # å·²æœ‰è°ƒç ”æˆæœæ–‡æ¡£
        "interview_log": [],
        "requirements": [],
        "summary": None
    }

    session_file = SESSIONS_DIR / f"{session_id}.json"
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify(session)


@app.route('/api/sessions/<session_id>', methods=['GET'])
def get_session(session_id):
    """è·å–ä¼šè¯è¯¦æƒ…"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))
    return jsonify(session)


@app.route('/api/sessions/<session_id>', methods=['PUT'])
def update_session(session_id):
    """æ›´æ–°ä¼šè¯"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    updates = request.get_json()
    session = json.loads(session_file.read_text(encoding="utf-8"))

    for key, value in updates.items():
        if key != "session_id":
            session[key] = value

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify(session)


@app.route('/api/sessions/<session_id>', methods=['DELETE'])
def delete_session(session_id):
    """åˆ é™¤ä¼šè¯"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if session_file.exists():
        session_file.unlink()
    return jsonify({"success": True})


# ============ AI é©±åŠ¨çš„è®¿è°ˆ API ============

@app.route('/api/sessions/<session_id>/next-question', methods=['POST'])
def get_next_question(session_id):
    """è·å–ä¸‹ä¸€ä¸ªé—®é¢˜ï¼ˆAI ç”Ÿæˆï¼‰"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))
    data = request.get_json() or {}
    dimension = data.get("dimension", "customer_needs")

    # æ£€æŸ¥æ˜¯å¦æœ‰ Claude API
    if not claude_client:
        return jsonify({
            "error": "AI æœåŠ¡æœªå¯ç”¨",
            "detail": "è¯·è”ç³»ç®¡ç†å‘˜é…ç½® ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡"
        }), 503

    # è·å–å½“å‰ç»´åº¦çš„æ‰€æœ‰è®°å½•
    all_dim_logs = [log for log in session.get("interview_log", []) if log.get("dimension") == dimension]

    # è®¡ç®—æ­£å¼é—®é¢˜æ•°é‡ï¼ˆæ’é™¤è¿½é—®ï¼‰
    formal_questions_count = len([log for log in all_dim_logs if not log.get("is_follow_up", False)])

    # æ£€æŸ¥ç»´åº¦æ˜¯å¦å·²å®Œæˆï¼ˆæ­£å¼é—®é¢˜è¾¾åˆ° 3 ä¸ªä¸”æ²¡æœ‰éœ€è¦è¿½é—®çš„å›ç­”ï¼‰
    if formal_questions_count >= 3:
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰éœ€è¦è¿½é—®çš„å›ç­”
        needs_follow_up = any(log.get("needs_follow_up", False) for log in all_dim_logs if not log.get("is_follow_up", False))
        if not needs_follow_up:
            return jsonify({
                "dimension": dimension,
                "completed": True
            })

    # è°ƒç”¨ Claude ç”Ÿæˆé—®é¢˜
    try:
        prompt, truncated_docs = build_interview_prompt(session, dimension, all_dim_logs)

        # æ—¥å¿—ï¼šè®°å½• prompt é•¿åº¦ï¼ˆä¾¿äºç›‘æ§å’Œè°ƒä¼˜ï¼‰
        if ENABLE_DEBUG_LOG:
            ref_docs_count = len(session.get("reference_docs", []))
            research_docs_count = len(session.get("research_docs", []))
            print(f"ğŸ“Š è®¿è°ˆ Prompt ç»Ÿè®¡ï¼šæ€»é•¿åº¦={len(prompt)}å­—ç¬¦ï¼Œå‚è€ƒæ–‡æ¡£={ref_docs_count}ä¸ªï¼Œè°ƒç ”æˆæœ={research_docs_count}ä¸ª")
            if truncated_docs:
                print(f"âš ï¸  æ–‡æ¡£æˆªæ–­ï¼š{len(truncated_docs)}ä¸ªæ–‡æ¡£è¢«æˆªæ–­")

        response = call_claude(
            prompt,
            max_tokens=MAX_TOKENS_QUESTION,
            call_type="question",
            truncated_docs=truncated_docs
        )

        if not response:
            return jsonify({
                "error": "AI å“åº”å¤±è´¥",
                "detail": "æœªèƒ½ä» AI æœåŠ¡è·å–å“åº”ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
            }), 503

        # è§£æ JSON å“åº”
        result = None
        parse_error = None

        if ENABLE_DEBUG_LOG:
            print(f"ğŸ“ AI åŸå§‹å“åº” (å‰500å­—): {response[:500]}")

        # æ–¹æ³•1: ç›´æ¥å°è¯•è§£æï¼ˆå¦‚æœAIä¸¥æ ¼éµå®ˆæŒ‡ä»¤ï¼‰
        try:
            cleaned = response.strip()
            if cleaned.startswith('{') and cleaned.endswith('}'):
                result = json.loads(cleaned)
                if ENABLE_DEBUG_LOG:
                    print(f"âœ… æ–¹æ³•1æˆåŠŸ: ç›´æ¥è§£æ")
        except json.JSONDecodeError as e:
            parse_error = e
            if ENABLE_DEBUG_LOG:
                print(f"âš ï¸ æ–¹æ³•1å¤±è´¥: {e}")

        # æ–¹æ³•2: å°è¯•æå– ```json ä»£ç å—
        if result is None and "```json" in response:
            try:
                json_start = response.find("```json") + 7
                json_end = response.find("```", json_start)
                if json_end > json_start:
                    json_str = response[json_start:json_end].strip()
                    result = json.loads(json_str)
                    if ENABLE_DEBUG_LOG:
                        print(f"âœ… æ–¹æ³•2æˆåŠŸ: ä»ä»£ç å—æå–")
            except json.JSONDecodeError as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•2å¤±è´¥ (JSONé”™è¯¯): {e}")
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•2å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æ–¹æ³•3: æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡ï¼ˆèŠ±æ‹¬å·é…å¯¹ï¼‰
        if result is None:
            try:
                json_start = response.find('{')
                if json_start >= 0:
                    brace_count = 0
                    json_end = -1
                    in_string = False
                    escape_next = False

                    for i in range(json_start, len(response)):
                        char = response[i]

                        if escape_next:
                            escape_next = False
                            continue

                        if char == '\\':
                            escape_next = True
                            continue

                        if char == '"' and not escape_next:
                            in_string = not in_string
                            continue

                        if not in_string:
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    json_end = i + 1
                                    break

                    if json_end > json_start:
                        try:
                            json_str = response[json_start:json_end]
                            result = json.loads(json_str)
                            if ENABLE_DEBUG_LOG:
                                print(f"âœ… æ–¹æ³•3æˆåŠŸ: èŠ±æ‹¬å·é…å¯¹æå–")
                        except json.JSONDecodeError as e:
                            parse_error = e
                            if ENABLE_DEBUG_LOG:
                                print(f"âš ï¸ æ–¹æ³•3å¤±è´¥ (JSONé”™è¯¯): {e}")
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•3å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æ–¹æ³•4: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON å¯¹è±¡
        if result is None:
            try:
                import re
                json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
                matches = re.findall(json_pattern, response, re.DOTALL)
                for match in matches:
                    try:
                        candidate = json.loads(match)
                        # éªŒè¯å¿…é¡»æœ‰ question å­—æ®µ
                        if isinstance(candidate, dict) and "question" in candidate:
                            result = candidate
                            if ENABLE_DEBUG_LOG:
                                print(f"âœ… æ–¹æ³•4æˆåŠŸ: æ­£åˆ™è¡¨è¾¾å¼æå–")
                            break
                    except json.JSONDecodeError:
                        continue
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•4å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æ–¹æ³•5: å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSONï¼ˆè¡¥å…¨ç¼ºå¤±å­—æ®µï¼‰
        if result is None and '{' in response and '"question"' in response:
            try:
                if ENABLE_DEBUG_LOG:
                    print(f"ğŸ”§ å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON...")

                # æ‰¾åˆ°JSONå¯¹è±¡çš„å¼€å§‹ä½ç½®
                json_start = response.find('{')
                json_content = response[json_start:]

                # å°è¯•è¡¥å…¨ç¼ºå¤±çš„ç»“å°¾éƒ¨åˆ†
                if '"options"' in json_content and '"question"' in json_content:
                    # å¦‚æœæœ‰optionsæ•°ç»„ä½†æ²¡æœ‰æ­£ç¡®ç»“æŸï¼Œå°è¯•è¡¥å…¨
                    if json_content.count('[') > json_content.count(']'):
                        json_content += ']'
                    if json_content.count('{') > json_content.count('}'):
                        # æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
                        if '"multi_select"' not in json_content:
                            json_content += ', "multi_select": false'
                        if '"is_follow_up"' not in json_content:
                            json_content += ', "is_follow_up": false'
                        json_content += '}'

                    # å°è¯•è§£æä¿®å¤åçš„JSON
                    try:
                        result = json.loads(json_content)
                        if isinstance(result, dict) and "question" in result:
                            if ENABLE_DEBUG_LOG:
                                print(f"âœ… æ–¹æ³•5æˆåŠŸ: JSONä¿®å¤å®Œæˆ")
                    except json.JSONDecodeError as e:
                        if ENABLE_DEBUG_LOG:
                            print(f"âš ï¸ æ–¹æ³•5å¤±è´¥: ä¿®å¤åä»æ— æ³•è§£æ - {e}")
            except Exception as e:
                parse_error = e
                if ENABLE_DEBUG_LOG:
                    print(f"âš ï¸ æ–¹æ³•5å¤±è´¥ (å…¶ä»–é”™è¯¯): {e}")

        # æˆåŠŸè§£æ
        if result is not None and isinstance(result, dict):
            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
            if "question" in result and "options" in result:
                result["dimension"] = dimension
                result["ai_generated"] = True
                # è¡¥å…¨å¯èƒ½ç¼ºå¤±çš„å­—æ®µ
                if "multi_select" not in result:
                    result["multi_select"] = False
                if "is_follow_up" not in result:
                    result["is_follow_up"] = False
                return jsonify(result)

        # æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥äº†
        if ENABLE_DEBUG_LOG:
            print(f"âŒ æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥")
            print(f"ğŸ“„ AI å“åº”å‰500å­—ç¬¦:\n{response[:500] if response else 'None'}")
            print(f"ğŸ“„ æœ€åè§£æé”™è¯¯: {str(parse_error) if parse_error else 'æœªçŸ¥'}")

        return jsonify({
            "error": "AI å“åº”æ ¼å¼é”™è¯¯",
            "detail": "AI è¿”å›çš„å†…å®¹æ— æ³•è§£æä¸ºæœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚è¯·ç‚¹å‡»ã€Œé‡è¯•ã€æŒ‰é’®é‡æ–°ç”Ÿæˆé—®é¢˜ã€‚"
        }), 503

    except Exception as e:
        print(f"ç”Ÿæˆé—®é¢˜æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        error_msg = str(e)

        # æ ¹æ®å¼‚å¸¸ç±»å‹æä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
        if "connection" in error_msg.lower() or "network" in error_msg.lower():
            return jsonify({
                "error": "ç½‘ç»œè¿æ¥å¤±è´¥",
                "detail": "æ— æ³•è¿æ¥åˆ° AI æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
            }), 503
        elif "timeout" in error_msg.lower():
            return jsonify({
                "error": "è¯·æ±‚è¶…æ—¶",
                "detail": "AI æœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
            }), 503
        elif "authentication" in error_msg.lower() or "api key" in error_msg.lower():
            return jsonify({
                "error": "API è®¤è¯å¤±è´¥",
                "detail": "API Key æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·è”ç³»ç®¡ç†å‘˜"
            }), 503
        elif "rate limit" in error_msg.lower():
            return jsonify({
                "error": "è¯·æ±‚é¢‘ç‡è¶…é™",
                "detail": "AI æœåŠ¡è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"
            }), 503
        else:
            return jsonify({
                "error": "ç”Ÿæˆé—®é¢˜å¤±è´¥",
                "detail": f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {error_msg}"
            }), 503


def get_fallback_question(session: dict, dimension: str) -> dict:
    """è·å–å¤‡ç”¨é—®é¢˜ï¼ˆæ—  AI æ—¶ä½¿ç”¨ï¼‰"""
    fallback_questions = {
        "customer_needs": [
            {"question": "æ‚¨å¸Œæœ›é€šè¿‡è¿™ä¸ªé¡¹ç›®è§£å†³å“ªäº›æ ¸å¿ƒé—®é¢˜ï¼Ÿ", "options": ["æå‡å·¥ä½œæ•ˆç‡", "é™ä½è¿è¥æˆæœ¬", "æ”¹å–„ç”¨æˆ·ä½“éªŒ", "å¢å¼ºæ•°æ®åˆ†æèƒ½åŠ›"], "multi_select": True},
            {"question": "ä¸»è¦çš„ç”¨æˆ·ç¾¤ä½“æœ‰å“ªäº›ï¼Ÿ", "options": ["å†…éƒ¨å‘˜å·¥", "å¤–éƒ¨å®¢æˆ·", "åˆä½œä¼™ä¼´", "ç®¡ç†å±‚"], "multi_select": True},
            {"question": "ç”¨æˆ·æœ€æœŸæœ›è·å¾—çš„æ ¸å¿ƒä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ", "options": ["èŠ‚çœæ—¶é—´", "å‡å°‘é”™è¯¯", "è·å–æ´å¯Ÿ", "æå‡åä½œ"], "multi_select": False},
        ],
        "business_process": [
            {"question": "å½“å‰ä¸šåŠ¡æµç¨‹ä¸­éœ€è¦ä¼˜åŒ–çš„ç¯èŠ‚æœ‰å“ªäº›ï¼Ÿ", "options": ["æ•°æ®å½•å…¥", "å®¡æ‰¹æµç¨‹", "æŠ¥è¡¨ç”Ÿæˆ", "è·¨éƒ¨é—¨åä½œ"], "multi_select": True},
            {"question": "å…³é”®ä¸šåŠ¡æµç¨‹æ¶‰åŠå“ªäº›éƒ¨é—¨ï¼Ÿ", "options": ["é”€å”®éƒ¨é—¨", "æŠ€æœ¯éƒ¨é—¨", "è´¢åŠ¡éƒ¨é—¨", "è¿è¥éƒ¨é—¨"], "multi_select": True},
            {"question": "æµç¨‹ä¸­æœ€å…³é”®çš„å†³ç­–èŠ‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ", "options": ["å®¡æ‰¹èŠ‚ç‚¹", "åˆ†é…èŠ‚ç‚¹", "éªŒæ”¶èŠ‚ç‚¹", "ç»“ç®—èŠ‚ç‚¹"], "multi_select": False},
        ],
        "tech_constraints": [
            {"question": "æœŸæœ›çš„ç³»ç»Ÿéƒ¨ç½²æ–¹å¼æ˜¯ï¼Ÿ", "options": ["å…¬æœ‰äº‘éƒ¨ç½²", "ç§æœ‰äº‘éƒ¨ç½²", "æ··åˆäº‘éƒ¨ç½²", "æœ¬åœ°éƒ¨ç½²"], "multi_select": False},
            {"question": "éœ€è¦ä¸å“ªäº›ç°æœ‰ç³»ç»Ÿé›†æˆï¼Ÿ", "options": ["ERPç³»ç»Ÿ", "CRMç³»ç»Ÿ", "OAåŠå…¬ç³»ç»Ÿ", "è´¢åŠ¡ç³»ç»Ÿ"], "multi_select": True},
            {"question": "å¯¹ç³»ç»Ÿå®‰å…¨æ€§çš„è¦æ±‚æ˜¯ï¼Ÿ", "options": ["ç­‰ä¿äºŒçº§", "ç­‰ä¿ä¸‰çº§", "åŸºç¡€å®‰å…¨å³å¯", "éœ€è¦è¯¦ç»†è¯„ä¼°"], "multi_select": False},
        ],
        "project_constraints": [
            {"question": "é¡¹ç›®çš„é¢„æœŸé¢„ç®—èŒƒå›´æ˜¯ï¼Ÿ", "options": ["10ä¸‡ä»¥å†…", "10-50ä¸‡", "50-100ä¸‡", "100ä¸‡ä»¥ä¸Š"], "multi_select": False},
            {"question": "æœŸæœ›çš„ä¸Šçº¿æ—¶é—´æ˜¯ï¼Ÿ", "options": ["1ä¸ªæœˆå†…", "1-3ä¸ªæœˆ", "3-6ä¸ªæœˆ", "6ä¸ªæœˆä»¥ä¸Š"], "multi_select": False},
            {"question": "é¡¹ç›®å›¢é˜Ÿçš„èµ„æºæƒ…å†µå¦‚ä½•ï¼Ÿ", "options": ["æœ‰ä¸“èŒå›¢é˜Ÿ", "å…¼èŒå‚ä¸", "å®Œå…¨å¤–åŒ…", "éœ€è¦è¯„ä¼°"], "multi_select": False},
        ]
    }

    # è·å–è¯¥ç»´åº¦å·²å›ç­”çš„é—®é¢˜æ•°
    answered = len([log for log in session.get("interview_log", []) if log.get("dimension") == dimension])
    questions = fallback_questions.get(dimension, [])

    if answered < len(questions):
        q = questions[answered]
        return {
            "question": q["question"],
            "options": q["options"],
            "multi_select": q.get("multi_select", False),
            "dimension": dimension,
            "ai_generated": False,
            "is_follow_up": False
        }

    # ç»´åº¦å·²å®Œæˆ
    return {
        "question": None,
        "dimension": dimension,
        "completed": True
    }


@app.route('/api/sessions/<session_id>/submit-answer', methods=['POST'])
def submit_answer(session_id):
    """æäº¤å›ç­”"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))
    data = request.get_json()

    question = data.get("question")
    answer = data.get("answer")
    dimension = data.get("dimension")
    options = data.get("options", [])
    is_follow_up = data.get("is_follow_up", False)

    # ä½¿ç”¨å¢å¼ºç‰ˆè¯„ä¼°å‡½æ•°åˆ¤æ–­å›ç­”æ˜¯å¦éœ€è¦è¿½é—®
    eval_result = evaluate_answer_depth(
        question=question,
        answer=answer,
        dimension=dimension,
        options=options,
        is_follow_up=is_follow_up
    )
    needs_follow_up = eval_result["needs_follow_up"]
    follow_up_signals = eval_result["signals"]

    if ENABLE_DEBUG_LOG and (needs_follow_up or eval_result["suggest_ai_eval"]):
        print(f"ğŸ“ å›ç­”è¯„ä¼°: signals={follow_up_signals}, needs_follow_up={needs_follow_up}")

    # æ·»åŠ åˆ°è®¿è°ˆè®°å½•
    log_entry = {
        "timestamp": get_utc_now(),
        "question": question,
        "answer": answer,
        "dimension": dimension,
        "options": options,
        "is_follow_up": is_follow_up,
        "needs_follow_up": needs_follow_up,
        "follow_up_signals": follow_up_signals  # è®°å½•æ£€æµ‹åˆ°çš„ä¿¡å·
    }
    session["interview_log"].append(log_entry)

    # æ›´æ–°ç»´åº¦æ•°æ®ï¼ˆåªæœ‰æ­£å¼é—®é¢˜æ‰æ·»åŠ åˆ°ç»´åº¦éœ€æ±‚åˆ—è¡¨ï¼‰
    if dimension and dimension in session["dimensions"] and not is_follow_up:
        session["dimensions"][dimension]["items"].append({
            "name": answer,
            "description": question,
            "priority": "ä¸­"
        })

    # è®¡ç®—è¦†ç›–åº¦ï¼ˆåªç»Ÿè®¡æ­£å¼é—®é¢˜ï¼Œè¿½é—®ä¸è®¡å…¥ï¼‰
    if dimension and dimension in session["dimensions"]:
        formal_count = len([log for log in session["interview_log"]
                           if log.get("dimension") == dimension and not log.get("is_follow_up", False)])
        session["dimensions"][dimension]["coverage"] = min(100, int(formal_count / 3 * 100))

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    # å¼‚æ­¥æ›´æ–°ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆè¶…è¿‡é˜ˆå€¼æ—¶è§¦å‘ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œåœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œä¸é˜»å¡å“åº”
    import threading
    def async_update_summary():
        try:
            update_context_summary(session, session_file)
        except Exception as e:
            print(f"âš ï¸ å¼‚æ­¥æ›´æ–°æ‘˜è¦å¤±è´¥: {e}")
    threading.Thread(target=async_update_summary, daemon=True).start()

    return jsonify(session)


@app.route('/api/sessions/<session_id>/undo-answer', methods=['POST'])
def undo_answer(session_id):
    """æ’¤é”€æœ€åä¸€ä¸ªå›ç­”"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # æ£€æŸ¥æ˜¯å¦æœ‰å›ç­”å¯ä»¥æ’¤é”€
    if not session.get("interview_log") or len(session["interview_log"]) == 0:
        return jsonify({"error": "æ²¡æœ‰å¯æ’¤é”€çš„å›ç­”"}), 400

    # åˆ é™¤æœ€åä¸€ä¸ªå›ç­”
    last_log = session["interview_log"].pop()
    dimension = last_log.get("dimension")
    was_follow_up = last_log.get("is_follow_up", False)

    # æ›´æ–°ç»´åº¦æ•°æ®ï¼ˆåªæœ‰æ­£å¼é—®é¢˜æ‰å½±å“ç»´åº¦ itemsï¼‰
    if dimension and dimension in session["dimensions"]:
        # åªæœ‰åˆ é™¤çš„æ˜¯æ­£å¼é—®é¢˜æ—¶ï¼Œæ‰ä» items ä¸­åˆ é™¤
        if not was_follow_up and session["dimensions"][dimension]["items"]:
            session["dimensions"][dimension]["items"].pop()

        # é‡æ–°è®¡ç®—è¦†ç›–åº¦ï¼ˆåªç»Ÿè®¡æ­£å¼é—®é¢˜ï¼‰
        formal_count = len([log for log in session["interview_log"]
                           if log.get("dimension") == dimension and not log.get("is_follow_up", False)])
        session["dimensions"][dimension]["coverage"] = min(100, int(formal_count / 3 * 100))

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify(session)


# ============ æ–‡æ¡£ä¸Šä¼  API ============

@app.route('/api/sessions/<session_id>/documents', methods=['POST'])
def upload_document(session_id):
    """ä¸Šä¼ å‚è€ƒæ–‡æ¡£"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    if 'file' not in request.files:
        return jsonify({"error": "æœªæ‰¾åˆ°æ–‡ä»¶"}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400

    filename = file.filename
    filepath = TEMP_DIR / filename
    file.save(filepath)

    # è¯»å–æ–‡ä»¶å†…å®¹
    ext = Path(filename).suffix.lower()
    content = ""

    if ext in ['.md', '.txt']:
        content = filepath.read_text(encoding="utf-8")
    elif ext == '.pdf':
        content = f"[PDF æ–‡ä»¶: {filename}]"  # ç®€åŒ–å¤„ç†
    elif ext in ['.docx', '.xlsx', '.pptx']:
        # è°ƒç”¨è½¬æ¢è„šæœ¬
        import subprocess
        convert_script = SKILL_DIR / "scripts" / "convert_doc.py"
        if convert_script.exists():
            try:
                result = subprocess.run(
                    ["uv", "run", str(convert_script), "convert", str(filepath)],
                    capture_output=True, text=True, cwd=str(SKILL_DIR)
                )
                if result.returncode == 0:
                    converted_file = CONVERTED_DIR / f"{Path(filename).stem}.md"
                    if converted_file.exists():
                        content = converted_file.read_text(encoding="utf-8")
            except Exception as e:
                print(f"è½¬æ¢æ–‡æ¡£å¤±è´¥: {e}")

    # æ›´æ–°ä¼šè¯
    session = json.loads(session_file.read_text(encoding="utf-8"))
    session["reference_docs"].append({
        "name": filename,
        "type": ext,
        "content": content[:10000],  # é™åˆ¶é•¿åº¦
        "uploaded_at": get_utc_now()
    })
    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify({
        "success": True,
        "filename": filename,
        "content_length": len(content)
    })


@app.route('/api/sessions/<session_id>/documents/<path:doc_name>', methods=['DELETE'])
def delete_document(session_id, doc_name):
    """åˆ é™¤å‚è€ƒæ–‡æ¡£"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # æŸ¥æ‰¾å¹¶åˆ é™¤æ–‡æ¡£
    original_count = len(session["reference_docs"])
    session["reference_docs"] = [
        doc for doc in session["reference_docs"]
        if doc["name"] != doc_name
    ]

    if len(session["reference_docs"]) == original_count:
        return jsonify({"error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    # æ³¨æ„ï¼šä¸åˆ é™¤åå°æ–‡ä»¶å­˜æ¡£ï¼Œä»…ä»ä¼šè¯ä¸­ç§»é™¤å¼•ç”¨
    # è¿™æ ·æ–‡ä»¶ä»ä¿ç•™åœ¨ temp/ å’Œ converted/ ç›®å½•ä¸­ä¾›åç»­ä½¿ç”¨

    return jsonify({
        "success": True,
        "deleted": doc_name
    })


# ============ å·²æœ‰è°ƒç ”æˆæœ API ============

@app.route('/api/sessions/<session_id>/research-docs', methods=['POST'])
def upload_research_doc(session_id):
    """ä¸Šä¼ å·²æœ‰è°ƒç ”æˆæœæ–‡æ¡£"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    if 'file' not in request.files:
        return jsonify({"error": "æœªæ‰¾åˆ°æ–‡ä»¶"}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400

    filename = file.filename
    filepath = TEMP_DIR / filename
    file.save(filepath)

    # è¯»å–æ–‡ä»¶å†…å®¹
    ext = Path(filename).suffix.lower()
    content = ""

    if ext in ['.md', '.txt']:
        content = filepath.read_text(encoding="utf-8")
    elif ext == '.pdf':
        content = f"[PDF æ–‡ä»¶: {filename}]"  # ç®€åŒ–å¤„ç†
    elif ext in ['.docx', '.xlsx', '.pptx']:
        # è°ƒç”¨è½¬æ¢è„šæœ¬
        import subprocess
        convert_script = SKILL_DIR / "scripts" / "convert_doc.py"
        if convert_script.exists():
            try:
                result = subprocess.run(
                    ["uv", "run", str(convert_script), "convert", str(filepath)],
                    capture_output=True, text=True, cwd=str(SKILL_DIR)
                )
                if result.returncode == 0:
                    converted_file = CONVERTED_DIR / f"{Path(filename).stem}.md"
                    if converted_file.exists():
                        content = converted_file.read_text(encoding="utf-8")
            except Exception as e:
                print(f"è½¬æ¢æ–‡æ¡£å¤±è´¥: {e}")

    # æ›´æ–°ä¼šè¯
    session = json.loads(session_file.read_text(encoding="utf-8"))

    # ç¡®ä¿ research_docs å­—æ®µå­˜åœ¨ï¼ˆå…¼å®¹æ—§ä¼šè¯ï¼‰
    if "research_docs" not in session:
        session["research_docs"] = []

    session["research_docs"].append({
        "name": filename,
        "type": ext,
        "content": content[:10000],  # é™åˆ¶é•¿åº¦
        "uploaded_at": get_utc_now()
    })
    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify({
        "success": True,
        "filename": filename,
        "content_length": len(content)
    })


@app.route('/api/sessions/<session_id>/research-docs/<path:doc_name>', methods=['DELETE'])
def delete_research_doc(session_id, doc_name):
    """åˆ é™¤å·²æœ‰è°ƒç ”æˆæœæ–‡æ¡£"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # ç¡®ä¿ research_docs å­—æ®µå­˜åœ¨ï¼ˆå…¼å®¹æ—§ä¼šè¯ï¼‰
    if "research_docs" not in session:
        session["research_docs"] = []
        return jsonify({"error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404

    # æŸ¥æ‰¾å¹¶åˆ é™¤æ–‡æ¡£
    original_count = len(session["research_docs"])
    session["research_docs"] = [
        doc for doc in session["research_docs"]
        if doc["name"] != doc_name
    ]

    if len(session["research_docs"]) == original_count:
        return jsonify({"error": "æ–‡æ¡£ä¸å­˜åœ¨"}), 404

    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify({
        "success": True,
        "deleted": doc_name
    })


# ============ é‡æ–°è°ƒç ” API ============

@app.route('/api/sessions/<session_id>/restart-research', methods=['POST'])
def restart_research(session_id):
    """é‡æ–°è°ƒç ”ï¼šå°†å½“å‰è®¿è°ˆè®°å½•ä¿å­˜ä¸ºè°ƒç ”æˆæœï¼Œç„¶åé‡ç½®è®¿è°ˆçŠ¶æ€"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # æ•´ç†å½“å‰è®¿è°ˆè®°å½•ä¸º markdown æ ¼å¼
    interview_log = session.get("interview_log", [])
    if not interview_log:
        return jsonify({"error": "æ²¡æœ‰è®¿è°ˆè®°å½•å¯ä»¥ä¿å­˜"}), 400

    # ç”Ÿæˆè°ƒç ”æˆæœæ–‡æ¡£å†…å®¹
    research_content = f"""# è°ƒç ”è®°å½• - {session.get('topic', 'æœªå‘½åè°ƒç ”')}

ç”Ÿæˆæ—¶é—´: {get_utc_now()}

"""

    if session.get("description"):
        # æ¸…ç†æè¿°ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        desc = session['description'].replace('\n', ' ').replace('\r', '')
        research_content += f"ä¸»é¢˜æè¿°: {desc}\n\n"

    research_content += "## è®¿è°ˆè®°å½•\n\n"

    # æŒ‰ç»´åº¦æ•´ç†è®¿è°ˆè®°å½•
    for dim_key, dim_info in DIMENSION_INFO.items():
        dim_logs = [log for log in interview_log if log.get("dimension") == dim_key]
        if dim_logs:
            research_content += f"### {dim_info['name']}\n\n"
            for log in dim_logs:
                # æ¸…ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…å½±å“ JSON è§£æ
                question = log.get('question', '').replace('**', '').replace('`', '')
                answer = log.get('answer', '').replace('**', '').replace('`', '')

                research_content += f"Q: {question}\n\n"
                research_content += f"A: {answer}\n\n"

                if log.get('follow_up_question'):
                    follow_q = log['follow_up_question'].replace('**', '').replace('`', '')
                    follow_a = log.get('follow_up_answer', '').replace('**', '').replace('`', '')
                    research_content += f"è¿½é—®: {follow_q}\n\n"
                    research_content += f"å›ç­”: {follow_a}\n\n"
                research_content += "---\n\n"

    # ç¡®ä¿ research_docs å­—æ®µå­˜åœ¨
    if "research_docs" not in session:
        session["research_docs"] = []

    # æ·»åŠ åˆ°è°ƒç ”æˆæœåˆ—è¡¨
    doc_name = f"è°ƒç ”è®°å½•-{get_utc_now().replace(':', '-').replace(' ', '_')}.md"

    # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¿‡é•¿å¯¼è‡´ AI prompt é—®é¢˜
    max_length = 2000
    if len(research_content) > max_length:
        research_content = research_content[:max_length] + "\n\n...(å†…å®¹è¿‡é•¿å·²æˆªæ–­)"

    session["research_docs"].append({
        "name": doc_name,
        "type": ".md",
        "content": research_content,
        "uploaded_at": get_utc_now()
    })

    # é‡ç½®è®¿è°ˆçŠ¶æ€
    session["interview_log"] = []
    session["dimensions"] = {
        "customer_needs": {"coverage": 0, "items": []},
        "business_process": {"coverage": 0, "items": []},
        "tech_constraints": {"coverage": 0, "items": []},
        "project_constraints": {"coverage": 0, "items": []}
    }
    session["status"] = "in_progress"  # é‡ç½®çŠ¶æ€ä¸ºè¿›è¡Œä¸­
    session["updated_at"] = get_utc_now()

    # ä¿å­˜ä¼šè¯
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify({
        "success": True,
        "message": "å·²ä¿å­˜å½“å‰è°ƒç ”æˆæœå¹¶é‡ç½®è®¿è°ˆ",
        "research_doc_name": doc_name
    })


# ============ æŠ¥å‘Šç”Ÿæˆ API ============

@app.route('/api/sessions/<session_id>/generate-report', methods=['POST'])
def generate_report(session_id):
    """ç”Ÿæˆè°ƒç ”æŠ¥å‘Šï¼ˆAI ç”Ÿæˆï¼‰"""
    session_file = SESSIONS_DIR / f"{session_id}.json"
    if not session_file.exists():
        return jsonify({"error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    session = json.loads(session_file.read_text(encoding="utf-8"))

    # æ£€æŸ¥æ˜¯å¦æœ‰ Claude API
    if claude_client:
        prompt = build_report_prompt(session)

        # æ—¥å¿—ï¼šè®°å½•æŠ¥å‘Šç”Ÿæˆ prompt ç»Ÿè®¡
        if ENABLE_DEBUG_LOG:
            ref_docs_count = len(session.get("reference_docs", []))
            research_docs_count = len(session.get("research_docs", []))
            interview_count = len(session.get("interview_log", []))
            print(f"ğŸ“Š æŠ¥å‘Šç”Ÿæˆ Prompt ç»Ÿè®¡ï¼šæ€»é•¿åº¦={len(prompt)}å­—ç¬¦ï¼Œå‚è€ƒæ–‡æ¡£={ref_docs_count}ä¸ªï¼Œè°ƒç ”æˆæœ={research_docs_count}ä¸ªï¼Œè®¿è°ˆè®°å½•={interview_count}æ¡")

        report_content = call_claude(
            prompt,
            max_tokens=MAX_TOKENS_REPORT,
            call_type="report"
        )

        if report_content:
            # è¿½åŠ å®Œæ•´çš„è®¿è°ˆè®°å½•é™„å½•ï¼ˆç¡®ä¿é™„å½•å®Œæ•´ï¼‰
            appendix = generate_interview_appendix(session)
            report_content = report_content + appendix

            # ä¿å­˜æŠ¥å‘Š
            topic_slug = session.get("topic", "report").replace(" ", "-")[:30]
            date_str = datetime.now().strftime("%Y%m%d")
            filename = f"deep-vision-{date_str}-{topic_slug}.md"
            report_file = REPORTS_DIR / filename
            report_file.write_text(report_content, encoding="utf-8")

            # æ›´æ–°ä¼šè¯çŠ¶æ€
            session["status"] = "completed"
            session["updated_at"] = get_utc_now()
            session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

            return jsonify({
                "success": True,
                "report_path": str(report_file),
                "report_name": filename,
                "ai_generated": True
            })

    # å›é€€åˆ°ç®€å•æŠ¥å‘Šç”Ÿæˆ
    report_content = generate_simple_report(session)
    topic_slug = session.get("topic", "report").replace(" ", "-")[:30]
    date_str = datetime.now().strftime("%Y%m%d")
    filename = f"deep-vision-{date_str}-{topic_slug}.md"
    report_file = REPORTS_DIR / filename
    report_file.write_text(report_content, encoding="utf-8")

    session["status"] = "completed"
    session["updated_at"] = get_utc_now()
    session_file.write_text(json.dumps(session, ensure_ascii=False, indent=2), encoding="utf-8")

    return jsonify({
        "success": True,
        "report_path": str(report_file),
        "report_name": filename,
        "ai_generated": False
    })


def generate_interview_appendix(session: dict) -> str:
    """ç”Ÿæˆå®Œæ•´çš„è®¿è°ˆè®°å½•é™„å½•"""
    interview_log = session.get("interview_log", [])
    if not interview_log:
        return ""

    appendix = "\n\n---\n\n## é™„å½•ï¼šå®Œæ•´è®¿è°ˆè®°å½•\n\n"
    appendix += f"> æœ¬æ¬¡è°ƒç ”å…±æ”¶é›†äº† {len(interview_log)} ä¸ªé—®é¢˜çš„å›ç­”\n\n"

    for i, log in enumerate(interview_log, 1):
        dim_name = DIMENSION_INFO.get(log.get('dimension', ''), {}).get('name', 'æœªåˆ†ç±»')
        appendix += f"### Q{i}: {log['question']}\n\n"
        appendix += f"**å›ç­”**: {log['answer']}\n\n"
        appendix += f"**ç»´åº¦**: {dim_name}\n\n"
        if log.get('timestamp'):
            appendix += f"*è®°å½•æ—¶é—´: {log['timestamp']}*\n\n"
        appendix += "---\n\n"

    return appendix


def generate_simple_report(session: dict) -> str:
    """ç”Ÿæˆç®€å•æŠ¥å‘Šï¼ˆæ—  AI æ—¶ä½¿ç”¨ï¼‰"""
    topic = session.get("topic", "æœªå‘½åé¡¹ç›®")
    interview_log = session.get("interview_log", [])
    now = datetime.now()

    content = f"""# {topic} éœ€æ±‚è°ƒç ”æŠ¥å‘Š

**è°ƒç ”æ—¥æœŸ**: {now.strftime('%Y-%m-%d')}
**æŠ¥å‘Šç¼–å·**: deep-vision-{now.strftime('%Y%m%d')}

---

## 1. è°ƒç ”æ¦‚è¿°

æœ¬æ¬¡è°ƒç ”ä¸»é¢˜ä¸ºã€Œ{topic}ã€ï¼Œå…±æ”¶é›†äº† {len(interview_log)} ä¸ªé—®é¢˜çš„å›ç­”ã€‚

## 2. éœ€æ±‚æ‘˜è¦

"""

    for dim_key, dim_info in DIMENSION_INFO.items():
        content += f"### {dim_info['name']}\n\n"
        logs = [log for log in interview_log if log.get("dimension") == dim_key]
        if logs:
            for log in logs:
                content += f"- **{log['answer']}** - {log['question']}\n"
        else:
            content += "*æš‚æ— æ•°æ®*\n"
        content += "\n"

    # ä½¿ç”¨ç»Ÿä¸€çš„é™„å½•ç”Ÿæˆå‡½æ•°ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
    content += generate_interview_appendix(session)

    content += """
*æ­¤æŠ¥å‘Šç”± Deep Vision æ·±ç³-æ™ºèƒ½éœ€æ±‚è°ƒç ”åŠ©æ‰‹ç”Ÿæˆ*
"""

    return content


# ============ æŠ¥å‘Š API ============

@app.route('/api/reports', methods=['GET'])
def list_reports():
    """è·å–æ‰€æœ‰æŠ¥å‘Šï¼ˆæ’é™¤å·²åˆ é™¤çš„ï¼‰"""
    deleted = get_deleted_reports()
    reports = []
    for f in REPORTS_DIR.glob("*.md"):
        # è·³è¿‡å·²æ ‡è®°ä¸ºåˆ é™¤çš„æŠ¥å‘Š
        if f.name in deleted:
            continue
        stat = f.stat()
        reports.append({
            "name": f.name,
            "path": str(f),
            "size": stat.st_size,
            "created_at": datetime.fromtimestamp(stat.st_mtime).isoformat()
        })

    reports.sort(key=lambda x: x["created_at"], reverse=True)
    return jsonify(reports)


@app.route('/api/reports/<path:filename>', methods=['GET'])
def get_report(filename):
    """è·å–æŠ¥å‘Šå†…å®¹"""
    report_file = REPORTS_DIR / filename
    if not report_file.exists():
        return jsonify({"error": "æŠ¥å‘Šä¸å­˜åœ¨"}), 404

    content = report_file.read_text(encoding="utf-8")
    return jsonify({"name": filename, "content": content})


@app.route('/api/reports/<path:filename>', methods=['DELETE'])
def delete_report(filename):
    """åˆ é™¤æŠ¥å‘Šï¼ˆä»…æ ‡è®°ä¸ºå·²åˆ é™¤ï¼Œä¿ç•™æ–‡ä»¶å­˜æ¡£ï¼‰"""
    report_file = REPORTS_DIR / filename
    if not report_file.exists():
        return jsonify({"error": "æŠ¥å‘Šä¸å­˜åœ¨"}), 404

    try:
        # åªæ ‡è®°ä¸ºå·²åˆ é™¤ï¼Œä¸çœŸæ­£åˆ é™¤æ–‡ä»¶
        mark_report_as_deleted(filename)
        return jsonify({
            "message": "æŠ¥å‘Šå·²ä»åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆæ–‡ä»¶å·²å­˜æ¡£ï¼‰",
            "name": filename
        })
    except Exception as e:
        return jsonify({"error": f"æ ‡è®°åˆ é™¤å¤±è´¥: {str(e)}"}), 500


# ============ çŠ¶æ€ API ============

@app.route('/api/status', methods=['GET'])
def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    return jsonify({
        "status": "running",
        "ai_available": claude_client is not None,
        "model": MODEL_NAME if claude_client else None,
        "sessions_dir": str(SESSIONS_DIR),
        "reports_dir": str(REPORTS_DIR)
    })


@app.route('/api/status/web-search', methods=['GET'])
def get_web_search_status():
    """è·å– Web Search API è°ƒç”¨çŠ¶æ€ï¼ˆç”¨äºå‰ç«¯å‘¼å¸ç¯æ•ˆæœï¼‰"""
    return jsonify({
        "active": web_search_active
    })


@app.route('/api/metrics', methods=['GET'])
def get_metrics():
    """è·å– API æ€§èƒ½æŒ‡æ ‡å’Œç»Ÿè®¡ä¿¡æ¯"""
    last_n = request.args.get('last_n', type=int)
    stats = metrics_collector.get_statistics(last_n=last_n)
    return jsonify(stats)


@app.route('/api/metrics/reset', methods=['POST'])
def reset_metrics():
    """é‡ç½®æ€§èƒ½æŒ‡æ ‡ï¼ˆæ¸…ç©ºå†å²æ•°æ®ï¼‰"""
    try:
        metrics_collector.metrics_file.write_text(json.dumps({
            "calls": [],
            "summary": {
                "total_calls": 0,
                "total_timeouts": 0,
                "total_truncations": 0,
                "avg_response_time": 0,
                "avg_prompt_length": 0
            }
        }, ensure_ascii=False, indent=2), encoding="utf-8")
        return jsonify({"success": True, "message": "æ€§èƒ½æŒ‡æ ‡å·²é‡ç½®"})
    except Exception as e:
        return jsonify({"error": f"é‡ç½®å¤±è´¥: {e}"}), 500


@app.route('/api/summaries', methods=['GET'])
def get_summaries_info():
    """è·å–æ™ºèƒ½æ‘˜è¦ç¼“å­˜ä¿¡æ¯"""
    try:
        cache_files = list(SUMMARIES_DIR.glob("*.txt"))
        total_size = sum(f.stat().st_size for f in cache_files)

        return jsonify({
            "enabled": ENABLE_SMART_SUMMARY,
            "cache_enabled": SUMMARY_CACHE_ENABLED,
            "threshold": SMART_SUMMARY_THRESHOLD,
            "target_length": SMART_SUMMARY_TARGET,
            "cached_count": len(cache_files),
            "cache_size_bytes": total_size,
            "cache_size_kb": round(total_size / 1024, 2),
            "cache_directory": str(SUMMARIES_DIR)
        })
    except Exception as e:
        return jsonify({"error": f"è·å–æ‘˜è¦ä¿¡æ¯å¤±è´¥: {e}"}), 500


@app.route('/api/summaries/clear', methods=['POST'])
def clear_summaries_cache():
    """æ¸…ç©ºæ™ºèƒ½æ‘˜è¦ç¼“å­˜"""
    try:
        cache_files = list(SUMMARIES_DIR.glob("*.txt"))
        deleted_count = 0
        for f in cache_files:
            try:
                f.unlink()
                deleted_count += 1
            except Exception:
                pass

        return jsonify({
            "success": True,
            "message": f"å·²æ¸…ç©º {deleted_count} ä¸ªæ‘˜è¦ç¼“å­˜",
            "deleted_count": deleted_count
        })
    except Exception as e:
        return jsonify({"error": f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}"}), 500


if __name__ == '__main__':
    print("=" * 60)
    print("Deep Vision Web Server - AI é©±åŠ¨ç‰ˆæœ¬")
    print("=" * 60)
    print(f"Sessions: {SESSIONS_DIR}")
    print(f"Reports: {REPORTS_DIR}")
    print(f"AI çŠ¶æ€: {'å·²å¯ç”¨' if claude_client else 'æœªå¯ç”¨'}")
    if claude_client:
        print(f"æ¨¡å‹: {MODEL_NAME}")

    # æœç´¢åŠŸèƒ½çŠ¶æ€
    search_enabled = ENABLE_WEB_SEARCH and ZHIPU_API_KEY and ZHIPU_API_KEY != "your-zhipu-api-key-here"
    print(f"è”ç½‘æœç´¢: {'âœ… å·²å¯ç”¨ (æ™ºè°±AI MCP)' if search_enabled else 'âš ï¸  æœªå¯ç”¨'}")
    if not search_enabled and ENABLE_WEB_SEARCH:
        print("   æç¤º: é…ç½® ZHIPU_API_KEY ä»¥å¯ç”¨è”ç½‘æœç´¢åŠŸèƒ½")

    print()
    print(f"è®¿é—®: http://localhost:{SERVER_PORT}")
    print("=" * 60)
    app.run(host=SERVER_HOST, port=SERVER_PORT, debug=DEBUG_MODE)
