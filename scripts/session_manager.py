#!/usr/bin/env python3
# /// script
# requires-python = ">=3.10"
# dependencies = []
# ///
"""
Deep-Vision ä¼šè¯ç®¡ç†å·¥å…·

ç”¨é€”: ç®¡ç†è°ƒç ”ä¼šè¯çš„ä¿å­˜ã€æ¢å¤å’Œæ¸…ç†
ä½¿ç”¨æ–¹å¼: uvx scripts/session_manager.py <å‘½ä»¤> [å‚æ•°]
"""

import argparse
import json
import logging
import os
import secrets
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# é¢œè‰²ä»£ç 
class Colors:
    RED = "\033[0;31m"
    GREEN = "\033[0;32m"
    YELLOW = "\033[1;33m"
    BLUE = "\033[0;34m"
    NC = "\033[0m"


def log_info(message: str) -> None:
    """è¾“å‡ºä¿¡æ¯æ—¥å¿—"""
    print(f"{Colors.GREEN}[INFO]{Colors.NC} {message}")


def log_warn(message: str) -> None:
    """è¾“å‡ºè­¦å‘Šæ—¥å¿—"""
    print(f"{Colors.YELLOW}[WARN]{Colors.NC} {message}")


def log_error(message: str) -> None:
    """è¾“å‡ºé”™è¯¯æ—¥å¿—"""
    print(f"{Colors.RED}[ERROR]{Colors.NC} {message}")


def get_script_dir() -> Path:
    """è·å–è„šæœ¬æ‰€åœ¨ç›®å½•"""
    return Path(__file__).parent.resolve()


def get_session_dir() -> Path:
    """è·å–ä¼šè¯å­˜å‚¨ç›®å½•"""
    session_dir = get_script_dir().parent / "data" / "sessions"
    session_dir.mkdir(parents=True, exist_ok=True)
    return session_dir


def get_reports_dir() -> Path:
    """è·å–æŠ¥å‘Šå­˜å‚¨ç›®å½•"""
    reports_dir = get_script_dir().parent / "data" / "reports"
    reports_dir.mkdir(parents=True, exist_ok=True)
    return reports_dir


def generate_session_id() -> str:
    """ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    random_suffix = secrets.token_hex(4)
    return f"dv-{timestamp}-{random_suffix}"


def get_utc_now() -> str:
    """è·å–å½“å‰UTCæ—¶é—´çš„ISOæ ¼å¼å­—ç¬¦ä¸²"""
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def create_session(topic: str) -> str:
    """
    åˆ›å»ºæ–°çš„è°ƒç ”ä¼šè¯

    Args:
        topic: è°ƒç ”ä¸»é¢˜

    Returns:
        str: ä¼šè¯ID
    """
    session_id = generate_session_id()
    session_file = get_session_dir() / f"{session_id}.json"

    session_data = {
        "session_id": session_id,
        "topic": topic,
        "created_at": get_utc_now(),
        "updated_at": get_utc_now(),
        "status": "in_progress",
        "scenario": None,  # è°ƒç ”åœºæ™¯
        "dimensions": {
            "customer_needs": {"coverage": 0, "items": []},
            "business_process": {"coverage": 0, "items": []},
            "tech_constraints": {"coverage": 0, "items": []},
            "project_constraints": {"coverage": 0, "items": []}
        },
        "reference_docs": [],
        "interview_log": [],
        "requirements": [],
        "summary": None
    }

    session_file.write_text(
        json.dumps(session_data, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    log_info(f"åˆ›å»ºä¼šè¯: {session_id}")
    return session_id


def list_sessions() -> list[dict]:
    """
    åˆ—å‡ºæ‰€æœ‰ä¼šè¯

    Returns:
        list[dict]: ä¼šè¯åˆ—è¡¨
    """
    session_dir = get_session_dir()
    sessions = []

    for session_file in session_dir.glob("*.json"):
        try:
            data = json.loads(session_file.read_text(encoding="utf-8"))
            sessions.append({
                "session_id": data.get("session_id", session_file.stem),
                "topic": data.get("topic", "æœªçŸ¥"),
                "status": data.get("status", "æœªçŸ¥"),
                "created_at": data.get("created_at", "æœªçŸ¥"),
                "updated_at": data.get("updated_at", "æœªçŸ¥"),
                "dimensions": data.get("dimensions", {})
            })
        except (json.JSONDecodeError, IOError) as e:
            log_warn(f"è¯»å–ä¼šè¯æ–‡ä»¶å¤±è´¥: {session_file.name} - {e}")

    # æŒ‰æ›´æ–°æ—¶é—´æ’åº
    sessions.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
    return sessions


def print_sessions_table(sessions: list[dict]) -> None:
    """æ‰“å°ä¼šè¯åˆ—è¡¨è¡¨æ ¼"""
    if not sessions:
        log_info("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¼šè¯")
        return

    # è¡¨å¤´
    print(f"{Colors.BLUE}{'â”' * 80}{Colors.NC}")
    print(f"{'ä¼šè¯ID':<25} {'ä¸»é¢˜':<20} {'çŠ¶æ€':<10} {'æ›´æ–°æ—¶é—´':<20}")
    print(f"{Colors.BLUE}{'â”' * 80}{Colors.NC}")

    status_icons = {
        "in_progress": "ğŸ”„ è¿›è¡Œä¸­",
        "completed": "âœ… å·²å®Œæˆ",
        "paused": "â¸ï¸ å·²æš‚åœ"
    }

    for session in sessions:
        topic = session["topic"]
        if len(topic) > 18:
            topic = topic[:15] + "..."

        status = status_icons.get(session["status"], session["status"])

        print(f"{session['session_id']:<25} {topic:<20} {status:<10} {session['updated_at']:<20}")

    print(f"{Colors.BLUE}{'â”' * 80}{Colors.NC}")


def get_session(session_id: str) -> Optional[dict]:
    """
    è·å–ä¼šè¯è¯¦æƒ…

    Args:
        session_id: ä¼šè¯ID

    Returns:
        Optional[dict]: ä¼šè¯æ•°æ®
    """
    session_file = get_session_dir() / f"{session_id}.json"

    if not session_file.exists():
        log_error(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        return None

    try:
        return json.loads(session_file.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, IOError) as e:
        log_error(f"è¯»å–ä¼šè¯å¤±è´¥: {e}")
        return None


def update_session(session_id: str, updates: dict) -> bool:
    """
    æ›´æ–°ä¼šè¯æ•°æ®

    Args:
        session_id: ä¼šè¯ID
        updates: è¦æ›´æ–°çš„å­—æ®µ

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    session_file = get_session_dir() / f"{session_id}.json"

    if not session_file.exists():
        log_error(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        return False

    try:
        data = json.loads(session_file.read_text(encoding="utf-8"))
        data.update(updates)
        data["updated_at"] = get_utc_now()

        session_file.write_text(
            json.dumps(data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        log_info(f"å·²æ›´æ–°ä¼šè¯: {session_id}")
        return True

    except (json.JSONDecodeError, IOError) as e:
        log_error(f"æ›´æ–°ä¼šè¯å¤±è´¥: {e}")
        return False


def add_interview_log(session_id: str, question: str, answer: str, dimension: Optional[str] = None) -> bool:
    """
    æ·»åŠ è®¿è°ˆè®°å½•

    Args:
        session_id: ä¼šè¯ID
        question: é—®é¢˜
        answer: å›ç­”
        dimension: æ‰€å±ç»´åº¦ï¼ˆå¯é€‰ï¼‰

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    session = get_session(session_id)
    if not session:
        return False

    log_entry = {
        "timestamp": get_utc_now(),
        "question": question,
        "answer": answer,
        "dimension": dimension
    }

    session["interview_log"].append(log_entry)
    session["updated_at"] = get_utc_now()

    session_file = get_session_dir() / f"{session_id}.json"
    session_file.write_text(
        json.dumps(session, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    return True


def update_dimension_coverage(session_id: str, dimension: str, coverage: int, items: list) -> bool:
    """
    æ›´æ–°ç»´åº¦è¦†ç›–åº¦

    Args:
        session_id: ä¼šè¯ID
        dimension: ç»´åº¦åç§°
        coverage: è¦†ç›–åº¦ç™¾åˆ†æ¯”
        items: æ”¶é›†çš„ä¿¡æ¯é¡¹

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    session = get_session(session_id)
    if not session:
        return False

    if dimension not in session["dimensions"]:
        log_error(f"æœªçŸ¥ç»´åº¦: {dimension}")
        return False

    session["dimensions"][dimension]["coverage"] = coverage
    session["dimensions"][dimension]["items"] = items
    session["updated_at"] = get_utc_now()

    session_file = get_session_dir() / f"{session_id}.json"
    session_file.write_text(
        json.dumps(session, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    return True


def get_incomplete_sessions() -> list[str]:
    """
    è·å–æœªå®Œæˆçš„ä¼šè¯IDåˆ—è¡¨

    Returns:
        list[str]: æœªå®Œæˆçš„ä¼šè¯IDåˆ—è¡¨
    """
    sessions = list_sessions()
    return [
        s["session_id"]
        for s in sessions
        if s["status"] in ("in_progress", "paused")
    ]


def pause_session(session_id: str) -> bool:
    """æš‚åœä¼šè¯"""
    return update_session(session_id, {"status": "paused"})


def resume_session(session_id: str) -> bool:
    """æ¢å¤ä¼šè¯"""
    return update_session(session_id, {"status": "in_progress"})


def complete_session(session_id: str) -> bool:
    """å®Œæˆä¼šè¯"""
    return update_session(session_id, {"status": "completed"})


def delete_session(session_id: str) -> bool:
    """
    åˆ é™¤ä¼šè¯

    Args:
        session_id: ä¼šè¯ID

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    session_file = get_session_dir() / f"{session_id}.json"

    if not session_file.exists():
        log_error(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        return False

    session_file.unlink()
    log_info(f"ä¼šè¯å·²åˆ é™¤: {session_id}")
    return True


def cleanup_completed(days: int = 30) -> int:
    """
    æ¸…ç†å·²å®Œæˆçš„æ—§ä¼šè¯

    Args:
        days: ä¿ç•™å¤©æ•°

    Returns:
        int: æ¸…ç†çš„ä¼šè¯æ•°é‡
    """
    cutoff = datetime.now(timezone.utc) - timedelta(days=days)
    count = 0

    for session_file in get_session_dir().glob("*.json"):
        try:
            data = json.loads(session_file.read_text(encoding="utf-8"))
            if data.get("status") == "completed":
                updated_str = data.get("updated_at", "")
                if updated_str:
                    updated = datetime.fromisoformat(updated_str.replace("Z", "+00:00"))
                    if updated < cutoff:
                        session_file.unlink()
                        count += 1
        except Exception as e:
            log_warn(f"å¤„ç†ä¼šè¯æ–‡ä»¶æ—¶å‡ºé”™: {session_file.name} - {e}")

    log_info(f"å·²æ¸…ç† {count} ä¸ªè¿‡æœŸä¼šè¯")
    return count


def get_progress_display(session_id: str) -> str:
    """
    è·å–è¿›åº¦æ˜¾ç¤ºå­—ç¬¦ä¸²

    Args:
        session_id: ä¼šè¯ID

    Returns:
        str: è¿›åº¦æ˜¾ç¤ºæ–‡æœ¬
    """
    session = get_session(session_id)
    if not session:
        return ""

    dimension_names = {
        "customer_needs": "å®¢æˆ·éœ€æ±‚",
        "business_process": "ä¸šåŠ¡æµç¨‹",
        "tech_constraints": "æŠ€æœ¯çº¦æŸ",
        "project_constraints": "é¡¹ç›®çº¦æŸ"
    }

    lines = ["ğŸ“Š è°ƒç ”è¿›åº¦"]

    for dim_key, dim_name in dimension_names.items():
        coverage = session["dimensions"].get(dim_key, {}).get("coverage", 0)

        # ç”Ÿæˆè¿›åº¦æ¡
        filled = int(coverage / 10)
        empty = 10 - filled

        if coverage == 100:
            icon = "âœ…"
        elif coverage > 0:
            icon = "ğŸ”„"
        else:
            icon = "â¬œ"

        bar = "â–ˆ" * filled + "â–‘" * empty
        lines.append(f" {icon} {dim_name:<8} [{bar}] {coverage:>3}%")

    return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Deep-Vision ä¼šè¯ç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  uvx scripts/session_manager.py create "CRMç³»ç»Ÿéœ€æ±‚è°ƒç ”"
  uvx scripts/session_manager.py list
  uvx scripts/session_manager.py get dv-20260120-abc12345
  uvx scripts/session_manager.py progress dv-20260120-abc12345
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="å‘½ä»¤")

    # create å‘½ä»¤
    create_parser = subparsers.add_parser("create", help="åˆ›å»ºæ–°ä¼šè¯")
    create_parser.add_argument("topic", help="è°ƒç ”ä¸»é¢˜")

    # list å‘½ä»¤
    subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰ä¼šè¯")

    # get å‘½ä»¤
    get_parser = subparsers.add_parser("get", help="è·å–ä¼šè¯è¯¦æƒ…")
    get_parser.add_argument("session_id", help="ä¼šè¯ID")

    # incomplete å‘½ä»¤
    subparsers.add_parser("incomplete", help="è·å–æœªå®Œæˆçš„ä¼šè¯")

    # pause å‘½ä»¤
    pause_parser = subparsers.add_parser("pause", help="æš‚åœä¼šè¯")
    pause_parser.add_argument("session_id", help="ä¼šè¯ID")

    # resume å‘½ä»¤
    resume_parser = subparsers.add_parser("resume", help="æ¢å¤ä¼šè¯")
    resume_parser.add_argument("session_id", help="ä¼šè¯ID")

    # complete å‘½ä»¤
    complete_parser = subparsers.add_parser("complete", help="å®Œæˆä¼šè¯")
    complete_parser.add_argument("session_id", help="ä¼šè¯ID")

    # delete å‘½ä»¤
    delete_parser = subparsers.add_parser("delete", help="åˆ é™¤ä¼šè¯")
    delete_parser.add_argument("session_id", help="ä¼šè¯ID")

    # cleanup å‘½ä»¤
    cleanup_parser = subparsers.add_parser("cleanup", help="æ¸…ç†å·²å®Œæˆçš„æ—§ä¼šè¯")
    cleanup_parser.add_argument("days", type=int, nargs="?", default=30, help="ä¿ç•™å¤©æ•°ï¼ˆé»˜è®¤30å¤©ï¼‰")

    # progress å‘½ä»¤
    progress_parser = subparsers.add_parser("progress", help="æ˜¾ç¤ºè°ƒç ”è¿›åº¦")
    progress_parser.add_argument("session_id", help="ä¼šè¯ID")

    # add-log å‘½ä»¤
    addlog_parser = subparsers.add_parser("add-log", help="æ·»åŠ è®¿è°ˆè®°å½•")
    addlog_parser.add_argument("session_id", help="ä¼šè¯ID")
    addlog_parser.add_argument("question", help="é—®é¢˜")
    addlog_parser.add_argument("answer", help="å›ç­”")
    addlog_parser.add_argument("--dimension", help="æ‰€å±ç»´åº¦")

    # update-dimension å‘½ä»¤
    updim_parser = subparsers.add_parser("update-dimension", help="æ›´æ–°ç»´åº¦è¦†ç›–åº¦")
    updim_parser.add_argument("session_id", help="ä¼šè¯ID")
    updim_parser.add_argument("dimension", help="ç»´åº¦åç§°")
    updim_parser.add_argument("coverage", type=int, help="è¦†ç›–åº¦ç™¾åˆ†æ¯”")
    updim_parser.add_argument("--items", help="ä¿¡æ¯é¡¹ï¼ˆJSONæ•°ç»„ï¼‰")

    args = parser.parse_args()

    if args.command == "create":
        session_id = create_session(args.topic)
        print(session_id)

    elif args.command == "list":
        sessions = list_sessions()
        print_sessions_table(sessions)

    elif args.command == "get":
        session = get_session(args.session_id)
        if session:
            print(json.dumps(session, ensure_ascii=False, indent=2))

    elif args.command == "incomplete":
        incomplete = get_incomplete_sessions()
        for sid in incomplete:
            print(sid)

    elif args.command == "pause":
        if pause_session(args.session_id):
            log_info(f"ä¼šè¯å·²æš‚åœ: {args.session_id}")

    elif args.command == "resume":
        if resume_session(args.session_id):
            log_info(f"ä¼šè¯å·²æ¢å¤: {args.session_id}")

    elif args.command == "complete":
        if complete_session(args.session_id):
            log_info(f"ä¼šè¯å·²å®Œæˆ: {args.session_id}")

    elif args.command == "delete":
        delete_session(args.session_id)

    elif args.command == "cleanup":
        cleanup_completed(args.days)

    elif args.command == "progress":
        progress = get_progress_display(args.session_id)
        if progress:
            print(progress)

    elif args.command == "add-log":
        if add_interview_log(args.session_id, args.question, args.answer, args.dimension):
            log_info("è®¿è°ˆè®°å½•å·²æ·»åŠ ")

    elif args.command == "update-dimension":
        items = json.loads(args.items) if args.items else []
        if update_dimension_coverage(args.session_id, args.dimension, args.coverage, items):
            log_info(f"ç»´åº¦ {args.dimension} å·²æ›´æ–°")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
